{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language  object  object oriented  oriented  oriented programming  popular  \\\n",
      "0         1       0                0         0                     0        0   \n",
      "1         0       0                0         0                     0        1   \n",
      "2         0       0                0         0                     0        0   \n",
      "3         0       1                1         1                     1        0   \n",
      "\n",
      "   programming  programming language  programming python  python  \\\n",
      "0            1                     1                   0       1   \n",
      "1            0                     0                   0       1   \n",
      "2            1                     0                   1       1   \n",
      "3            1                     0                   1       1   \n",
      "\n",
      "   python popular  python programming  \n",
      "0               0                   1  \n",
      "1               1                   0  \n",
      "2               0                   0  \n",
      "3               0                   0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "documents = [\n",
    "    'python is a programming language',\n",
    "    'python is popular',\n",
    "    'programming in python',\n",
    "    'object-oriented programming in python'\n",
    "]\n",
    "\n",
    "vectorizer=CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "vectorizer.fit(documents)\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.fit_transform(documents).toarray(),\n",
    "    columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language    object  oriented   popular  programming    python\n",
      "0  0.711525  0.000000  0.000000  0.000000     0.496856  0.496856\n",
      "1  0.000000  0.000000  0.000000  0.871247     0.000000  0.490845\n",
      "2  0.000000  0.000000  0.000000  0.000000     0.707107  0.707107\n",
      "3  0.000000  0.616065  0.616065  0.000000     0.347080  0.347080\n",
      "4  0.819887  0.000000  0.000000  0.000000     0.572526  0.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "documents = [\n",
    "    'python is a programming language',\n",
    "    'python is popular',\n",
    "    'programming in python',\n",
    "    'object-oriented programming in python',\n",
    "    'programming language'\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=['is','in'])\n",
    "df=pd.DataFrame(data=vectorizer.fit_transform(documents).toarray(),columns=vectorizer.get_feature_names_out())\n",
    "print(df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracja 0 centroid1: [2.277925978589282, 1.4238109865487707], centroind2 [1.2154173629196332, -0.940860909988089]\n",
      "Iteracja 1 centroid1: [0.5076646452504974, 2.7977017256629315], centroind2 [2.325742076120114, -2.817348936343221]\n",
      "Iteracja 2 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 3 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 4 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 5 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 6 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 7 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 8 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n",
      "Iteracja 9 centroid1: [0.35237492115444785, 2.5020478929692644], centroind2 [2.6628395433031256, -3.08320016985017]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "data_raw=pd.read_csv('data.csv')\n",
    "min_x1=min(data_raw['x1'])\n",
    "max_x1=max(data_raw['x1'])\n",
    "min_x2=min(data_raw['x2'])\n",
    "max_x2=max(data_raw['x2'])    \n",
    "centroid1=[random.uniform(min_x1,max_x1),random.uniform(min_x2,max_x2)]\n",
    "centroid2=[random.uniform(min_x1,max_x1),random.uniform(min_x2,max_x2)]\n",
    "#print(centroid1,centroid2)\n",
    "for i in range(0,10):\n",
    "    data_raw['dist1']=norm(data_raw[['x1','x2']]-centroid1,axis=1)\n",
    "    data_raw['dist2']=norm(data_raw[['x1','x2']]-centroid2,axis=1)\n",
    "    data_raw['cluster']=np.where(data_raw['dist1']<data_raw['dist2'],1,2)\n",
    "    tempx1=data_raw[data_raw['cluster']==1]['x1']\n",
    "    tempx2=data_raw[data_raw['cluster']==1]['x2']\n",
    "    centroid1=[tempx1.values.sum()/len(tempx1), tempx2.values.sum()/len(tempx2)] \n",
    "    tempx1=data_raw[data_raw['cluster']==2]['x1']\n",
    "    tempx2=data_raw[data_raw['cluster']==2]['x2']\n",
    "    centroid2=[tempx1.values.sum()/len(tempx1), tempx2.values.sum()/len(tempx2)] \n",
    "    print(f'Iteracja {i} centroid1: {centroid1}, centroind2 {centroid2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23414.04, 7734.89, 4282.14, 3866.72, 3442.86, 3120.69, 2716.96, 2469.26]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "wcss=[]\n",
    "data_raw=pd.read_csv('clusters.csv')\n",
    "for i in(range(2,10)):\n",
    "    cluster=KMeans(n_clusters=i,random_state=42)\n",
    "    cluster.fit(data_raw[['x1','x2']])  \n",
    "    wcss.append(round(cluster.inertia_,2))\n",
    "print(wcss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23414.04, 7734.89, 4282.14, 3866.72, 3442.86, 3120.69, 2716.96, 2469.26]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.read_csv('clusters.csv')\n",
    "\n",
    "wcss = []\n",
    "for i in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(df)\n",
    "    wcss.append(round(kmeans.inertia_, 2))\n",
    "print('3' )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2  cluster\n",
      "0 -2.486532  7.025770        0\n",
      "1 -3.522549  8.578303        0\n",
      "2 -2.982040  7.998514        0\n",
      "3 -2.135276  6.255888        0\n",
      "4  2.762504  4.210918        1\n",
      "5 -3.541472  8.489106        0\n",
      "6  1.240259  0.781640        1\n",
      "7  0.053390  8.966770        0\n",
      "8 -0.827918  6.742253        0\n",
      "9  3.291716  1.296751        1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1005: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "df=pd.read_csv('clusters.csv')\n",
    "cluster=AgglomerativeClustering(n_clusters=2,affinity='manhattan',linkage='complete')\n",
    "df['cluster']=cluster.fit_predict(df)\n",
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DBSCAN' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m cluster\u001b[38;5;241m=\u001b[39mDBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m,min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mcluster\u001b[38;5;241m.\u001b[39mfit_predict(df) \n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(cluster\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DBSCAN' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "df=pd.read_csv('clusters.csv')\n",
    "cluster=DBSCAN(eps=0.6,min_samples=7)\n",
    "df['cluster']=cluster.fit_predict(df) \n",
    "print(df.cluster.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90068117 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904 -1.34022653 -1.3154443 ]\n",
      " [-0.53717756 -1.16971425 -1.05217993]\n",
      " [-1.50652052 -1.34022653 -1.18381211]\n",
      " [-1.02184904 -1.2833891  -1.3154443 ]\n",
      " [-1.74885626 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -1.2833891  -1.44707648]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "df=pd.read_csv('pca.csv')\n",
    "X=df[['var1','var2','var3']]\n",
    "y=df['class']\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "print(X_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pca1      pca2  class\n",
      "0 -2.060360 -0.298674    0.0\n",
      "1 -2.195981 -0.101727    0.0\n",
      "2 -2.365221  0.080749    0.0\n",
      "3 -2.365794  0.208165    0.0\n",
      "4 -2.128171 -0.200201    0.0\n",
      "5 -1.603256 -0.412703    0.0\n",
      "6 -2.323005  0.262683    0.0\n",
      "7 -2.094552 -0.185730    0.0\n",
      "8 -2.535034  0.390641    0.0\n",
      "9 -2.238771 -0.156245    0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "np.set_printoptions(\n",
    "    precision=8, suppress=True, edgeitems=5, linewidth=200\n",
    ")\n",
    "np.random.seed(42)\n",
    "df = pd.read_csv('pca.csv')\n",
    "\n",
    "X = df.copy()\n",
    "y = X.pop('class')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "eig_vals,eig_vecs=np.linalg.eig(np.cov(X_std.T))\n",
    "eig_pairs=[(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "eig_pairs.sort(reverse=True) \n",
    "W=np.hstack((eig_pairs[0][1].reshape(3,1),eig_pairs[1][1].reshape(3,1)))\n",
    "X_pca=X_std.dot(W)  \n",
    "df_pca=pd.DataFrame(data=X_pca,columns=['pca_1','pca_2'])\n",
    "df_pca['pca_2']=-df_pca['pca_2']\n",
    "df_pca['class']=y\n",
    "print(df_pca[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pca_1     pca_2  class\n",
      "0 -2.060360 -0.298674    0.0\n",
      "1 -2.195981 -0.101727    0.0\n",
      "2 -2.365221  0.080749    0.0\n",
      "3 -2.365794  0.208165    0.0\n",
      "4 -2.128171 -0.200201    0.0\n",
      "5 -1.603256 -0.412703    0.0\n",
      "6 -2.323005  0.262683    0.0\n",
      "7 -2.094552 -0.185730    0.0\n",
      "8 -2.535034  0.390641    0.0\n",
      "9 -2.238771 -0.156245    0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "np.set_printoptions(\n",
    "    precision=8, suppress=True, edgeitems=5, linewidth=200\n",
    ")\n",
    "np.random.seed(42)\n",
    "df = pd.read_csv('pca.csv')\n",
    "\n",
    "X = df.copy()\n",
    "y = X.pop('class')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "pca=PCA(n_components=2)\n",
    "X_pca=pca.fit_transform(X_std)\n",
    "df_pca=pd.DataFrame(data=X_pca,columns=['pca_1','pca_2'])\n",
    "df_pca['class']=y\n",
    "print(df_pca[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   expained_variance_ratio  cumulative  component\n",
      "0                 0.357832    0.357832          1\n",
      "1                 0.168064    0.525896          2\n",
      "2                 0.142732    0.668627          3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df=pd.read_csv('pca.csv')\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(df)\n",
    "pca=PCA(n_components=3)\n",
    "X_pca=pca.fit_transform(X_scaled)\n",
    "explained_variance=pca.explained_variance_ratio_\n",
    "#print(type(explained_variance))\n",
    "result=pd.DataFrame(data=explained_variance,columns=['expained_variance_ratio'])\n",
    "result['cumulative']=result.expained_variance_ratio.cumsum()\n",
    "result['component']=result.index+1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba komponentów: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df=pd.read_csv('pca.csv')\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(df)\n",
    "pca=PCA(n_components=0.95)\n",
    "X_pca=pca.fit_transform(X_scaled)   \n",
    "print('Liczba komponentów:',pca.n_components_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
