{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7222412,"sourceType":"datasetVersion","datasetId":4180521},{"sourceId":7497252,"sourceType":"datasetVersion","datasetId":4349966}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n### Zadanie prostsze: Analiza fake newsów na podstawie tytułów, \n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować tweety na podstawie tytułu. W danych mamy dostarczone tytuły artykułów oraz etykiety fake news (1) albo nie (0). \nKroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty znajdują się w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty powinny być tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przykładowo niech składa się z następujących warstw:\n\n* Warstwa wejściowa: Przyjmuje sekwencje tokenów o długości określonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentację słów jako gęstych wektorów cech.\n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, który pozwala modelowi skupić się na różnych częściach sekwencji wejściowej, co jest szczególnie przydatne w przetwarzaniu języka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z różnych części sekwencji, redukując wymiarowość danych i przygotowując je do procesu klasyfikacji.\n* Warstwa Dense (wyjściowa): Z funkcją aktywacji softmax, generuje dystrybucję prawdopodobieństwa dla dwóch możliwych klas sentymentu, umożliwiając klasyfikację.\n\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcją straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metryką \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy fake newsów na podstawie tytułów. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size).\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \n\nfake=pd.read_csv(\"/kaggle/input/fake-news-detection/fake.csv\")\ntrue=pd.read_csv(\"/kaggle/input/fake-news-detection/true.csv\")\n\nfake['class']=0\nfake.head()\n\ntrue['class']=1\ntrue.head()\n\n\ndata=pd.concat([fake,true],axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:39:47.730560Z","iopub.execute_input":"2024-02-22T17:39:47.731231Z","iopub.status.idle":"2024-02-22T17:39:49.209213Z","shell.execute_reply.started":"2024-02-22T17:39:47.731202Z","shell.execute_reply":"2024-02-22T17:39:49.208380Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X = data['title'].to_numpy()\ny = data['class'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:39:53.619505Z","iopub.execute_input":"2024-02-22T17:39:53.620108Z","iopub.status.idle":"2024-02-22T17:39:53.624879Z","shell.execute_reply.started":"2024-02-22T17:39:53.620078Z","shell.execute_reply":"2024-02-22T17:39:53.623904Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"fake\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:54:17.680907Z","iopub.execute_input":"2024-02-22T17:54:17.681334Z","iopub.status.idle":"2024-02-22T17:54:17.704176Z","shell.execute_reply.started":"2024-02-22T17:54:17.681303Z","shell.execute_reply":"2024-02-22T17:54:17.703092Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0       Donald Trump Sends Out Embarrassing New Year’...   \n1       Drunk Bragging Trump Staffer Started Russian ...   \n2       Sheriff David Clarke Becomes An Internet Joke...   \n3       Trump Is So Obsessed He Even Has Obama’s Name...   \n4       Pope Francis Just Called Out Donald Trump Dur...   \n...                                                  ...   \n23476  McPain: John McCain Furious That Iran Treated ...   \n23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n23479  How to Blow $700 Million: Al Jazeera America F...   \n23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n\n                                                    text      subject  \\\n0      Donald Trump just couldn t wish all Americans ...         News   \n1      House Intelligence Committee Chairman Devin Nu...         News   \n2      On Friday, it was revealed that former Milwauk...         News   \n3      On Christmas day, Donald Trump announced that ...         News   \n4      Pope Francis used his annual Christmas Day mes...         News   \n...                                                  ...          ...   \n23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n\n                    date  class  \n0      December 31, 2017      0  \n1      December 31, 2017      0  \n2      December 30, 2017      0  \n3      December 29, 2017      0  \n4      December 25, 2017      0  \n...                  ...    ...  \n23476   January 16, 2016      0  \n23477   January 16, 2016      0  \n23478   January 15, 2016      0  \n23479   January 14, 2016      0  \n23480   January 12, 2016      0  \n\n[23481 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n      <td>News</td>\n      <td>December 30, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n      <td>News</td>\n      <td>December 29, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n      <td>News</td>\n      <td>December 25, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23476</th>\n      <td>McPain: John McCain Furious That Iran Treated ...</td>\n      <td>21st Century Wire says As 21WIRE reported earl...</td>\n      <td>Middle-east</td>\n      <td>January 16, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23477</th>\n      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n      <td>21st Century Wire says It s a familiar theme. ...</td>\n      <td>Middle-east</td>\n      <td>January 16, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23478</th>\n      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n      <td>Middle-east</td>\n      <td>January 15, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23479</th>\n      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n      <td>21st Century Wire says Al Jazeera America will...</td>\n      <td>Middle-east</td>\n      <td>January 14, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23480</th>\n      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n      <td>Middle-east</td>\n      <td>January 12, 2016</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23481 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:47:09.785840Z","iopub.execute_input":"2024-02-22T17:47:09.786796Z","iopub.status.idle":"2024-02-22T17:47:27.106984Z","shell.execute_reply.started":"2024-02-22T17:47:09.786760Z","shell.execute_reply":"2024-02-22T17:47:27.106112Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-02-22 17:47:12.012854: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 17:47:12.013006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 17:47:12.197799: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\n\nembed_dim = 32  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"głowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar słownika\n\ninputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(embedding_layer, embedding_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=320, validation_split=0.1, verbose=1)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:51:20.031393Z","iopub.execute_input":"2024-02-22T17:51:20.031845Z","iopub.status.idle":"2024-02-22T17:52:13.855910Z","shell.execute_reply.started":"2024-02-22T17:51:20.031814Z","shell.execute_reply":"2024-02-22T17:52:13.854884Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/10\n89/89 [==============================] - 12s 109ms/step - loss: 0.6862 - accuracy: 0.5541 - val_loss: 0.6458 - val_accuracy: 0.5409\nEpoch 2/10\n89/89 [==============================] - 7s 75ms/step - loss: 0.3276 - accuracy: 0.8975 - val_loss: 0.1515 - val_accuracy: 0.9415\nEpoch 3/10\n89/89 [==============================] - 5s 56ms/step - loss: 0.1204 - accuracy: 0.9562 - val_loss: 0.1241 - val_accuracy: 0.9513\nEpoch 4/10\n89/89 [==============================] - 5s 54ms/step - loss: 0.0924 - accuracy: 0.9679 - val_loss: 0.1092 - val_accuracy: 0.9590\nEpoch 5/10\n89/89 [==============================] - 5s 51ms/step - loss: 0.0706 - accuracy: 0.9762 - val_loss: 0.1012 - val_accuracy: 0.9640\nEpoch 6/10\n89/89 [==============================] - 5s 52ms/step - loss: 0.0566 - accuracy: 0.9812 - val_loss: 0.0977 - val_accuracy: 0.9650\nEpoch 7/10\n89/89 [==============================] - 4s 43ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 0.0946 - val_accuracy: 0.9669\nEpoch 8/10\n89/89 [==============================] - 4s 44ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 0.1006 - val_accuracy: 0.9691\nEpoch 9/10\n89/89 [==============================] - 4s 47ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.1098 - val_accuracy: 0.9701\nEpoch 10/10\n89/89 [==============================] - 5s 51ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1176 - val_accuracy: 0.9672\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7cccb046d990>"},"metadata":{}}]},{"cell_type":"markdown","source":"\n### Zadanie prostsze: Analiza fake newsów na podstawie tytułów z PositionalEncoding\n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować na podstawie tytułu. W danych mamy dostarczone tytuły artykułów oraz etykiety fake news (1) albo nie (0). \nKroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty znajdują się w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty powinny być tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przykładowo niech składa się z następujących warstw:\n\n* Warstwa wejściowa: Przyjmuje sekwencje tokenów o długości określonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentację słów jako gęstych wektorów cech.\n* Warstwa PositionalEncoding(position, embed_dim)(embedding_layer), która mapuje sekwencje na odpowiednie pozycje. \n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, który pozwala modelowi skupić się na różnych częściach sekwencji wejściowej, co jest szczególnie przydatne w przetwarzaniu języka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z różnych części sekwencji, redukując wymiarowość danych i przygotowując je do procesu klasyfikacji.\n* Warstwa Dense (wyjściowa): Z funkcją aktywacji softmax, generuje dystrybucję prawdopodobieństwa dla dwóch możliwych klas sentymentu, umożliwiając klasyfikację.\n\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcją straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metryką \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy fake newsów na podstawie tytułów. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size).\n","metadata":{}},{"cell_type":"code","source":"X = data['title'].to_numpy()\ny = data['class'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:14:42.328112Z","iopub.execute_input":"2024-02-22T18:14:42.329021Z","iopub.status.idle":"2024-02-22T18:14:42.333635Z","shell.execute_reply.started":"2024-02-22T18:14:42.328986Z","shell.execute_reply":"2024-02-22T18:14:42.332470Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\n#max_sequence_length = 10000\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:14:43.962261Z","iopub.execute_input":"2024-02-22T18:14:43.962641Z","iopub.status.idle":"2024-02-22T18:14:46.453169Z","shell.execute_reply.started":"2024-02-22T18:14:43.962611Z","shell.execute_reply":"2024-02-22T18:14:46.452126Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"max_sequence_length","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:05:06.524209Z","iopub.execute_input":"2024-02-22T18:05:06.524632Z","iopub.status.idle":"2024-02-22T18:05:06.531428Z","shell.execute_reply.started":"2024-02-22T18:05:06.524600Z","shell.execute_reply":"2024-02-22T18:05:06.530205Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"286"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Embedding, Dense, Dropout, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Input\n\nclass PositionalEncoding(Layer):\n   def __init__(self, position, d_model):\n       super(PositionalEncoding, self).__init__()\n       self.pos_encoding = self.positional_encoding(position, d_model)\n\n   def get_angles(self, position, i, d_model):\n       angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n       return position * angles\n\n   def positional_encoding(self, position, d_model):\n       angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n                                    np.arange(d_model)[np.newaxis, :],\n                                    d_model)\n       # Aplikuj sinus do indeksów parzystych w macierzy; 2i\n       angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n       # Aplikuj cosinus do indeksów nieparzystych w macierzy; 2i+1\n       angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n       pos_encoding = angle_rads[np.newaxis, ...]\n       return tf.cast(pos_encoding, dtype=tf.float32)\n\n   def call(self, inputs):\n       return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:04:45.259067Z","iopub.execute_input":"2024-02-22T18:04:45.259695Z","iopub.status.idle":"2024-02-22T18:04:45.270637Z","shell.execute_reply.started":"2024-02-22T18:04:45.259662Z","shell.execute_reply":"2024-02-22T18:04:45.269574Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nclass TokenAndPositionEmbedding(layers.Layer):\n   def __init__(self, maxlen, vocab_size, embed_dim):\n       super().__init__()\n       self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n       self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n   def call(self, x):\n       # Obliczanie długości sekwencji\n       maxlen = tf.shape(x)[-1]\n       # Generowanie pozycji dla każdego tokenu w sekwencji\n       positions = tf.range(start=0, limit=maxlen, delta=1)\n       # Uzyskanie pozycyjnego embedding\n       positions = self.pos_emb(positions)\n       # Uzyskanie tlenowego embedding\n       x = self.token_emb(x)\n       # Dodanie pozycyjnego embedding do tlenowego embedding\n       return x + positions\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:08:18.058546Z","iopub.execute_input":"2024-02-22T18:08:18.058979Z","iopub.status.idle":"2024-02-22T18:08:18.067396Z","shell.execute_reply.started":"2024-02-22T18:08:18.058938Z","shell.execute_reply":"2024-02-22T18:08:18.066296Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\n\nembed_dim = 32  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"głowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar słownika\n\ninputs = Input(shape=(max_sequence_length,))\n#embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\npositional_layer=TokenAndPositionEmbedding(max_sequence_length,vocab_size, embed_dim)(inputs),\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(positional_layer, positional_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=320, validation_split=0.1, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:09:01.846695Z","iopub.execute_input":"2024-02-22T18:09:01.847098Z","iopub.status.idle":"2024-02-22T18:09:02.008257Z","shell.execute_reply.started":"2024-02-22T18:09:01.847068Z","shell.execute_reply":"2024-02-22T18:09:02.006845Z"},"trusted":true},"execution_count":30,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m positional_layer\u001b[38;5;241m=\u001b[39mTokenAndPositionEmbedding(max_sequence_length,vocab_size, embed_dim)(inputs),\n\u001b[0;32m---> 13\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositional_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositional_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m global_average \u001b[38;5;241m=\u001b[39m GlobalAveragePooling1D()(attention_output)\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(global_average)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:220\u001b[0m, in \u001b[0;36mDimension.__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(value\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__index__\u001b[39m())\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension value must be integer or None or have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man __index__ method, got value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{1!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    223\u001b[0m           value, \u001b[38;5;28mtype\u001b[39m(value))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    225\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m must be >= 0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"multi_head_attention_8\" (type MultiHeadAttention).\n\nDimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'Placeholder:0' shape=(None, 286, 32) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.SymbolicTensor'>'\n\nCall arguments received by layer \"multi_head_attention_8\" (type MultiHeadAttention):\n  • query=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  • value=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  • key=None\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False"],"ename":"TypeError","evalue":"Exception encountered when calling layer \"multi_head_attention_8\" (type MultiHeadAttention).\n\nDimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'Placeholder:0' shape=(None, 286, 32) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.SymbolicTensor'>'\n\nCall arguments received by layer \"multi_head_attention_8\" (type MultiHeadAttention):\n  • query=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  • value=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  • key=None\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False","output_type":"error"}]},{"cell_type":"code","source":"inputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\npos_encoding = PositionalEncoding(max_sequence_length, embed_dim)(embedding_layer)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(pos_encoding, pos_encoding)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=320, validation_split=0.1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:14:57.705152Z","iopub.execute_input":"2024-02-22T18:14:57.705566Z","iopub.status.idle":"2024-02-22T18:15:49.694369Z","shell.execute_reply.started":"2024-02-22T18:14:57.705533Z","shell.execute_reply":"2024-02-22T18:15:49.691816Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/10\n89/89 [==============================] - 10s 96ms/step - loss: 0.6920 - accuracy: 0.5235 - val_loss: 0.6849 - val_accuracy: 0.9055\nEpoch 2/10\n89/89 [==============================] - 7s 81ms/step - loss: 0.2904 - accuracy: 0.9070 - val_loss: 0.1161 - val_accuracy: 0.9529\nEpoch 3/10\n89/89 [==============================] - 6s 65ms/step - loss: 0.0786 - accuracy: 0.9711 - val_loss: 0.0914 - val_accuracy: 0.9640\nEpoch 4/10\n89/89 [==============================] - 4s 49ms/step - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.1173 - val_accuracy: 0.9574\nEpoch 5/10\n89/89 [==============================] - 5s 52ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0886 - val_accuracy: 0.9685\nEpoch 6/10\n89/89 [==============================] - 4s 45ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1002 - val_accuracy: 0.9675\nEpoch 7/10\n89/89 [==============================] - 4s 42ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.1279 - val_accuracy: 0.9634\nEpoch 8/10\n89/89 [==============================] - 4s 44ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1322 - val_accuracy: 0.9647\nEpoch 9/10\n89/89 [==============================] - 4s 45ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1415 - val_accuracy: 0.9637\nEpoch 10/10\n89/89 [==============================] - 4s 43ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1576 - val_accuracy: 0.9637\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7cccb8489330>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Zadanie: Analiza 16 typów osobowości na podstawie Tweetów\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować tweety na podstawie osobowości osób piszących. W danych mamy dostarczone tweety oraz etykiety osobowości (np. INTP, ENTJ).\n\n## Kroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty tweetów znajdują się w kolumnach tweet_1, tweet_2, itp., a etykiety sentymentu w kolumnie \"sentiment\". Teksty tweetów oraz etykiety sentymentu są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty tweetów są tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Przygotuj model sieci neuronowej złożony z: \n\n* Warstwa wejściowa: Przyjmuje sekwencje tokenów o długości określonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentację słów jako gęstych wektorów cech.\n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, który pozwala modelowi skupić się na różnych częściach sekwencji wejściowej, co jest szczególnie przydatne w przetwarzaniu języka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z różnych części sekwencji, redukując wymiarowość danych i przygotowując je do procesu klasyfikacji.\n* Warstwa Dense (wyjściowa): Z funkcją aktywacji softmax, generuje dystrybucję prawdopodobieństwa dla dwóch możliwych klas sentymentu, umożliwiając klasyfikację.\n\n4. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy 16 typów osobowości na podstawie tweetów. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size), wymiar embeddingu czy rozmiar warstwy LSTM, aby dostosować model do danego zadania analizy sentymentu tekst","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv('/kaggle/input/filtered-eng-twitter/languages_eng_cleaned.csv', index_col = 0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:56:28.364289Z","iopub.execute_input":"2024-02-22T18:56:28.364681Z","iopub.status.idle":"2024-02-22T18:56:30.893491Z","shell.execute_reply.started":"2024-02-22T18:56:28.364647Z","shell.execute_reply":"2024-02-22T18:56:30.892531Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"         id                                            tweet_1  \\\n1  <NUMBER>  PLEASE VOTE, VOTE, VOTE FOR AMYBETH! thanks! i...   \n3  <NUMBER>  RT <USER>: 🤷‍♀️\\n<TAG>EXOLSelcaDay \\n<USER> <URL>   \n5  <NUMBER>  RT <USER>: The media are just feeding fear ove...   \n6  <NUMBER>  RT <USER>: Are y'all washing your hands at hom...   \n8  <NUMBER>  RT <USER>: <TAG>Supergirl really missed the ma...   \n\n                                             tweet_2  \\\n1  RT <USER>: Look at this cutie! Thank you for t...   \n3          RT <USER>: when is this from??? 😭😭😭 <URL>   \n5  RT <USER>: How my mother feels about these che...   \n6                                       <USER> <URL>   \n8  RT <USER>: Wild how most of the media response...   \n\n                                             tweet_3  \\\n1  'kelangan talaga lumipat ng bahay, pero di ka ...   \n3  RT <USER>: since we're talking about suhø, a f...   \n5  RT <USER>: I know now, as an adult, it’s my re...   \n6  <USER> not \"bun in the front\". straight to the...   \n8  RT <USER>: Let it be known that these are the ...   \n\n                                             tweet_4  \\\n1  forgiveness and justice.\\nforgiveness with jus...   \n3  I am supporting this fundraising page <URL> an...   \n5  RT <USER>: In the right now, I know that you n...   \n6  RT <USER>: Doug Collins, who has self-quaranti...   \n8  RT <USER>: The ultimate ghost Pokemon got ghos...   \n\n                                             tweet_5  \\\n1    hirap maging babae no? <TAG>PamilyaKoPagkabuwag   \n3              RT <USER>: Sun and moon outfits <URL>   \n5  RT <USER>: I grew up and still have moments of...   \n6  <USER> <USER> Imagine if she challenged you to...   \n8  RT <USER>: Dear ableds: Panic buying is not go...   \n\n                                             tweet_6  \\\n1  eh damang-dama ko yung pagod ni luz, yung pago...   \n3  <USER> that looks like porridge AND TO DRAIN I...   \n5  RT <USER>: I also never had space for my menta...   \n6                             <USER> They really do!   \n8  <USER> exactly, and corporate world is really ...   \n\n                                             tweet_7  \\\n1  oo nga no? makes you think, what's your deal-b...   \n3  RT <USER>: Au Revoir, Paris (세훈)\\n\\n👉🏻<URL>\\n\\...   \n5  RT <USER>: I grew up “tip toeing” , watching t...   \n6  <USER> Stepping that ground game up and not ha...   \n8  I would report him to HR and my employer will ...   \n\n                                             tweet_8  \\\n1  hay nako si apol timing fail talaga.\\n<TAG>Pam...   \n3  RT <USER>: this is definitely one of my fav se...   \n5    RT <USER>: Let's discuss UK Wig Makers 😭🥺 <URL>   \n6  RT <USER>: Folks should spend more time on doo...   \n8  <USER> <USER> <USER> <USER> are you guys even ...   \n\n                                             tweet_9  ...  \\\n1  RT <USER>: Halimaw si Sylvia Sanchez. In every...  ...   \n3  RT <USER>: oh to be watching the rain and list...  ...   \n5  RT <USER>: When Nicole spilled the tea about P...  ...   \n6  <USER> <USER> *The real source of the breakup ...  ...   \n8  <USER> i can stay home for a long period of ti...  ...   \n\n                                           tweet_193  \\\n1  RT <USER>: <USER> <URL> \\nIn all of these scen...   \n3                                                NaN   \n5  RT <USER>: Beyoncé's <NUMBER>/<NUMBER> video i...   \n6             <USER> being blocked is a blessing lol   \n8  oh dear, youve only got <NUMBER> followers so ...   \n\n                                           tweet_194  \\\n1  RT <USER>: Who can pinpoint the exact moment A...   \n3                                                NaN   \n5  RT <USER>: <TAG>InternationalWomensDay began o...   \n6                   <USER> <USER> it makes no sense.   \n8                               <USER> Katie McGrath   \n\n                                           tweet_195  \\\n1  RT <USER>: Dear Gilbert,\\n\\nI'm throwing the r...   \n3                                                NaN   \n5  RT <USER>: It’s fascinating how our love langu...   \n6                                           <USER> 😭   \n8  <USER> <USER> \"except like if they started hav...   \n\n                                           tweet_196  \\\n1  RT <USER>: (ANNE NATION)\\n\\nwe are everyone \\n...   \n3                                                NaN   \n5                                        Bread <URL>   \n6                                   <USER> yes <URL>   \n8  TRIED TO MAKE BANANA PANCAKE BUT IT FAILED 🙃 <...   \n\n                                           tweet_197  \\\n1  RT <USER>: (what is love)\\n\\nloving is learnin...   \n3                                                NaN   \n5                                        Queen <URL>   \n6  RT <USER>: If Bloomberg wanted to waste <NUMBE...   \n8  RT <USER>: Never going to an anime convention ...   \n\n                                           tweet_198  \\\n1  RT <USER>: This Anne Nation. \\n\\nAdded active ...   \n3                                                NaN   \n5                         And the land is dark <URL>   \n6  <USER> mugs really were saying they'd look bey...   \n8  RT <USER>: \"I'm gonna be a SOLDIER. The best o...   \n\n                                           tweet_199  \\\n1  RT <USER>: To fail means we’ve tried. To be hu...   \n3                                                NaN   \n5                              Couple days ago <URL>   \n6  Please inform all the ppl who were saying they...   \n8                                                NaN   \n\n                                           tweet_200 mbti_personality  \\\n1  <USER> hahahahahahaha! tingnan natin! mahal ko...             infp   \n3                                                NaN             infp   \n5                                                NaN             infp   \n6                                          <USER> 😭😭             infp   \n8                                                NaN             infp   \n\n  detected_language  \n1                en  \n3                en  \n5                en  \n6                en  \n8                en  \n\n[5 rows x 203 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet_1</th>\n      <th>tweet_2</th>\n      <th>tweet_3</th>\n      <th>tweet_4</th>\n      <th>tweet_5</th>\n      <th>tweet_6</th>\n      <th>tweet_7</th>\n      <th>tweet_8</th>\n      <th>tweet_9</th>\n      <th>...</th>\n      <th>tweet_193</th>\n      <th>tweet_194</th>\n      <th>tweet_195</th>\n      <th>tweet_196</th>\n      <th>tweet_197</th>\n      <th>tweet_198</th>\n      <th>tweet_199</th>\n      <th>tweet_200</th>\n      <th>mbti_personality</th>\n      <th>detected_language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>PLEASE VOTE, VOTE, VOTE FOR AMYBETH! thanks! i...</td>\n      <td>RT &lt;USER&gt;: Look at this cutie! Thank you for t...</td>\n      <td>'kelangan talaga lumipat ng bahay, pero di ka ...</td>\n      <td>forgiveness and justice.\\nforgiveness with jus...</td>\n      <td>hirap maging babae no? &lt;TAG&gt;PamilyaKoPagkabuwag</td>\n      <td>eh damang-dama ko yung pagod ni luz, yung pago...</td>\n      <td>oo nga no? makes you think, what's your deal-b...</td>\n      <td>hay nako si apol timing fail talaga.\\n&lt;TAG&gt;Pam...</td>\n      <td>RT &lt;USER&gt;: Halimaw si Sylvia Sanchez. In every...</td>\n      <td>...</td>\n      <td>RT &lt;USER&gt;: &lt;USER&gt; &lt;URL&gt; \\nIn all of these scen...</td>\n      <td>RT &lt;USER&gt;: Who can pinpoint the exact moment A...</td>\n      <td>RT &lt;USER&gt;: Dear Gilbert,\\n\\nI'm throwing the r...</td>\n      <td>RT &lt;USER&gt;: (ANNE NATION)\\n\\nwe are everyone \\n...</td>\n      <td>RT &lt;USER&gt;: (what is love)\\n\\nloving is learnin...</td>\n      <td>RT &lt;USER&gt;: This Anne Nation. \\n\\nAdded active ...</td>\n      <td>RT &lt;USER&gt;: To fail means we’ve tried. To be hu...</td>\n      <td>&lt;USER&gt; hahahahahahaha! tingnan natin! mahal ko...</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: 🤷‍♀️\\n&lt;TAG&gt;EXOLSelcaDay \\n&lt;USER&gt; &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: when is this from??? 😭😭😭 &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: since we're talking about suhø, a f...</td>\n      <td>I am supporting this fundraising page &lt;URL&gt; an...</td>\n      <td>RT &lt;USER&gt;: Sun and moon outfits &lt;URL&gt;</td>\n      <td>&lt;USER&gt; that looks like porridge AND TO DRAIN I...</td>\n      <td>RT &lt;USER&gt;: Au Revoir, Paris (세훈)\\n\\n👉🏻&lt;URL&gt;\\n\\...</td>\n      <td>RT &lt;USER&gt;: this is definitely one of my fav se...</td>\n      <td>RT &lt;USER&gt;: oh to be watching the rain and list...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: The media are just feeding fear ove...</td>\n      <td>RT &lt;USER&gt;: How my mother feels about these che...</td>\n      <td>RT &lt;USER&gt;: I know now, as an adult, it’s my re...</td>\n      <td>RT &lt;USER&gt;: In the right now, I know that you n...</td>\n      <td>RT &lt;USER&gt;: I grew up and still have moments of...</td>\n      <td>RT &lt;USER&gt;: I also never had space for my menta...</td>\n      <td>RT &lt;USER&gt;: I grew up “tip toeing” , watching t...</td>\n      <td>RT &lt;USER&gt;: Let's discuss UK Wig Makers 😭🥺 &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: When Nicole spilled the tea about P...</td>\n      <td>...</td>\n      <td>RT &lt;USER&gt;: Beyoncé's &lt;NUMBER&gt;/&lt;NUMBER&gt; video i...</td>\n      <td>RT &lt;USER&gt;: &lt;TAG&gt;InternationalWomensDay began o...</td>\n      <td>RT &lt;USER&gt;: It’s fascinating how our love langu...</td>\n      <td>Bread &lt;URL&gt;</td>\n      <td>Queen &lt;URL&gt;</td>\n      <td>And the land is dark &lt;URL&gt;</td>\n      <td>Couple days ago &lt;URL&gt;</td>\n      <td>NaN</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: Are y'all washing your hands at hom...</td>\n      <td>&lt;USER&gt; &lt;URL&gt;</td>\n      <td>&lt;USER&gt; not \"bun in the front\". straight to the...</td>\n      <td>RT &lt;USER&gt;: Doug Collins, who has self-quaranti...</td>\n      <td>&lt;USER&gt; &lt;USER&gt; Imagine if she challenged you to...</td>\n      <td>&lt;USER&gt; They really do!</td>\n      <td>&lt;USER&gt; Stepping that ground game up and not ha...</td>\n      <td>RT &lt;USER&gt;: Folks should spend more time on doo...</td>\n      <td>&lt;USER&gt; &lt;USER&gt; *The real source of the breakup ...</td>\n      <td>...</td>\n      <td>&lt;USER&gt; being blocked is a blessing lol</td>\n      <td>&lt;USER&gt; &lt;USER&gt; it makes no sense.</td>\n      <td>&lt;USER&gt; 😭</td>\n      <td>&lt;USER&gt; yes &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: If Bloomberg wanted to waste &lt;NUMBE...</td>\n      <td>&lt;USER&gt; mugs really were saying they'd look bey...</td>\n      <td>Please inform all the ppl who were saying they...</td>\n      <td>&lt;USER&gt; 😭😭</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: &lt;TAG&gt;Supergirl really missed the ma...</td>\n      <td>RT &lt;USER&gt;: Wild how most of the media response...</td>\n      <td>RT &lt;USER&gt;: Let it be known that these are the ...</td>\n      <td>RT &lt;USER&gt;: The ultimate ghost Pokemon got ghos...</td>\n      <td>RT &lt;USER&gt;: Dear ableds: Panic buying is not go...</td>\n      <td>&lt;USER&gt; exactly, and corporate world is really ...</td>\n      <td>I would report him to HR and my employer will ...</td>\n      <td>&lt;USER&gt; &lt;USER&gt; &lt;USER&gt; &lt;USER&gt; are you guys even ...</td>\n      <td>&lt;USER&gt; i can stay home for a long period of ti...</td>\n      <td>...</td>\n      <td>oh dear, youve only got &lt;NUMBER&gt; followers so ...</td>\n      <td>&lt;USER&gt; Katie McGrath</td>\n      <td>&lt;USER&gt; &lt;USER&gt; \"except like if they started hav...</td>\n      <td>TRIED TO MAKE BANANA PANCAKE BUT IT FAILED 🙃 &lt;...</td>\n      <td>RT &lt;USER&gt;: Never going to an anime convention ...</td>\n      <td>RT &lt;USER&gt;: \"I'm gonna be a SOLDIER. The best o...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 203 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# Konwersja tweetów na pojedynczy tekst dla każdego użytkownika\ndf['all_tweets'] = df.apply(lambda row: ' '.join([str(tweet) for tweet in row[1:201]]), axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:56:33.711219Z","iopub.execute_input":"2024-02-22T18:56:33.712029Z","iopub.status.idle":"2024-02-22T18:56:48.689188Z","shell.execute_reply.started":"2024-02-22T18:56:33.711994Z","shell.execute_reply":"2024-02-22T18:56:48.688169Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-02-22 18:56:35.929125: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 18:56:35.929252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 18:56:36.100248: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nimport numpy as np\n\n# Przygotowanie etykiet (MBTI)\nlabels = pd.get_dummies(df['mbti_personality']).values\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:57:00.093524Z","iopub.execute_input":"2024-02-22T18:57:00.093901Z","iopub.status.idle":"2024-02-22T18:57:00.526430Z","shell.execute_reply.started":"2024-02-22T18:57:00.093870Z","shell.execute_reply":"2024-02-22T18:57:00.525646Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X=df['all_tweets'].to_numpy()\ny=labels","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:57:02.726621Z","iopub.execute_input":"2024-02-22T18:57:02.727715Z","iopub.status.idle":"2024-02-22T18:57:02.731939Z","shell.execute_reply.started":"2024-02-22T18:57:02.727684Z","shell.execute_reply":"2024-02-22T18:57:02.730927Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = 5000\n#max_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:57:04.668267Z","iopub.execute_input":"2024-02-22T18:57:04.668611Z","iopub.status.idle":"2024-02-22T18:57:49.484863Z","shell.execute_reply.started":"2024-02-22T18:57:04.668584Z","shell.execute_reply":"2024-02-22T18:57:49.483830Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max(len(seq) for seq in X)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:34:09.681640Z","iopub.execute_input":"2024-02-22T18:34:09.683128Z","iopub.status.idle":"2024-02-22T18:34:09.695934Z","shell.execute_reply.started":"2024-02-22T18:34:09.683080Z","shell.execute_reply":"2024-02-22T18:34:09.694816Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"26634"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nembed_dim = 32  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"głowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar słownika\n\ninputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n#pos_encoding = PositionalEncoding(max_sequence_length, embed_dim)(embedding_layer)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(embedding_layer, embedding_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(16, activation='softmax')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=4, validation_split=0.1, verbose=1, validation_data=(X_val,y_val))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:59:20.877567Z","iopub.execute_input":"2024-02-22T18:59:20.878186Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1504/1504 [==============================] - 277s 183ms/step - loss: 1.8563 - accuracy: 0.0906 - val_loss: 1.7781 - val_accuracy: 0.0962\nEpoch 2/10\n1504/1504 [==============================] - 226s 150ms/step - loss: 1.8442 - accuracy: 0.1046 - val_loss: 1.8625 - val_accuracy: 0.3579\nEpoch 3/10\n1504/1504 [==============================] - 204s 136ms/step - loss: 1.9419 - accuracy: 0.1072 - val_loss: 1.9869 - val_accuracy: 0.0962\nEpoch 4/10\n 855/1504 [================>.............] - ETA: 1:13 - loss: 2.0643 - accuracy: 0.1053","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}