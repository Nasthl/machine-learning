{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7222412,"sourceType":"datasetVersion","datasetId":4180521},{"sourceId":7497252,"sourceType":"datasetVersion","datasetId":4349966}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n### Zadanie prostsze: Analiza fake news√≥w na podstawie tytu≈Ç√≥w, \n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, kt√≥ry bƒôdzie klasyfikowaƒá tweety na podstawie tytu≈Çu. W danych mamy dostarczone tytu≈Çy artyku≈Ç√≥w oraz etykiety fake news (1) albo nie (0). \nKroki, kt√≥re musisz podjƒÖƒá:\n\n1. Przygotowanie danych: Dane zosta≈Çy wczytane z pliku CSV. Teksty znajdujƒÖ siƒô w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety sƒÖ przygotowane do dalszej obr√≥bki.\n\n2. Tokenizacja tekstu: Teksty powinny byƒá tokenizowane za pomocƒÖ Tokenizer, a nastƒôpnie przekszta≈Çcane na sekwencje liczb. Jest to niezbƒôdne, aby mo≈ºna by≈Ço u≈ºywaƒá ich jako danych wej≈õciowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przyk≈Çadowo niech sk≈Çada siƒô z nastƒôpujƒÖcych warstw:\n\n* Warstwa wej≈õciowa: Przyjmuje sekwencje token√≥w o d≈Çugo≈õci okre≈õlonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentacjƒô s≈Ç√≥w jako gƒôstych wektor√≥w cech.\n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, kt√≥ry pozwala modelowi skupiƒá siƒô na r√≥≈ºnych czƒô≈õciach sekwencji wej≈õciowej, co jest szczeg√≥lnie przydatne w przetwarzaniu jƒôzyka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z r√≥≈ºnych czƒô≈õci sekwencji, redukujƒÖc wymiarowo≈õƒá danych i przygotowujƒÖc je do procesu klasyfikacji.\n* Warstwa Dense (wyj≈õciowa): Z funkcjƒÖ aktywacji softmax, generuje dystrybucjƒô prawdopodobie≈Ñstwa dla dw√≥ch mo≈ºliwych klas sentymentu, umo≈ºliwiajƒÖc klasyfikacjƒô.\n\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcjƒÖ straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metrykƒÖ \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweet√≥w przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupe≈Çnienie kodu i dostosowanie parametr√≥w modelu oraz trenowania, aby uzyskaƒá jak najlepsze wyniki w zadaniu analizy fake news√≥w na podstawie tytu≈Ç√≥w. Mo≈ºesz eksperymentowaƒá z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size).\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \n\nfake=pd.read_csv(\"/kaggle/input/fake-news-detection/fake.csv\")\ntrue=pd.read_csv(\"/kaggle/input/fake-news-detection/true.csv\")\n\nfake['class']=0\nfake.head()\n\ntrue['class']=1\ntrue.head()\n\n\ndata=pd.concat([fake,true],axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:39:47.730560Z","iopub.execute_input":"2024-02-22T17:39:47.731231Z","iopub.status.idle":"2024-02-22T17:39:49.209213Z","shell.execute_reply.started":"2024-02-22T17:39:47.731202Z","shell.execute_reply":"2024-02-22T17:39:49.208380Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X = data['title'].to_numpy()\ny = data['class'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:39:53.619505Z","iopub.execute_input":"2024-02-22T17:39:53.620108Z","iopub.status.idle":"2024-02-22T17:39:53.624879Z","shell.execute_reply.started":"2024-02-22T17:39:53.620078Z","shell.execute_reply":"2024-02-22T17:39:53.623904Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"fake\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:54:17.680907Z","iopub.execute_input":"2024-02-22T17:54:17.681334Z","iopub.status.idle":"2024-02-22T17:54:17.704176Z","shell.execute_reply.started":"2024-02-22T17:54:17.681303Z","shell.execute_reply":"2024-02-22T17:54:17.703092Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0       Donald Trump Sends Out Embarrassing New Year‚Äô...   \n1       Drunk Bragging Trump Staffer Started Russian ...   \n2       Sheriff David Clarke Becomes An Internet Joke...   \n3       Trump Is So Obsessed He Even Has Obama‚Äôs Name...   \n4       Pope Francis Just Called Out Donald Trump Dur...   \n...                                                  ...   \n23476  McPain: John McCain Furious That Iran Treated ...   \n23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n23478  Sunnistan: US and Allied ‚ÄòSafe Zone‚Äô Plan to T...   \n23479  How to Blow $700 Million: Al Jazeera America F...   \n23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n\n                                                    text      subject  \\\n0      Donald Trump just couldn t wish all Americans ...         News   \n1      House Intelligence Committee Chairman Devin Nu...         News   \n2      On Friday, it was revealed that former Milwauk...         News   \n3      On Christmas day, Donald Trump announced that ...         News   \n4      Pope Francis used his annual Christmas Day mes...         News   \n...                                                  ...          ...   \n23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n\n                    date  class  \n0      December 31, 2017      0  \n1      December 31, 2017      0  \n2      December 30, 2017      0  \n3      December 29, 2017      0  \n4      December 25, 2017      0  \n...                  ...    ...  \n23476   January 16, 2016      0  \n23477   January 16, 2016      0  \n23478   January 15, 2016      0  \n23479   January 14, 2016      0  \n23480   January 12, 2016      0  \n\n[23481 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Donald Trump Sends Out Embarrassing New Year‚Äô...</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n      <td>News</td>\n      <td>December 30, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump Is So Obsessed He Even Has Obama‚Äôs Name...</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n      <td>News</td>\n      <td>December 29, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n      <td>News</td>\n      <td>December 25, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23476</th>\n      <td>McPain: John McCain Furious That Iran Treated ...</td>\n      <td>21st Century Wire says As 21WIRE reported earl...</td>\n      <td>Middle-east</td>\n      <td>January 16, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23477</th>\n      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n      <td>21st Century Wire says It s a familiar theme. ...</td>\n      <td>Middle-east</td>\n      <td>January 16, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23478</th>\n      <td>Sunnistan: US and Allied ‚ÄòSafe Zone‚Äô Plan to T...</td>\n      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n      <td>Middle-east</td>\n      <td>January 15, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23479</th>\n      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n      <td>21st Century Wire says Al Jazeera America will...</td>\n      <td>Middle-east</td>\n      <td>January 14, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23480</th>\n      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n      <td>Middle-east</td>\n      <td>January 12, 2016</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23481 rows √ó 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:47:09.785840Z","iopub.execute_input":"2024-02-22T17:47:09.786796Z","iopub.status.idle":"2024-02-22T17:47:27.106984Z","shell.execute_reply.started":"2024-02-22T17:47:09.786760Z","shell.execute_reply":"2024-02-22T17:47:27.106112Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-02-22 17:47:12.012854: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 17:47:12.013006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 17:47:12.197799: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\n\nembed_dim = 32  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"g≈Çowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar s≈Çownika\n\ninputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(embedding_layer, embedding_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=320, validation_split=0.1, verbose=1)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T17:51:20.031393Z","iopub.execute_input":"2024-02-22T17:51:20.031845Z","iopub.status.idle":"2024-02-22T17:52:13.855910Z","shell.execute_reply.started":"2024-02-22T17:51:20.031814Z","shell.execute_reply":"2024-02-22T17:52:13.854884Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/10\n89/89 [==============================] - 12s 109ms/step - loss: 0.6862 - accuracy: 0.5541 - val_loss: 0.6458 - val_accuracy: 0.5409\nEpoch 2/10\n89/89 [==============================] - 7s 75ms/step - loss: 0.3276 - accuracy: 0.8975 - val_loss: 0.1515 - val_accuracy: 0.9415\nEpoch 3/10\n89/89 [==============================] - 5s 56ms/step - loss: 0.1204 - accuracy: 0.9562 - val_loss: 0.1241 - val_accuracy: 0.9513\nEpoch 4/10\n89/89 [==============================] - 5s 54ms/step - loss: 0.0924 - accuracy: 0.9679 - val_loss: 0.1092 - val_accuracy: 0.9590\nEpoch 5/10\n89/89 [==============================] - 5s 51ms/step - loss: 0.0706 - accuracy: 0.9762 - val_loss: 0.1012 - val_accuracy: 0.9640\nEpoch 6/10\n89/89 [==============================] - 5s 52ms/step - loss: 0.0566 - accuracy: 0.9812 - val_loss: 0.0977 - val_accuracy: 0.9650\nEpoch 7/10\n89/89 [==============================] - 4s 43ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 0.0946 - val_accuracy: 0.9669\nEpoch 8/10\n89/89 [==============================] - 4s 44ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 0.1006 - val_accuracy: 0.9691\nEpoch 9/10\n89/89 [==============================] - 4s 47ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.1098 - val_accuracy: 0.9701\nEpoch 10/10\n89/89 [==============================] - 5s 51ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1176 - val_accuracy: 0.9672\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7cccb046d990>"},"metadata":{}}]},{"cell_type":"markdown","source":"\n### Zadanie prostsze: Analiza fake news√≥w na podstawie tytu≈Ç√≥w z PositionalEncoding\n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, kt√≥ry bƒôdzie klasyfikowaƒá na podstawie tytu≈Çu. W danych mamy dostarczone tytu≈Çy artyku≈Ç√≥w oraz etykiety fake news (1) albo nie (0). \nKroki, kt√≥re musisz podjƒÖƒá:\n\n1. Przygotowanie danych: Dane zosta≈Çy wczytane z pliku CSV. Teksty znajdujƒÖ siƒô w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety sƒÖ przygotowane do dalszej obr√≥bki.\n\n2. Tokenizacja tekstu: Teksty powinny byƒá tokenizowane za pomocƒÖ Tokenizer, a nastƒôpnie przekszta≈Çcane na sekwencje liczb. Jest to niezbƒôdne, aby mo≈ºna by≈Ço u≈ºywaƒá ich jako danych wej≈õciowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przyk≈Çadowo niech sk≈Çada siƒô z nastƒôpujƒÖcych warstw:\n\n* Warstwa wej≈õciowa: Przyjmuje sekwencje token√≥w o d≈Çugo≈õci okre≈õlonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentacjƒô s≈Ç√≥w jako gƒôstych wektor√≥w cech.\n* Warstwa PositionalEncoding(position, embed_dim)(embedding_layer), kt√≥ra mapuje sekwencje na odpowiednie pozycje. \n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, kt√≥ry pozwala modelowi skupiƒá siƒô na r√≥≈ºnych czƒô≈õciach sekwencji wej≈õciowej, co jest szczeg√≥lnie przydatne w przetwarzaniu jƒôzyka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z r√≥≈ºnych czƒô≈õci sekwencji, redukujƒÖc wymiarowo≈õƒá danych i przygotowujƒÖc je do procesu klasyfikacji.\n* Warstwa Dense (wyj≈õciowa): Z funkcjƒÖ aktywacji softmax, generuje dystrybucjƒô prawdopodobie≈Ñstwa dla dw√≥ch mo≈ºliwych klas sentymentu, umo≈ºliwiajƒÖc klasyfikacjƒô.\n\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcjƒÖ straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metrykƒÖ \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweet√≥w przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupe≈Çnienie kodu i dostosowanie parametr√≥w modelu oraz trenowania, aby uzyskaƒá jak najlepsze wyniki w zadaniu analizy fake news√≥w na podstawie tytu≈Ç√≥w. Mo≈ºesz eksperymentowaƒá z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size).\n","metadata":{}},{"cell_type":"code","source":"X = data['title'].to_numpy()\ny = data['class'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:14:42.328112Z","iopub.execute_input":"2024-02-22T18:14:42.329021Z","iopub.status.idle":"2024-02-22T18:14:42.333635Z","shell.execute_reply.started":"2024-02-22T18:14:42.328986Z","shell.execute_reply":"2024-02-22T18:14:42.332470Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\n#max_sequence_length = 10000\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:14:43.962261Z","iopub.execute_input":"2024-02-22T18:14:43.962641Z","iopub.status.idle":"2024-02-22T18:14:46.453169Z","shell.execute_reply.started":"2024-02-22T18:14:43.962611Z","shell.execute_reply":"2024-02-22T18:14:46.452126Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"max_sequence_length","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:05:06.524209Z","iopub.execute_input":"2024-02-22T18:05:06.524632Z","iopub.status.idle":"2024-02-22T18:05:06.531428Z","shell.execute_reply.started":"2024-02-22T18:05:06.524600Z","shell.execute_reply":"2024-02-22T18:05:06.530205Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"286"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Embedding, Dense, Dropout, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Input\n\nclass PositionalEncoding(Layer):\n   def __init__(self, position, d_model):\n       super(PositionalEncoding, self).__init__()\n       self.pos_encoding = self.positional_encoding(position, d_model)\n\n   def get_angles(self, position, i, d_model):\n       angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n       return position * angles\n\n   def positional_encoding(self, position, d_model):\n       angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n                                    np.arange(d_model)[np.newaxis, :],\n                                    d_model)\n       # Aplikuj sinus do indeks√≥w parzystych w macierzy; 2i\n       angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n       # Aplikuj cosinus do indeks√≥w nieparzystych w macierzy; 2i+1\n       angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n       pos_encoding = angle_rads[np.newaxis, ...]\n       return tf.cast(pos_encoding, dtype=tf.float32)\n\n   def call(self, inputs):\n       return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:04:45.259067Z","iopub.execute_input":"2024-02-22T18:04:45.259695Z","iopub.status.idle":"2024-02-22T18:04:45.270637Z","shell.execute_reply.started":"2024-02-22T18:04:45.259662Z","shell.execute_reply":"2024-02-22T18:04:45.269574Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nclass TokenAndPositionEmbedding(layers.Layer):\n   def __init__(self, maxlen, vocab_size, embed_dim):\n       super().__init__()\n       self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n       self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n   def call(self, x):\n       # Obliczanie d≈Çugo≈õci sekwencji\n       maxlen = tf.shape(x)[-1]\n       # Generowanie pozycji dla ka≈ºdego tokenu w sekwencji\n       positions = tf.range(start=0, limit=maxlen, delta=1)\n       # Uzyskanie pozycyjnego embedding\n       positions = self.pos_emb(positions)\n       # Uzyskanie tlenowego embedding\n       x = self.token_emb(x)\n       # Dodanie pozycyjnego embedding do tlenowego embedding\n       return x + positions\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:08:18.058546Z","iopub.execute_input":"2024-02-22T18:08:18.058979Z","iopub.status.idle":"2024-02-22T18:08:18.067396Z","shell.execute_reply.started":"2024-02-22T18:08:18.058938Z","shell.execute_reply":"2024-02-22T18:08:18.066296Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\n\nembed_dim = 32  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"g≈Çowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar s≈Çownika\n\ninputs = Input(shape=(max_sequence_length,))\n#embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\npositional_layer=TokenAndPositionEmbedding(max_sequence_length,vocab_size, embed_dim)(inputs),\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(positional_layer, positional_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=320, validation_split=0.1, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:09:01.846695Z","iopub.execute_input":"2024-02-22T18:09:01.847098Z","iopub.status.idle":"2024-02-22T18:09:02.008257Z","shell.execute_reply.started":"2024-02-22T18:09:01.847068Z","shell.execute_reply":"2024-02-22T18:09:02.006845Z"},"trusted":true},"execution_count":30,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m positional_layer\u001b[38;5;241m=\u001b[39mTokenAndPositionEmbedding(max_sequence_length,vocab_size, embed_dim)(inputs),\n\u001b[0;32m---> 13\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositional_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositional_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m global_average \u001b[38;5;241m=\u001b[39m GlobalAveragePooling1D()(attention_output)\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(global_average)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:220\u001b[0m, in \u001b[0;36mDimension.__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(value\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__index__\u001b[39m())\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension value must be integer or None or have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man __index__ method, got value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{1!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    223\u001b[0m           value, \u001b[38;5;28mtype\u001b[39m(value))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    225\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m must be >= 0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"multi_head_attention_8\" (type MultiHeadAttention).\n\nDimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'Placeholder:0' shape=(None, 286, 32) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.SymbolicTensor'>'\n\nCall arguments received by layer \"multi_head_attention_8\" (type MultiHeadAttention):\n  ‚Ä¢ query=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  ‚Ä¢ value=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  ‚Ä¢ key=None\n  ‚Ä¢ attention_mask=None\n  ‚Ä¢ return_attention_scores=False\n  ‚Ä¢ training=None\n  ‚Ä¢ use_causal_mask=False"],"ename":"TypeError","evalue":"Exception encountered when calling layer \"multi_head_attention_8\" (type MultiHeadAttention).\n\nDimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'Placeholder:0' shape=(None, 286, 32) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.SymbolicTensor'>'\n\nCall arguments received by layer \"multi_head_attention_8\" (type MultiHeadAttention):\n  ‚Ä¢ query=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  ‚Ä¢ value=('tf.Tensor(shape=(None, 286, 32), dtype=float32)',)\n  ‚Ä¢ key=None\n  ‚Ä¢ attention_mask=None\n  ‚Ä¢ return_attention_scores=False\n  ‚Ä¢ training=None\n  ‚Ä¢ use_causal_mask=False","output_type":"error"}]},{"cell_type":"code","source":"inputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\npos_encoding = PositionalEncoding(max_sequence_length, embed_dim)(embedding_layer)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(pos_encoding, pos_encoding)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=320, validation_split=0.1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:14:57.705152Z","iopub.execute_input":"2024-02-22T18:14:57.705566Z","iopub.status.idle":"2024-02-22T18:15:49.694369Z","shell.execute_reply.started":"2024-02-22T18:14:57.705533Z","shell.execute_reply":"2024-02-22T18:15:49.691816Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/10\n89/89 [==============================] - 10s 96ms/step - loss: 0.6920 - accuracy: 0.5235 - val_loss: 0.6849 - val_accuracy: 0.9055\nEpoch 2/10\n89/89 [==============================] - 7s 81ms/step - loss: 0.2904 - accuracy: 0.9070 - val_loss: 0.1161 - val_accuracy: 0.9529\nEpoch 3/10\n89/89 [==============================] - 6s 65ms/step - loss: 0.0786 - accuracy: 0.9711 - val_loss: 0.0914 - val_accuracy: 0.9640\nEpoch 4/10\n89/89 [==============================] - 4s 49ms/step - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.1173 - val_accuracy: 0.9574\nEpoch 5/10\n89/89 [==============================] - 5s 52ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0886 - val_accuracy: 0.9685\nEpoch 6/10\n89/89 [==============================] - 4s 45ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1002 - val_accuracy: 0.9675\nEpoch 7/10\n89/89 [==============================] - 4s 42ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.1279 - val_accuracy: 0.9634\nEpoch 8/10\n89/89 [==============================] - 4s 44ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1322 - val_accuracy: 0.9647\nEpoch 9/10\n89/89 [==============================] - 4s 45ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1415 - val_accuracy: 0.9637\nEpoch 10/10\n89/89 [==============================] - 4s 43ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1576 - val_accuracy: 0.9637\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7cccb8489330>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Zadanie: Analiza 16 typ√≥w osobowo≈õci na podstawie Tweet√≥w\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, kt√≥ry bƒôdzie klasyfikowaƒá tweety na podstawie osobowo≈õci os√≥b piszƒÖcych. W danych mamy dostarczone tweety oraz etykiety osobowo≈õci (np. INTP, ENTJ).\n\n## Kroki, kt√≥re musisz podjƒÖƒá:\n\n1. Przygotowanie danych: Dane zosta≈Çy wczytane z pliku CSV. Teksty tweet√≥w znajdujƒÖ siƒô w kolumnach tweet_1, tweet_2, itp., a etykiety sentymentu w kolumnie \"sentiment\". Teksty tweet√≥w oraz etykiety sentymentu sƒÖ przygotowane do dalszej obr√≥bki.\n\n2. Tokenizacja tekstu: Teksty tweet√≥w sƒÖ tokenizowane za pomocƒÖ Tokenizer, a nastƒôpnie przekszta≈Çcane na sekwencje liczb. Jest to niezbƒôdne, aby mo≈ºna by≈Ço u≈ºywaƒá ich jako danych wej≈õciowych do modelu sieci neuronowej.\n\n3. Przygotuj model sieci neuronowej z≈Ço≈ºony z: \n\n* Warstwa wej≈õciowa: Przyjmuje sekwencje token√≥w o d≈Çugo≈õci okre≈õlonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentacjƒô s≈Ç√≥w jako gƒôstych wektor√≥w cech.\n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, kt√≥ry pozwala modelowi skupiƒá siƒô na r√≥≈ºnych czƒô≈õciach sekwencji wej≈õciowej, co jest szczeg√≥lnie przydatne w przetwarzaniu jƒôzyka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z r√≥≈ºnych czƒô≈õci sekwencji, redukujƒÖc wymiarowo≈õƒá danych i przygotowujƒÖc je do procesu klasyfikacji.\n* Warstwa Dense (wyj≈õciowa): Z funkcjƒÖ aktywacji softmax, generuje dystrybucjƒô prawdopodobie≈Ñstwa dla dw√≥ch mo≈ºliwych klas sentymentu, umo≈ºliwiajƒÖc klasyfikacjƒô.\n\n4. Trenowanie modelu: Model jest trenowany na danych tweet√≥w przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupe≈Çnienie kodu i dostosowanie parametr√≥w modelu oraz trenowania, aby uzyskaƒá jak najlepsze wyniki w zadaniu analizy 16 typ√≥w osobowo≈õci na podstawie tweet√≥w. Mo≈ºesz eksperymentowaƒá z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size), wymiar embeddingu czy rozmiar warstwy LSTM, aby dostosowaƒá model do danego zadania analizy sentymentu tekst","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv('/kaggle/input/filtered-eng-twitter/languages_eng_cleaned.csv', index_col = 0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:56:28.364289Z","iopub.execute_input":"2024-02-22T18:56:28.364681Z","iopub.status.idle":"2024-02-22T18:56:30.893491Z","shell.execute_reply.started":"2024-02-22T18:56:28.364647Z","shell.execute_reply":"2024-02-22T18:56:30.892531Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"         id                                            tweet_1  \\\n1  <NUMBER>  PLEASE VOTE, VOTE, VOTE FOR AMYBETH! thanks! i...   \n3  <NUMBER>  RT <USER>: ü§∑‚Äç‚ôÄÔ∏è\\n<TAG>EXOLSelcaDay \\n<USER> <URL>   \n5  <NUMBER>  RT <USER>: The media are just feeding fear ove...   \n6  <NUMBER>  RT <USER>: Are y'all washing your hands at hom...   \n8  <NUMBER>  RT <USER>: <TAG>Supergirl really missed the ma...   \n\n                                             tweet_2  \\\n1  RT <USER>: Look at this cutie! Thank you for t...   \n3          RT <USER>: when is this from??? üò≠üò≠üò≠ <URL>   \n5  RT <USER>: How my mother feels about these che...   \n6                                       <USER> <URL>   \n8  RT <USER>: Wild how most of the media response...   \n\n                                             tweet_3  \\\n1  'kelangan talaga lumipat ng bahay, pero di ka ...   \n3  RT <USER>: since we're talking about suh√∏, a f...   \n5  RT <USER>: I know now, as an adult, it‚Äôs my re...   \n6  <USER> not \"bun in the front\". straight to the...   \n8  RT <USER>: Let it be known that these are the ...   \n\n                                             tweet_4  \\\n1  forgiveness and justice.\\nforgiveness with jus...   \n3  I am supporting this fundraising page <URL> an...   \n5  RT <USER>: In the right now, I know that you n...   \n6  RT <USER>: Doug Collins, who has self-quaranti...   \n8  RT <USER>: The ultimate ghost Pokemon got ghos...   \n\n                                             tweet_5  \\\n1    hirap maging babae no? <TAG>PamilyaKoPagkabuwag   \n3              RT <USER>: Sun and moon outfits <URL>   \n5  RT <USER>: I grew up and still have moments of...   \n6  <USER> <USER> Imagine if she challenged you to...   \n8  RT <USER>: Dear ableds: Panic buying is not go...   \n\n                                             tweet_6  \\\n1  eh damang-dama ko yung pagod ni luz, yung pago...   \n3  <USER> that looks like porridge AND TO DRAIN I...   \n5  RT <USER>: I also never had space for my menta...   \n6                             <USER> They really do!   \n8  <USER> exactly, and corporate world is really ...   \n\n                                             tweet_7  \\\n1  oo nga no? makes you think, what's your deal-b...   \n3  RT <USER>: Au Revoir, Paris (ÏÑ∏Ìõà)\\n\\nüëâüèª<URL>\\n\\...   \n5  RT <USER>: I grew up ‚Äútip toeing‚Äù , watching t...   \n6  <USER> Stepping that ground game up and not ha...   \n8  I would report him to HR and my employer will ...   \n\n                                             tweet_8  \\\n1  hay nako si apol timing fail talaga.\\n<TAG>Pam...   \n3  RT <USER>: this is definitely one of my fav se...   \n5    RT <USER>: Let's discuss UK Wig Makers üò≠ü•∫ <URL>   \n6  RT <USER>: Folks should spend more time on doo...   \n8  <USER> <USER> <USER> <USER> are you guys even ...   \n\n                                             tweet_9  ...  \\\n1  RT <USER>: Halimaw si Sylvia Sanchez. In every...  ...   \n3  RT <USER>: oh to be watching the rain and list...  ...   \n5  RT <USER>: When Nicole spilled the tea about P...  ...   \n6  <USER> <USER> *The real source of the breakup ...  ...   \n8  <USER> i can stay home for a long period of ti...  ...   \n\n                                           tweet_193  \\\n1  RT <USER>: <USER> <URL> \\nIn all of these scen...   \n3                                                NaN   \n5  RT <USER>: Beyonc√©'s <NUMBER>/<NUMBER> video i...   \n6             <USER> being blocked is a blessing lol   \n8  oh dear, youve only got <NUMBER> followers so ...   \n\n                                           tweet_194  \\\n1  RT <USER>: Who can pinpoint the exact moment A...   \n3                                                NaN   \n5  RT <USER>: <TAG>InternationalWomensDay began o...   \n6                   <USER> <USER> it makes no sense.   \n8                               <USER> Katie McGrath   \n\n                                           tweet_195  \\\n1  RT <USER>: Dear Gilbert,\\n\\nI'm throwing the r...   \n3                                                NaN   \n5  RT <USER>: It‚Äôs fascinating how our love langu...   \n6                                           <USER> üò≠   \n8  <USER> <USER> \"except like if they started hav...   \n\n                                           tweet_196  \\\n1  RT <USER>: (ANNE NATION)\\n\\nwe are everyone \\n...   \n3                                                NaN   \n5                                        Bread <URL>   \n6                                   <USER> yes <URL>   \n8  TRIED TO MAKE BANANA PANCAKE BUT IT FAILED üôÉ <...   \n\n                                           tweet_197  \\\n1  RT <USER>: (what is love)\\n\\nloving is learnin...   \n3                                                NaN   \n5                                        Queen <URL>   \n6  RT <USER>: If Bloomberg wanted to waste <NUMBE...   \n8  RT <USER>: Never going to an anime convention ...   \n\n                                           tweet_198  \\\n1  RT <USER>: This Anne Nation. \\n\\nAdded active ...   \n3                                                NaN   \n5                         And the land is dark <URL>   \n6  <USER> mugs really were saying they'd look bey...   \n8  RT <USER>: \"I'm gonna be a SOLDIER. The best o...   \n\n                                           tweet_199  \\\n1  RT <USER>: To fail means we‚Äôve tried. To be hu...   \n3                                                NaN   \n5                              Couple days ago <URL>   \n6  Please inform all the ppl who were saying they...   \n8                                                NaN   \n\n                                           tweet_200 mbti_personality  \\\n1  <USER> hahahahahahaha! tingnan natin! mahal ko...             infp   \n3                                                NaN             infp   \n5                                                NaN             infp   \n6                                          <USER> üò≠üò≠             infp   \n8                                                NaN             infp   \n\n  detected_language  \n1                en  \n3                en  \n5                en  \n6                en  \n8                en  \n\n[5 rows x 203 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet_1</th>\n      <th>tweet_2</th>\n      <th>tweet_3</th>\n      <th>tweet_4</th>\n      <th>tweet_5</th>\n      <th>tweet_6</th>\n      <th>tweet_7</th>\n      <th>tweet_8</th>\n      <th>tweet_9</th>\n      <th>...</th>\n      <th>tweet_193</th>\n      <th>tweet_194</th>\n      <th>tweet_195</th>\n      <th>tweet_196</th>\n      <th>tweet_197</th>\n      <th>tweet_198</th>\n      <th>tweet_199</th>\n      <th>tweet_200</th>\n      <th>mbti_personality</th>\n      <th>detected_language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>PLEASE VOTE, VOTE, VOTE FOR AMYBETH! thanks! i...</td>\n      <td>RT &lt;USER&gt;: Look at this cutie! Thank you for t...</td>\n      <td>'kelangan talaga lumipat ng bahay, pero di ka ...</td>\n      <td>forgiveness and justice.\\nforgiveness with jus...</td>\n      <td>hirap maging babae no? &lt;TAG&gt;PamilyaKoPagkabuwag</td>\n      <td>eh damang-dama ko yung pagod ni luz, yung pago...</td>\n      <td>oo nga no? makes you think, what's your deal-b...</td>\n      <td>hay nako si apol timing fail talaga.\\n&lt;TAG&gt;Pam...</td>\n      <td>RT &lt;USER&gt;: Halimaw si Sylvia Sanchez. In every...</td>\n      <td>...</td>\n      <td>RT &lt;USER&gt;: &lt;USER&gt; &lt;URL&gt; \\nIn all of these scen...</td>\n      <td>RT &lt;USER&gt;: Who can pinpoint the exact moment A...</td>\n      <td>RT &lt;USER&gt;: Dear Gilbert,\\n\\nI'm throwing the r...</td>\n      <td>RT &lt;USER&gt;: (ANNE NATION)\\n\\nwe are everyone \\n...</td>\n      <td>RT &lt;USER&gt;: (what is love)\\n\\nloving is learnin...</td>\n      <td>RT &lt;USER&gt;: This Anne Nation. \\n\\nAdded active ...</td>\n      <td>RT &lt;USER&gt;: To fail means we‚Äôve tried. To be hu...</td>\n      <td>&lt;USER&gt; hahahahahahaha! tingnan natin! mahal ko...</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: ü§∑‚Äç‚ôÄÔ∏è\\n&lt;TAG&gt;EXOLSelcaDay \\n&lt;USER&gt; &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: when is this from??? üò≠üò≠üò≠ &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: since we're talking about suh√∏, a f...</td>\n      <td>I am supporting this fundraising page &lt;URL&gt; an...</td>\n      <td>RT &lt;USER&gt;: Sun and moon outfits &lt;URL&gt;</td>\n      <td>&lt;USER&gt; that looks like porridge AND TO DRAIN I...</td>\n      <td>RT &lt;USER&gt;: Au Revoir, Paris (ÏÑ∏Ìõà)\\n\\nüëâüèª&lt;URL&gt;\\n\\...</td>\n      <td>RT &lt;USER&gt;: this is definitely one of my fav se...</td>\n      <td>RT &lt;USER&gt;: oh to be watching the rain and list...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: The media are just feeding fear ove...</td>\n      <td>RT &lt;USER&gt;: How my mother feels about these che...</td>\n      <td>RT &lt;USER&gt;: I know now, as an adult, it‚Äôs my re...</td>\n      <td>RT &lt;USER&gt;: In the right now, I know that you n...</td>\n      <td>RT &lt;USER&gt;: I grew up and still have moments of...</td>\n      <td>RT &lt;USER&gt;: I also never had space for my menta...</td>\n      <td>RT &lt;USER&gt;: I grew up ‚Äútip toeing‚Äù , watching t...</td>\n      <td>RT &lt;USER&gt;: Let's discuss UK Wig Makers üò≠ü•∫ &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: When Nicole spilled the tea about P...</td>\n      <td>...</td>\n      <td>RT &lt;USER&gt;: Beyonc√©'s &lt;NUMBER&gt;/&lt;NUMBER&gt; video i...</td>\n      <td>RT &lt;USER&gt;: &lt;TAG&gt;InternationalWomensDay began o...</td>\n      <td>RT &lt;USER&gt;: It‚Äôs fascinating how our love langu...</td>\n      <td>Bread &lt;URL&gt;</td>\n      <td>Queen &lt;URL&gt;</td>\n      <td>And the land is dark &lt;URL&gt;</td>\n      <td>Couple days ago &lt;URL&gt;</td>\n      <td>NaN</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: Are y'all washing your hands at hom...</td>\n      <td>&lt;USER&gt; &lt;URL&gt;</td>\n      <td>&lt;USER&gt; not \"bun in the front\". straight to the...</td>\n      <td>RT &lt;USER&gt;: Doug Collins, who has self-quaranti...</td>\n      <td>&lt;USER&gt; &lt;USER&gt; Imagine if she challenged you to...</td>\n      <td>&lt;USER&gt; They really do!</td>\n      <td>&lt;USER&gt; Stepping that ground game up and not ha...</td>\n      <td>RT &lt;USER&gt;: Folks should spend more time on doo...</td>\n      <td>&lt;USER&gt; &lt;USER&gt; *The real source of the breakup ...</td>\n      <td>...</td>\n      <td>&lt;USER&gt; being blocked is a blessing lol</td>\n      <td>&lt;USER&gt; &lt;USER&gt; it makes no sense.</td>\n      <td>&lt;USER&gt; üò≠</td>\n      <td>&lt;USER&gt; yes &lt;URL&gt;</td>\n      <td>RT &lt;USER&gt;: If Bloomberg wanted to waste &lt;NUMBE...</td>\n      <td>&lt;USER&gt; mugs really were saying they'd look bey...</td>\n      <td>Please inform all the ppl who were saying they...</td>\n      <td>&lt;USER&gt; üò≠üò≠</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;NUMBER&gt;</td>\n      <td>RT &lt;USER&gt;: &lt;TAG&gt;Supergirl really missed the ma...</td>\n      <td>RT &lt;USER&gt;: Wild how most of the media response...</td>\n      <td>RT &lt;USER&gt;: Let it be known that these are the ...</td>\n      <td>RT &lt;USER&gt;: The ultimate ghost Pokemon got ghos...</td>\n      <td>RT &lt;USER&gt;: Dear ableds: Panic buying is not go...</td>\n      <td>&lt;USER&gt; exactly, and corporate world is really ...</td>\n      <td>I would report him to HR and my employer will ...</td>\n      <td>&lt;USER&gt; &lt;USER&gt; &lt;USER&gt; &lt;USER&gt; are you guys even ...</td>\n      <td>&lt;USER&gt; i can stay home for a long period of ti...</td>\n      <td>...</td>\n      <td>oh dear, youve only got &lt;NUMBER&gt; followers so ...</td>\n      <td>&lt;USER&gt; Katie McGrath</td>\n      <td>&lt;USER&gt; &lt;USER&gt; \"except like if they started hav...</td>\n      <td>TRIED TO MAKE BANANA PANCAKE BUT IT FAILED üôÉ &lt;...</td>\n      <td>RT &lt;USER&gt;: Never going to an anime convention ...</td>\n      <td>RT &lt;USER&gt;: \"I'm gonna be a SOLDIER. The best o...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>infp</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 203 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# Konwersja tweet√≥w na pojedynczy tekst dla ka≈ºdego u≈ºytkownika\ndf['all_tweets'] = df.apply(lambda row: ' '.join([str(tweet) for tweet in row[1:201]]), axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:56:33.711219Z","iopub.execute_input":"2024-02-22T18:56:33.712029Z","iopub.status.idle":"2024-02-22T18:56:48.689188Z","shell.execute_reply.started":"2024-02-22T18:56:33.711994Z","shell.execute_reply":"2024-02-22T18:56:48.688169Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-02-22 18:56:35.929125: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 18:56:35.929252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 18:56:36.100248: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nimport numpy as np\n\n# Przygotowanie etykiet (MBTI)\nlabels = pd.get_dummies(df['mbti_personality']).values\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:57:00.093524Z","iopub.execute_input":"2024-02-22T18:57:00.093901Z","iopub.status.idle":"2024-02-22T18:57:00.526430Z","shell.execute_reply.started":"2024-02-22T18:57:00.093870Z","shell.execute_reply":"2024-02-22T18:57:00.525646Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X=df['all_tweets'].to_numpy()\ny=labels","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:57:02.726621Z","iopub.execute_input":"2024-02-22T18:57:02.727715Z","iopub.status.idle":"2024-02-22T18:57:02.731939Z","shell.execute_reply.started":"2024-02-22T18:57:02.727684Z","shell.execute_reply":"2024-02-22T18:57:02.730927Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = 5000\n#max_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:57:04.668267Z","iopub.execute_input":"2024-02-22T18:57:04.668611Z","iopub.status.idle":"2024-02-22T18:57:49.484863Z","shell.execute_reply.started":"2024-02-22T18:57:04.668584Z","shell.execute_reply":"2024-02-22T18:57:49.483830Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max(len(seq) for seq in X)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:34:09.681640Z","iopub.execute_input":"2024-02-22T18:34:09.683128Z","iopub.status.idle":"2024-02-22T18:34:09.695934Z","shell.execute_reply.started":"2024-02-22T18:34:09.683080Z","shell.execute_reply":"2024-02-22T18:34:09.694816Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"26634"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nembed_dim = 32  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"g≈Çowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar s≈Çownika\n\ninputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n#pos_encoding = PositionalEncoding(max_sequence_length, embed_dim)(embedding_layer)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(embedding_layer, embedding_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\noutputs = Dense(16, activation='softmax')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=4, validation_split=0.1, verbose=1, validation_data=(X_val,y_val))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T18:59:20.877567Z","iopub.execute_input":"2024-02-22T18:59:20.878186Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1504/1504 [==============================] - 277s 183ms/step - loss: 1.8563 - accuracy: 0.0906 - val_loss: 1.7781 - val_accuracy: 0.0962\nEpoch 2/10\n1504/1504 [==============================] - 226s 150ms/step - loss: 1.8442 - accuracy: 0.1046 - val_loss: 1.8625 - val_accuracy: 0.3579\nEpoch 3/10\n1504/1504 [==============================] - 204s 136ms/step - loss: 1.9419 - accuracy: 0.1072 - val_loss: 1.9869 - val_accuracy: 0.0962\nEpoch 4/10\n 855/1504 [================>.............] - ETA: 1:13 - loss: 2.0643 - accuracy: 0.1053","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}