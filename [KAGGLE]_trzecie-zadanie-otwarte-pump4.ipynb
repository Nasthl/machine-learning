{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6191570,"sourceType":"datasetVersion","datasetId":3553967},{"sourceId":6203280,"sourceType":"datasetVersion","datasetId":3561611},{"sourceId":6235877,"sourceType":"datasetVersion","datasetId":3582369}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Rotated spiral w Kerasie\nW ramach tego zadania, Twoim zadaniem jest przygotowanie algorytmu klasyfikacji opartego na sieci neuronowej. Podpowiedzia w odpowiednim doborze algorytmu jest zadanie poprzednie. Wskazówką do architektury modelu może być https://playground.tensorflow.org/.\n\n\nAby zrealizować to zadanie, wykonaj poniższe kroki:\n\n1. Wygeneruj zbiór danych do klasyfikacji. Kod jest przygotowany powyżej.\n\n2. Podziel zbiór danych na zbiór treningowy i testowy przy użyciu funkcji `train_test_split` z biblioteki `sklearn.model_selection`. \n\n3. Zakoduj etykiety klas przy użyciu kodowania \"one-hot\" za pomocą klasy `OneHotEncoder` z biblioteki `sklearn.preprocessing`. Przekształć etykiety treningowe i testowe na postać \"one-hot\".\n\n4. Stwórz model sieci neuronowej wykorzystującej `Sequential` z biblioteki `tensorflow.keras.models`. Dodaj warstwę gęstą (`Dense`) z dwoma wyjściami i aktywacją softmaxową.\n\n5. Skompiluj model, używając jako funkcji straty `categorical_crossentropy` i jako optymalizatora `Adam`, dobierz `learning rate`. Dodaj również metrykę `accuracy` do oceny wydajności modelu.\n\n6. Trenuj model na zbiorze treningowym przez określoną liczbę epok, używając funkcji `fit`. Ustal rozmiar partii (batch size) i opcjonalnie możesz dodać podział walidacyjny (`validation_split`), aby monitorować wydajność modelu na zbiorze walidacyjnym.\n\n7. Ewaluuj model na zbiorze testowym przy użyciu funkcji `evaluate` i oblicz wartości straty (`loss`) oraz dokładności (`accuracy`).\n\n8. Wyżej jest zdefiniowana funkcja plot_decision_boundary(model, X, y), która wyświetli granice decyzyjne modelu na wykresie. Funkcja ta przyjmuje trzy argumenty: model (wytrenowany model sieci neuronowej), X (zbiór danych wejściowych) i y (etykiety klas). Funkcja wygneruej siatkę punktów na podstawie zakresu danych wejściowych $X$, a następnie przewidzi etykiety dla każdego punktu na siatce przy użyciu modelu. Na koniec, funkcja powinna narysować wykres, na którym punkty danych są kolorowane na podstawie ich rzeczywistych etykiet klas, a granice decyzyjne są wizualizowane jako kontury lub tło z różnymi kolorami dla różnych klas.\n\n\nWykonując te kroki, będziesz miał przygotowany algorytm klasyfikacji oparty na sieci neuronowej. Pamiętaj o dostosowaniu parametrów oraz optymalizacji modelu, aby uzyskać jak najlepsze wyniki klasyfikacji.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/spiral-playgorund/spiral.csv', index_col=0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:12.276028Z","iopub.execute_input":"2024-02-07T19:17:12.277765Z","iopub.status.idle":"2024-02-07T19:17:12.327374Z","shell.execute_reply.started":"2024-02-07T19:17:12.277711Z","shell.execute_reply":"2024-02-07T19:17:12.326024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\ndef plot_decision_boundary(model, X, y):\n    # Przygotowanie siatki punktów w zakresie danych wejściowych\n    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n    h = 0.01\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    grid_points = np.c_[xx.ravel(), yy.ravel()]\n\n    # Wykonanie predykcji dla siatki punktów\n    y_pred = model.predict(grid_points)\n\n    # Przekształcenie wyników predykcji do pierwotnego kształtu siatki\n    # Wykonanie predykcji dla siatki punktów\n    y_pred = model.predict(grid_points)\n    y_pred = np.argmax(y_pred, axis=1)\n\n    # Przekształcenie wyników predykcji do pierwotnego kształtu siatki\n    y_pred = y_pred.reshape(xx.shape)\n\n    # Wyświetlenie wykresu z liniami decyzyjnymi\n    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Paired)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n    plt.xlabel('X_1')\n    plt.ylabel('X_2')\n    plt.title('Decision Boundary')\n    plt.show()\n\nn_samples = 500\nn_classes = 2\nnoise = 0.1\nangle = 45","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:12.330130Z","iopub.execute_input":"2024-02-07T19:17:12.330589Z","iopub.status.idle":"2024-02-07T19:17:12.364702Z","shell.execute_reply.started":"2024-02-07T19:17:12.330543Z","shell.execute_reply":"2024-02-07T19:17:12.363052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \n\nX = df[['X1', 'X2']].to_numpy()\ny = df['y'].to_numpy()\n\nplt.figure(figsize=(6, 6))\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\nplt.title('Rotated Spiral')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:12.366613Z","iopub.execute_input":"2024-02-07T19:17:12.367947Z","iopub.status.idle":"2024-02-07T19:17:12.739540Z","shell.execute_reply.started":"2024-02-07T19:17:12.367897Z","shell.execute_reply":"2024-02-07T19:17:12.738538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Wygeneruj zbiór danych do klasyfikacji. Kod jest przygotowany powyżej.\n","metadata":{}},{"cell_type":"markdown","source":"2. Podziel zbiór danych na zbiór treningowy i testowy przy użyciu funkcji `train_test_split` z biblioteki `sklearn.model_selection`. \n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:12.740788Z","iopub.execute_input":"2024-02-07T19:17:12.741201Z","iopub.status.idle":"2024-02-07T19:17:12.748847Z","shell.execute_reply.started":"2024-02-07T19:17:12.741163Z","shell.execute_reply":"2024-02-07T19:17:12.747848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Zakoduj etykiety klas przy użyciu kodowania \"one-hot\" za pomocą klasy `OneHotEncoder` z biblioteki `sklearn.preprocessing`. Przekształć etykiety treningowe i testowe na postać \"one-hot\".\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nencoder=OneHotEncoder()\ny_train_one_hot = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\ny_test_one_hot = encoder.transform(y_test.reshape(-1, 1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:12.751707Z","iopub.execute_input":"2024-02-07T19:17:12.752192Z","iopub.status.idle":"2024-02-07T19:17:12.764584Z","shell.execute_reply.started":"2024-02-07T19:17:12.752154Z","shell.execute_reply":"2024-02-07T19:17:12.763433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Stwórz model sieci neuronowej wykorzystującej `Sequential` z biblioteki `tensorflow.keras.models`. Dodaj warstwę gęstą (`Dense`) z dwoma wyjściami i aktywacją softmaxową.\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2024-02-04T10:05:11.346684Z","iopub.execute_input":"2024-02-04T10:05:11.347079Z","iopub.status.idle":"2024-02-04T10:05:11.360891Z","shell.execute_reply.started":"2024-02-04T10:05:11.347039Z","shell.execute_reply":"2024-02-04T10:05:11.359991Z"}}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel=Sequential()\nmodel.add(Dense(30,input_dim=2,activation='relu'))\nmodel.add(Dense(2,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:12.766541Z","iopub.execute_input":"2024-02-07T19:17:12.767205Z","iopub.status.idle":"2024-02-07T19:17:13.275925Z","shell.execute_reply.started":"2024-02-07T19:17:12.767172Z","shell.execute_reply":"2024-02-07T19:17:13.274720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Skompiluj model, używając jako funkcji straty `categorical_crossentropy` i jako optymalizatora `Adam`, dobierz `learning rate`. Dodaj również metrykę `accuracy` do oceny wydajności modelu.\n\n","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.1), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:13.281397Z","iopub.execute_input":"2024-02-07T19:17:13.282772Z","iopub.status.idle":"2024-02-07T19:17:13.294925Z","shell.execute_reply.started":"2024-02-07T19:17:13.282731Z","shell.execute_reply":"2024-02-07T19:17:13.293559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Trenuj model na zbiorze treningowym przez określoną liczbę epok, używając funkcji `fit`. Ustal rozmiar partii (batch size) i opcjonalnie możesz dodać podział walidacyjny (`validation_split`), aby monitorować wydajność modelu na zbiorze walidacyjnym.\n\n","metadata":{}},{"cell_type":"code","source":"model.fit(X_train,y_train_one_hot, batch_size=32, validation_split=0.2,epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:13.296512Z","iopub.execute_input":"2024-02-07T19:17:13.296975Z","iopub.status.idle":"2024-02-07T19:17:21.351200Z","shell.execute_reply.started":"2024-02-07T19:17:13.296945Z","shell.execute_reply":"2024-02-07T19:17:21.350007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Ewaluuj model na zbiorze testowym przy użyciu funkcji `evaluate` i oblicz wartości straty (`loss`) oraz dokładności (`accuracy`).\n\n","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test,y_test_one_hot)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:21.353261Z","iopub.execute_input":"2024-02-07T19:17:21.353736Z","iopub.status.idle":"2024-02-07T19:17:21.586110Z","shell.execute_reply.started":"2024-02-07T19:17:21.353695Z","shell.execute_reply":"2024-02-07T19:17:21.584837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. Wyżej jest zdefiniowana funkcja plot_decision_boundary(model, X, y), która wyświetli granice decyzyjne modelu na wykresie. Funkcja ta przyjmuje trzy argumenty: model (wytrenowany model sieci neuronowej), X (zbiór danych wejściowych) i y (etykiety klas). Funkcja wygneruej siatkę punktów na podstawie zakresu danych wejściowych $X$, a następnie przewidzi etykiety dla każdego punktu na siatce przy użyciu modelu. Na koniec, funkcja powinna narysować wykres, na którym punkty danych są kolorowane na podstawie ich rzeczywistych etykiet klas, a granice decyzyjne są wizualizowane jako kontury lub tło z różnymi kolorami dla różnych klas.","metadata":{}},{"cell_type":"code","source":"plot_decision_boundary(model, X, y)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:21.587771Z","iopub.execute_input":"2024-02-07T19:17:21.588247Z","iopub.status.idle":"2024-02-07T19:17:39.319597Z","shell.execute_reply.started":"2024-02-07T19:17:21.588206Z","shell.execute_reply":"2024-02-07T19:17:39.318580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Zadanie: Klasyfikacja danych z MNIST 100 za pomocą prostego modelu MLP\n\nOpiszemy zadanie klasyfikacji danych z MNIST 100, wykorzystując prosty model wielowarstwowy perceptronów (Multilayer Perceptron - MLP). Zadanie polega na przewidzeniu kategorii dla obrazów z zestawu danych MNIST. Zbiór danych MNIST 100 zawiera 60 000 obrazów treningowych i 10 000 obrazów testowych, z podziałem na 10 kategorii odzieżowych.\n\n1. Wczytaj zbiór danych MNIST przy użyciu biblioteki numpy.\n\n2. Przygotuj zbiór danych na zestawy treningowy i testowy odpowiednio go standaryzując.\n\n3. Przekształć dane obrazów do postaci wektorowej (spłaszcz), aby były kompatybilne z modelem MLP. Możesz użyć metody `reshape` z biblioteki NumPy.\n\n4. Przeprowadź normalizację danych, skalując wartości pikseli do zakresu od 0 do 1. Możesz to zrobić, dzieląc wartości przez 255.\n\n5. Zakoduj etykiety klas przy użyciu kodowania \"one-hot\" za pomocą funkcji `to_categorical` z biblioteki `tensorflow.keras.utils`.\n\n6. Zdefiniuj prosty model MLP, używając klasy `Sequential` z biblioteki `tensorflow.keras.models`. Dodaj kilka warstw gęstych (`Dense`) z aktywacją ReLU. Możesz eksperymentować z różnymi liczbami neuronów i warstwami.\n\n7. Skompiluj model, wybierając odpowiednią funkcję straty i optymalizator. Dla problemu klasyfikacji wieloklasowej, użyj funkcji straty `categorical_crossentropy` oraz optymalizatora `adam`. Dodaj również metrykę `accuracy`, aby monitorować wydajność modelu.\n\n8. Trenuj model na zestawie treningowym za pomocą funkcji `fit`. Wybierz odpowiednią liczbę epok i rozmiar partii (batch size). Możesz także dodać podział walidacyjny (`validation_split`), aby monitorować wydajność modelu na zestawie walidacyjnym.\n\n9. Ewaluuj model na zestawie testowym przy użyciu funkcji `evaluate` i oblicz wartości straty oraz dokładności.\n\n10. Przeprowadź predykcję dla kilku obrazów ze zbioru testowego za pomocą funkcji `predict` i wyświetl wyniki.\n\n11. Dodatkowo, możesz narysować kilka przykładowych obrazów z ich prawdziwymi etykietami i przewidywanymi etykietami, aby zobaczyć jak dobrze model radzi sobie z klasyfikacją.\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Wczytaj zbiór danych MNIST przy użyciu biblioteki `tensorflow.keras.datasets.fashion_mnist`.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Loading data from the 'mnist_compressed.npz' file\ndata = np.load('/kaggle/input/mnist100/mnist_compressed.npz')\n\n# Reading variables containing the data\nX_test, y_test, X_train, y_train =  data['test_images'], data['test_labels'], data['train_images'], data['train_labels']","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:39.321120Z","iopub.execute_input":"2024-02-07T19:17:39.321914Z","iopub.status.idle":"2024-02-07T19:17:40.337778Z","shell.execute_reply.started":"2024-02-07T19:17:39.321877Z","shell.execute_reply":"2024-02-07T19:17:40.336547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndata['test_images'].shape\nplt.imshow(data['test_images'][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:17:40.339633Z","iopub.execute_input":"2024-02-07T19:17:40.340108Z","iopub.status.idle":"2024-02-07T19:17:40.811383Z","shell.execute_reply.started":"2024-02-07T19:17:40.340065Z","shell.execute_reply":"2024-02-07T19:17:40.809948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Przygotuj zbiór danych na zestawy treningowy i testowy odpowiednio go standaryzując.\n\n","metadata":{}},{"cell_type":"code","source":"pip install numpy==1.22.0","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-07T19:21:43.644793Z","iopub.execute_input":"2024-02-07T19:21:43.645550Z","iopub.status.idle":"2024-02-07T19:22:02.907326Z","shell.execute_reply.started":"2024-02-07T19:21:43.645516Z","shell.execute_reply":"2024-02-07T19:22:02.906142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX_test_flattened=X_test.reshape(X_test.shape[0],-1)\nX_train_flattened=X_train.reshape(X_train.shape[0],-1)\nX_train_scaled=scaler.fit_transform(X_train_flattened)\nX_test_scaled=scaler.transform(X_test_flattened)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:03.891063Z","iopub.execute_input":"2024-02-07T19:18:03.891542Z","iopub.status.idle":"2024-02-07T19:18:05.040484Z","shell.execute_reply.started":"2024-02-07T19:18:03.891502Z","shell.execute_reply":"2024-02-07T19:18:05.039066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Przekształć dane obrazów do postaci wektorowej (spłaszcz), aby były kompatybilne z modelem MLP. Możesz użyć metody `reshape` z biblioteki NumPy.\n\n","metadata":{}},{"cell_type":"code","source":"X_train.min()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:05.042141Z","iopub.execute_input":"2024-02-07T19:18:05.042526Z","iopub.status.idle":"2024-02-07T19:18:05.059801Z","shell.execute_reply.started":"2024-02-07T19:18:05.042495Z","shell.execute_reply":"2024-02-07T19:18:05.058481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.min()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:05.060909Z","iopub.execute_input":"2024-02-07T19:18:05.061248Z","iopub.status.idle":"2024-02-07T19:18:05.070880Z","shell.execute_reply.started":"2024-02-07T19:18:05.061219Z","shell.execute_reply":"2024-02-07T19:18:05.069505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Przeprowadź normalizację danych, skalując wartości pikseli do zakresu od 0 do 1. Możesz to zrobić, dzieląc wartości przez 255.\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Zakoduj etykiety klas przy użyciu kodowania \"one-hot\" za pomocą funkcji `to_categorical` z biblioteki `tensorflow.keras.utils`.\n\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_train_one_hot=to_categorical(y_train)\ny_test_one_hot=to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:05.072492Z","iopub.execute_input":"2024-02-07T19:18:05.072874Z","iopub.status.idle":"2024-02-07T19:18:05.100964Z","shell.execute_reply.started":"2024-02-07T19:18:05.072841Z","shell.execute_reply":"2024-02-07T19:18:05.099574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Zdefiniuj prosty model MLP, używając klasy `Sequential` z biblioteki `tensorflow.keras.models`. Dodaj kilka warstw gęstych (`Dense`) z aktywacją ReLU. Możesz eksperymentować z różnymi liczbami neuronów i warstwami.\n\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom keras.layers import Dense,Dropout\n\nmodel=Sequential()\nmodel.add(Dense(100,input_dim=28*28*2,activation='relu'))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(100,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:05.102949Z","iopub.execute_input":"2024-02-07T19:18:05.103302Z","iopub.status.idle":"2024-02-07T19:18:05.202620Z","shell.execute_reply.started":"2024-02-07T19:18:05.103273Z","shell.execute_reply":"2024-02-07T19:18:05.201333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Skompiluj model, wybierając odpowiednią funkcję straty i optymalizator. Dla problemu klasyfikacji wieloklasowej, użyj funkcji straty `categorical_crossentropy` oraz optymalizatora `adam`. Dodaj również metrykę `accuracy`, aby monitorować wydajność modelu.\n\n","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:05.204389Z","iopub.execute_input":"2024-02-07T19:18:05.204778Z","iopub.status.idle":"2024-02-07T19:18:05.219317Z","shell.execute_reply.started":"2024-02-07T19:18:05.204747Z","shell.execute_reply":"2024-02-07T19:18:05.218095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. Trenuj model na zestawie treningowym za pomocą funkcji `fit`. Wybierz odpowiednią liczbę epok i rozmiar partii (batch size). Możesz także dodać podział walidacyjny (`validation_split`), aby monitorować wydajność modelu na zestawie walidacyjnym.\n\n","metadata":{}},{"cell_type":"code","source":"model.fit(X_train_scaled,y_train_one_hot, batch_size=512, validation_split=0.2,epochs=30)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:05.220735Z","iopub.execute_input":"2024-02-07T19:18:05.221311Z","iopub.status.idle":"2024-02-07T19:18:51.902605Z","shell.execute_reply.started":"2024-02-07T19:18:05.221263Z","shell.execute_reply":"2024-02-07T19:18:51.901636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"9. Ewaluuj model na zestawie testowym przy użyciu funkcji `evaluate` i oblicz wartości straty oraz dokładności.\n\n","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test_scaled,y_test_one_hot)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:51.904309Z","iopub.execute_input":"2024-02-07T19:18:51.905039Z","iopub.status.idle":"2024-02-07T19:18:53.339766Z","shell.execute_reply.started":"2024-02-07T19:18:51.905005Z","shell.execute_reply":"2024-02-07T19:18:53.338602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"10. Przeprowadź predykcję dla kilku obrazów ze zbioru testowego za pomocą funkcji `predict` i wyświetl wyniki.\n\n","metadata":{}},{"cell_type":"code","source":"predictions=model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:53.341175Z","iopub.execute_input":"2024-02-07T19:18:53.341542Z","iopub.status.idle":"2024-02-07T19:18:54.251621Z","shell.execute_reply.started":"2024-02-07T19:18:53.341513Z","shell.execute_reply":"2024-02-07T19:18:54.250352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11. Dodatkowo, możesz narysować kilka przykładowych obrazów z ich prawdziwymi etykietami i przewidywanymi etykietami, aby zobaczyć jak dobrze model radzi sobie z klasyfikacją.","metadata":{}},{"cell_type":"code","source":"for i in range(100):\n    if np.argmax(predictions[i])!= y_test[i]:\n        plt.imshow(X_test[i], cmap='gray')\n        plt.title(f'Przewidywana etykieta: {np.argmax(predictions[i])}, poprawna {y_test[i]}')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:18:54.253312Z","iopub.execute_input":"2024-02-07T19:18:54.253708Z","iopub.status.idle":"2024-02-07T19:18:56.579522Z","shell.execute_reply.started":"2024-02-07T19:18:54.253673Z","shell.execute_reply":"2024-02-07T19:18:56.578356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Zadanie - Klasyfikacja - overfiting:\nStwórz sieć konwolucyjną do klasyfikacji obrazków ze zbioru CIFAR-100. Wykorzystaj bibliotekę Keras do zbudowania modelu. Zbadaj wpływ różnych architektur sieci, takich jak liczba warstw konwolucyjnych, liczba filtrów, rozmiar filtrów, użyte funkcje aktywacji oraz techniki regularyzacji (np. Dropout), na skuteczność klasyfikacji. Przeprowadź eksperymenty i porównaj wyniki różnych konfiguracji sieci.","metadata":{}},{"cell_type":"markdown","source":"Zbiór danych CIFAR-100 to popularny zbiór danych do uczenia maszynowego, używany do zadania klasyfikacji obrazów. Zbiór składa się z 60 000 kolorowych obrazów o rozmiarze 32x32 piksele, podzielonych na 50 000 przykładów treningowych i 10 000 przykładów testowych.\n\nCIFAR-100 różni się od innego znanego zbioru danych, CIFAR-10, tym że zawiera 100 różnych klas obiektów, zamiast 10. Każda klasa zawiera 600 obrazów, przy czym 500 przykładów należy do zbioru treningowego, a 100 do zbioru testowego.\n\nW przypadku CIFAR-100, kategorie obiektów są bardziej zróżnicowane i skomplikowane niż w CIFAR-10. Zawiera on różne obiekty z różnych kategorii, takie jak zwierzęta, pojazdy, rośliny, instrumenty muzyczne itp.\n","metadata":{}},{"cell_type":"code","source":"from keras.datasets import cifar100\nfrom keras.utils import to_categorical\n\n# Załaduj dane\n(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n\n# Przekształć wektor klas na macierz binarną\ny_train = to_categorical(y_train, num_classes=100)\ny_test = to_categorical(y_test, num_classes=100)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:22:08.843861Z","iopub.execute_input":"2024-02-07T19:22:08.844228Z","iopub.status.idle":"2024-02-07T19:22:09.608572Z","shell.execute_reply.started":"2024-02-07T19:22:08.844196Z","shell.execute_reply":"2024-02-07T19:22:09.607424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.datasets import cifar100\n# example of loading the cifar100 dataset\nfrom matplotlib import pyplot\n\n# load dataset\n# summarize loaded dataset\nprint('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tpyplot.imshow(X_train[i])\n# show the figure\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:22:12.175096Z","iopub.execute_input":"2024-02-07T19:22:12.175853Z","iopub.status.idle":"2024-02-07T19:22:13.073912Z","shell.execute_reply.started":"2024-02-07T19:22:12.175823Z","shell.execute_reply":"2024-02-07T19:22:13.072997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizuj dane wejściowe\nX_train = X_train.astype('float32') / 255\nX_test = X_test.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:22:15.564893Z","iopub.execute_input":"2024-02-07T19:22:15.565697Z","iopub.status.idle":"2024-02-07T19:22:15.835246Z","shell.execute_reply.started":"2024-02-07T19:22:15.565660Z","shell.execute_reply":"2024-02-07T19:22:15.833870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n\n# Definicja modelu sieci\nmodel = Sequential()\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(256, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(1024, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(100, activation='softmax'))\n\n\n# Kompilacja modelu\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Trenowanie modelu\nhistory = model.fit(X_train, y_train, epochs=200, batch_size=256,\n                    validation_split=0.1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:22:19.332136Z","iopub.execute_input":"2024-02-07T19:22:19.332512Z","iopub.status.idle":"2024-02-07T20:23:55.965790Z","shell.execute_reply.started":"2024-02-07T19:22:19.332483Z","shell.execute_reply":"2024-02-07T20:23:55.964876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:24:45.140151Z","iopub.execute_input":"2024-02-07T20:24:45.140908Z","iopub.status.idle":"2024-02-07T20:24:47.809780Z","shell.execute_reply.started":"2024-02-07T20:24:45.140878Z","shell.execute_reply":"2024-02-07T20:24:47.808720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Konwolucja 1D - Przewidywanie cen akcji firmy przy użyciu modelu regresji z siecią konwolucyjną 1D\n\n","metadata":{}},{"cell_type":"markdown","source":"Opis zbioru danych dla notowań spółki PKN Orlen:\n\nNazwa: Notowania Spółki PKN Orlen\nOpis: Zbiór danych zawierający notowania finansowe spółki PKN Orlen, jednego z największych przedsiębiorstw naftowych w Polsce. Dane obejmują cotygodniowe notowania na giełdzie, reprezentując różne cechy związane z cenami akcji spółki w określonych okresach.\n\nKolumny:\n1. Data (Date): Data notowania.\n2. Otwarcie (Open): Cena otwarcia akcji spółki PKN Orlen w danym tygodniu.\n3. Najwyższy (High): Najwyższa cena akcji osiągnięta w danym tygodniu.\n4. Najniższy (Low): Najniższa cena akcji osiągnięta w danym tygodniu.\n5. Zamknięcie (Close): Cena zamknięcia akcji spółki PKN Orlen w danym tygodniu.\n6. Zmiana (Change): Różnica między ceną zamknięcia a ceną otwarcia akcji spółki PKN Orlen w danym tygodniu.\n7. Wolumen (Volume): Wolumen handlu, czyli liczba akcji spółki PKN Orlen kupionych lub sprzedanych w danym tygodniu.\n\nTen zbiór danych może być używany do analizy trendów cenowych, wykrywania zmian w cenach akcji, czy budowy modeli prognozujących zachowanie notowań spółki PKN Orlen na giełdzie. Odpowiednie analizy i modele mogą dostarczyć cennych informacji inwestorom, analitykom i decydentom finansowym zainteresowanym tym rynkiem.\n\n0. Wczytaj zbiór danych PKN Orlen przy użyciu biblioteki pandas.\n0. Przygotuj wizualizacje wykresem liniowym. \n1. Zbadaj wpływ różnych architektur sieci, takich jak liczba warstw rekurencyjnych, liczba neuronów w warstwach, funkcje aktywacji oraz techniki regularyzacji (np. Dropout), na jakość prognoz.\n2. Przeprowadź eksperymenty i porównaj wyniki różnych konfiguracji sieci.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wizualizacja zbioru ","metadata":{}},{"cell_type":"markdown","source":"0. Wczytaj zbiór danych PKN Orlen przy użyciu biblioteki pandas.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# importowanie potrzebnych bibliotek\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\n# Wczytanie danych\ndf = pd.read_csv('/kaggle/input/orlen-dataset/pkn_d.csv')\n\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:24:53.939431Z","iopub.execute_input":"2024-02-07T20:24:53.939792Z","iopub.status.idle":"2024-02-07T20:24:54.463246Z","shell.execute_reply.started":"2024-02-07T20:24:53.939764Z","shell.execute_reply":"2024-02-07T20:24:54.462320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0. Przygotuj wizualizacje wykresem liniowym. \n","metadata":{}},{"cell_type":"code","source":"data = df[['Data', 'Otwarcie']]\n# Normalizacja danych\nfrom sklearn.preprocessing import MinMaxScaler\n\ndata = data.drop(columns=['Data'])\nscaler = MinMaxScaler()\ndata = scaler.fit_transform(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:25:00.656188Z","iopub.execute_input":"2024-02-07T20:25:00.657049Z","iopub.status.idle":"2024-02-07T20:25:00.672674Z","shell.execute_reply.started":"2024-02-07T20:25:00.657016Z","shell.execute_reply":"2024-02-07T20:25:00.671722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(df.index, df['Otwarcie'])\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.title('Orlen Price Over Time')\nplt.xticks(rotation=45)  # Obrót etykiet osi X, aby były bardziej czytelne\nplt.grid(True)          # Dodanie siatki na wykresie (opcjonalne)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:25:02.859918Z","iopub.execute_input":"2024-02-07T20:25:02.860285Z","iopub.status.idle":"2024-02-07T20:25:03.069383Z","shell.execute_reply.started":"2024-02-07T20:25:02.860253Z","shell.execute_reply":"2024-02-07T20:25:03.068524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Zbadaj wpływ różnych architektur sieci, takich jak liczba warstw rekurencyjnych, liczba neuronów w warstwach, funkcje aktywacji oraz techniki regularyzacji (np. Dropout), na jakość prognoz.\n","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:20:32.923389Z","iopub.status.idle":"2024-02-07T19:20:32.924644Z","shell.execute_reply.started":"2024-02-07T19:20:32.924311Z","shell.execute_reply":"2024-02-07T19:20:32.924340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Zbadaj wpływ różnych architektur sieci, takich jak liczba warstw rekurencyjnych, liczba neuronów w warstwach, funkcje aktywacji oraz techniki regularyzacji (np. Dropout), na jakość prognoz.","metadata":{}},{"cell_type":"code","source":"# Podział danych na zestawy treningowe i testowe\ntrain_size = int(len(data) * 0.8)\ntrain_data, test_data = data[:train_size], data[train_size:]\n\n\n# Zmniejszenie wymiarowości danych\nwindow_size = 12\n\ndef create_dataset(X, y, time_steps=1):\n    Xs, ys = [], []\n    for i in range(X.shape[0] - time_steps):\n        Xs.append(X[i:(i+time_steps)])\n        ys.append(y[i+time_steps])\n    return np.array(Xs), np.array(ys)\n\n\nX_train, y_train = create_dataset(train_data, train_data, window_size)\nX_test, y_test = create_dataset(test_data, test_data, window_size)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:25:06.759439Z","iopub.execute_input":"2024-02-07T20:25:06.760042Z","iopub.status.idle":"2024-02-07T20:25:06.782507Z","shell.execute_reply.started":"2024-02-07T20:25:06.760014Z","shell.execute_reply":"2024-02-07T20:25:06.781729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nmodel=Sequential()\nmodel.add(Conv1D(filters=2, kernel_size=1, activation='relu', input_shape=(window_size,1)))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=Adam(learning_rate=0.01), loss='mse',metrics='mse')\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=500, verbose=1)\n\ny_pred = model.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"MSE: {mse}\")\n\n\nplt.plot(y_test, label='Rzeczywiste')\nplt.plot(y_pred, label='Prognozy')\nplt.grid(True)          # Dodanie siatki na wykresie (opcjonalne)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:25:54.970284Z","iopub.execute_input":"2024-02-07T20:25:54.970688Z","iopub.status.idle":"2024-02-07T20:25:56.153612Z","shell.execute_reply.started":"2024-02-07T20:25:54.970659Z","shell.execute_reply":"2024-02-07T20:25:56.152793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"#filters 2, kernel_size 1 daje wg mnie najlepsze wyniki, gdyż usuwa także szum danych i pozwala na uzyskanie wykresu z bardziej widoczną linią trendu","metadata":{}},{"cell_type":"markdown","source":"3. Przeprowadź eksperymenty i porównaj wyniki różnych konfiguracji sieci.","metadata":{}}]}