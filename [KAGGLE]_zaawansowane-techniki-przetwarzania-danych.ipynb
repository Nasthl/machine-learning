{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777},{"sourceId":3205803,"sourceType":"datasetVersion","datasetId":1918992},{"sourceId":6293021,"sourceType":"datasetVersion","datasetId":3619394}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-08T16:53:44.901105Z","iopub.execute_input":"2024-02-08T16:53:44.901501Z","iopub.status.idle":"2024-02-08T16:53:54.596088Z","shell.execute_reply.started":"2024-02-08T16:53:44.901469Z","shell.execute_reply":"2024-02-08T16:53:54.594869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dokładnia detekcja cyfr z obrazków","metadata":{}},{"cell_type":"markdown","source":"\n### Zadanie: Klasyfikacja i Regresja w Detekcji Obiektów\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej do detekcji obiektów, który łączy w sobie zarówno zadania klasyfikacji, jak i regresji. Zaprojektowana sieć będzie przyjmować obrazy o wymiarach `(input_size, input_size, 1)` i wykonywać następujące operacje:\n\n1. **Ekstrakcja cech**: Zaimplementowana funkcja `build_feature_extractor(inputs)` przyjmuje obrazy jako wejście i przeprowadza ekstrakcję cech, wykorzystując warstwy konwolucyjne i warstwy max-pooling.\n\n2. **Model Adaptor**: Funkcja `build_model_adaptor(inputs)` przyjmuje wyekstrahowane cechy i przekształca je na jednowymiarowy wektor za pomocą warstw `Flatten` i `Dense`.\n\n3. **Klasyfikacja**: Funkcja `build_classifier_head(inputs)` przyjmuje wyjście z modelu adaptora i dokonuje klasyfikacji na określoną liczbę klas (parametr `n_classes`) za pomocą warstwy `Dense` i funkcji aktywacji softmax.\n\n4. **Regresja**: Funkcja `build_regressor_head(inputs)` również przyjmuje wyjście z modelu adaptora, ale w tym przypadku przewiduje wartości numeryczne, wykorzystując warstwę `Dense` bez funkcji aktywacji.\n\n5. Trening: Wytrenuj model na danych z datasetu mnist-for-object detection. \n\nTwoim zadaniem jest zaimplementować funkcję `build_object_detection_model(inputs)`, która złoży te części razem w jednym modelu. Model ten będzie miał dwie główne gałęzie wyjściowe: jedna do klasyfikacji obiektów i druga do regresji. Należy także dostosować proces uczenia, określić optymalizator, funkcje straty i metryki.\n\nPo zdefiniowaniu modelu, użyj funkcji `model.compile` do kompilacji modelu z odpowiednimi parametrami.\n\nPodsumowując, Twoje zadanie polega na zaimplementowaniu funkcji `build_object_detection_model(inputs)` i przystosowaniu modelu do jednoczesnej klasyfikacji i regresji w zadaniu detekcji obiektów.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Loading data from the 'mnist_compressed.npz' file\ndata = np.load('/kaggle/input/mnist-for-object-detection/mnist_object.npz')\n\n# Reading variables containing the data\nX_train, y_train, y_train_bboxes =  data['train_images'], data['train_labels'], data['train_bboxes']\nX_test, y_test, y_test_bboxes  = data['test_images'], data['test_labels'], data['test_bboxes']","metadata":{"execution":{"iopub.status.busy":"2024-02-08T16:55:47.273038Z","iopub.execute_input":"2024-02-08T16:55:47.273701Z","iopub.status.idle":"2024-02-08T16:55:47.763756Z","shell.execute_reply.started":"2024-02-08T16:55:47.273662Z","shell.execute_reply":"2024-02-08T16:55:47.762220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Set up the subplot\nfig, axes = plt.subplots(1, 5, figsize=(15, 3))\n\nfor i in range(5):\n    image = X_test[i]\n\n    # Plot the image and bounding box on the current subplot\n    axes[i].imshow(image, cmap='gray')\n    axes[i].plot([y_test_bboxes[i, 0], y_test_bboxes[i, 1]], [y_test_bboxes[i, 2], y_test_bboxes[i, 2]], 'r-')\n    axes[i].plot([y_test_bboxes[i, 0], y_test_bboxes[i, 1]], [y_test_bboxes[i, 3], y_test_bboxes[i, 3]], 'r-')\n    axes[i].plot([y_test_bboxes[i, 0], y_test_bboxes[i, 0]], [y_test_bboxes[i, 2], y_test_bboxes[i, 3]], 'r-')\n    axes[i].plot([y_test_bboxes[i, 1], y_test_bboxes[i, 1]], [y_test_bboxes[i, 2], y_test_bboxes[i, 3]], 'r-')\n    axes[i].set_title(f\"Sample Image {i+1}\")\n\n# Adjust layout for better spacing\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T16:55:56.679776Z","iopub.execute_input":"2024-02-08T16:55:56.680205Z","iopub.status.idle":"2024-02-08T16:55:57.990940Z","shell.execute_reply.started":"2024-02-08T16:55:56.680174Z","shell.execute_reply":"2024-02-08T16:55:57.989770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\nnum_classes = 10 # Assuming there are 10 classes (digits from 0 to 9)\ny_train = to_categorical(y_train, num_classes)\nX_train = np.expand_dims(X_train, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T16:57:03.590728Z","iopub.execute_input":"2024-02-08T16:57:03.591236Z","iopub.status.idle":"2024-02-08T16:57:13.890422Z","shell.execute_reply.started":"2024-02-08T16:57:03.591198Z","shell.execute_reply":"2024-02-08T16:57:13.888977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_feature_extractor(inputs):\n    layer = Conv2D(8, kernel_size=3, activation='relu', input_shape=(input_size, input_size, 1))(inputs)\n    layer = MaxPooling2D(2, 2)(layer)\n\n    layer = Conv2D(32, kernel_size=3, activation='relu')(layer)\n    layer = MaxPooling2D(2, 2)(layer)\n\n    layer = Conv2D(64, kernel_size=3, activation='relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = MaxPooling2D(2, 2)(layer)\n    return layer\n\ndef build_model_adaptor(inputs):\n    layer = Flatten()(inputs)\n    layer = Dense(128, activation='relu')(layer)\n    layer = Dense(64, activation='relu')(layer)\n    return layer\n\n\ndef build_classifier_head(inputs):\n    return Dense(n_classes, activation='softmax', name='classifier_head')(inputs)\n\ndef build_regressor_head(inputs):\n    return Dense(units=4, name='regressor_head')(inputs)\n\ndef build_object_detection_model(inputs):\n    feature_extractor = build_feature_extractor(inputs)\n\n    model_adaptor = build_model_adaptor(feature_extractor)\n    classification_head = build_classifier_head(model_adaptor)\n    regressor_head = build_regressor_head(model_adaptor)\n\n    model = Model(inputs=inputs, outputs=[classification_head, regressor_head])\n\n    model.compile(\n    optimizer=Adam(learning_rate=0.01),\n    loss={'classifier_head': 'categorical_crossentropy', 'regressor_head': 'mse'},\n    metrics={'classifier_head': 'accuracy', 'regressor_head': 'mse'}\n    )\n\n    return model\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:14:37.411734Z","iopub.execute_input":"2024-02-08T17:14:37.412677Z","iopub.status.idle":"2024-02-08T17:14:37.426499Z","shell.execute_reply.started":"2024-02-08T17:14:37.412630Z","shell.execute_reply":"2024-02-08T17:14:37.425258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#todo model 2 głowicowy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input\ninput_size=28\nn_classes=10\nmodel=build_object_detection_model(Input(shape=(input_size, input_size,1)))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:14:43.405213Z","iopub.execute_input":"2024-02-08T17:14:43.405645Z","iopub.status.idle":"2024-02-08T17:14:43.581313Z","shell.execute_reply.started":"2024-02-08T17:14:43.405613Z","shell.execute_reply":"2024-02-08T17:14:43.579746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, [y_train, y_train_bboxes], epochs=20, batch_size=1000)\ny_pred,y_regres_pred=model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:14:50.077302Z","iopub.execute_input":"2024-02-08T17:14:50.077736Z","iopub.status.idle":"2024-02-08T17:19:16.515482Z","shell.execute_reply.started":"2024-02-08T17:14:50.077689Z","shell.execute_reply":"2024-02-08T17:19:16.514062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Set up the subplot\n#fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n\nfor i in range(5):\n    image = X_test[i]\n\n    plt.figure(figsize = (20,2))\n    plt.imshow(image, cmap='gray')\n    plt.plot([y_regres_pred[i, 0], y_regres_pred[i, 1]], [y_regres_pred[i, 2], y_regres_pred[i, 2]], 'r-')\n    plt.plot([y_regres_pred[i, 0], y_regres_pred[i, 1]], [y_regres_pred[i, 3], y_regres_pred[i, 3]], 'r-')\n    plt.plot([y_regres_pred[i, 0], y_regres_pred[i, 0]], [y_regres_pred[i, 2], y_regres_pred[i, 3]], 'r-')\n    plt.plot([y_regres_pred[i, 1], y_regres_pred[i, 1]], [y_regres_pred[i, 2], y_regres_pred[i, 3]], 'r-')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:19:17.531317Z","iopub.execute_input":"2024-02-08T17:19:17.531910Z","iopub.status.idle":"2024-02-08T17:19:18.551041Z","shell.execute_reply.started":"2024-02-08T17:19:17.531852Z","shell.execute_reply":"2024-02-08T17:19:18.549767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oto treść zadania opartego na podanym kodzie:\n\n### Zadanie: Analiza sentymentu tekstów za pomocą modelu LSTM\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie przewidywać sentyment na podstawie tekstu z wykorzystaniem modelu LSTM. Dane tekstowe są dostarczone w pliku CSV, który został już wczytany do ramki danych `df`.\n\nKroki, które musisz podjąć:\n\n1. **Przygotowanie danych**: Dane są wczytane z pliku CSV, a etykiety sentymentu są zamienione na wartości liczbowe (0 dla \"negative\", 1 dla \"positive\" i 2 dla \"neutral\"). Teksty są przekształcane na sekwencje liczb za pomocą Tokenizera. Następnie dane są podzielone na zbiór treningowy, walidacyjny i testowy.\n\n2. **Model LSTM**: Model jest zdefiniowany w kodzie i składa się z następujących warstw:\n   - Warstwa Embedding: Mapuje słowa na wektory o określonej długości.\n   - Warstwa LSTM: Warstwa rekurencyjna LSTM, która przetwarza sekwencje wektorów.\n   - Warstwa Dense: Warstwa wyjściowa z funkcją aktywacji softmax, która generuje trzy możliwe klasy sentymentu.\n\n3. **Kompilacja modelu**: Model jest skompilowany z odpowiednią funkcją straty \"binary_crossentropy\", optymalizatorem \"adam\" i metryką \"accuracy\".\n\n4. **Trenowanie modelu**: Model jest trenowany na danych treningowych przez 10 epok, z wsadem o rozmiarze 10. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie tego kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy sentymentu tekstu. Możesz eksperymentować z parametrami, takimi jak rozmiar sekwencji (max_sequence_length), wymiar embeddingu (embedding_dim) czy liczba epok treningu, aby dostosować model do danego zadania analizy sentymentu.","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:35:54.137473Z","iopub.execute_input":"2024-02-18T09:35:54.138034Z","iopub.status.idle":"2024-02-18T09:35:54.638023Z","shell.execute_reply.started":"2024-02-18T09:35:54.137992Z","shell.execute_reply":"2024-02-18T09:35:54.636886Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                            Sentence Sentiment\n0  The GeoSolutions technology will leverage Bene...  positive\n1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n2  For the last quarter of 2010 , Componenta 's n...  positive\n3  According to the Finnish-Russian Chamber of Co...   neutral\n4  The Swedish buyout firm has sold its remaining...   neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The GeoSolutions technology will leverage Bene...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>For the last quarter of 2010 , Componenta 's n...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>According to the Finnish-Russian Chamber of Co...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Swedish buyout firm has sold its remaining...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:35:54.639732Z","iopub.execute_input":"2024-02-18T09:35:54.640440Z","iopub.status.idle":"2024-02-18T09:35:54.652214Z","shell.execute_reply.started":"2024-02-18T09:35:54.640398Z","shell.execute_reply":"2024-02-18T09:35:54.651368Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"array(['positive', 'negative', 'neutral'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# Mapowanie etykiet sentymentu na wartości float\nsentiment_map = {\"positive\": 1, \"negative\": 0, 'neutral': 2}\ndf['Sentiment'] = df['Sentiment'].map(sentiment_map)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:35:56.782501Z","iopub.execute_input":"2024-02-18T09:35:56.783006Z","iopub.status.idle":"2024-02-18T09:35:56.798182Z","shell.execute_reply.started":"2024-02-18T09:35:56.782962Z","shell.execute_reply":"2024-02-18T09:35:56.796853Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:36:00.134734Z","iopub.execute_input":"2024-02-18T09:36:00.135124Z","iopub.status.idle":"2024-02-18T09:36:10.249941Z","shell.execute_reply.started":"2024-02-18T09:36:00.135095Z","shell.execute_reply":"2024-02-18T09:36:10.248961Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def clean_sentence_enhanced_v2(sentence):\n   # Konwersja na małe litery\n   sentence = sentence.lower()\n   # Usuwanie kwot z symbolem dolara i liczb z przecinkami\n   sentence = re.sub(r'\\$\\d+(?:\\.\\d+)?', '', sentence)\n   sentence = re.sub(r'\\d+,\\d+', '', sentence)\n   # Zamiana URLi\n   sentence = re.sub(r'http\\S+|www\\S+|https\\S+', '<URL>', sentence, flags=re.MULTILINE)\n   # Zamiana wzmianek o użytkownikach\n   sentence = re.sub(r'@\\w+', '<USER>', sentence)\n   # Zamiana znaków '#'\n   sentence = re.sub(r'#', '<TAG>', sentence)\n   # Zamiana pozostałych cyfr\n   sentence = re.sub(r'\\d+', '<NUMBER>', sentence)\n   # Usuwanie znaków interpunkcyjnych\n   sentence = ''.join(ch for ch in sentence if ch not in string.punctuation)\n   return sentence\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:36:10.345374Z","iopub.execute_input":"2024-02-18T09:36:10.345699Z","iopub.status.idle":"2024-02-18T09:36:10.358788Z","shell.execute_reply.started":"2024-02-18T09:36:10.345673Z","shell.execute_reply":"2024-02-18T09:36:10.357300Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nfrom tensorflow.keras.utils import to_categorical\nX = df['Sentence']\nprint(X.head())\ny = df['Sentiment']\nX=X.apply(clean_sentence_enhanced_v2)\nprint(X.head())\nnum_classes = 3 \ny = to_categorical(y, num_classes)\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nX = tokenizer.texts_to_sequences(X)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:37:13.781409Z","iopub.execute_input":"2024-02-18T09:37:13.782436Z","iopub.status.idle":"2024-02-18T09:37:14.440194Z","shell.execute_reply.started":"2024-02-18T09:37:13.782390Z","shell.execute_reply":"2024-02-18T09:37:14.438966Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"0    The GeoSolutions technology will leverage Bene...\n1    $ESI on lows, down $1.50 to $2.50 BK a real po...\n2    For the last quarter of 2010 , Componenta 's n...\n3    According to the Finnish-Russian Chamber of Co...\n4    The Swedish buyout firm has sold its remaining...\nName: Sentence, dtype: object\n0    the geosolutions technology will leverage bene...\n1          esi on lows down  to  bk a real possibility\n2    for the last quarter of NUMBER  componenta s n...\n3    according to the finnishrussian chamber of com...\n4    the swedish buyout firm has sold its remaining...\nName: Sentence, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Sentence'].shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:43:04.986436Z","iopub.execute_input":"2024-02-18T09:43:04.987093Z","iopub.status.idle":"2024-02-18T09:43:04.995475Z","shell.execute_reply.started":"2024-02-18T09:43:04.987058Z","shell.execute_reply":"2024-02-18T09:43:04.994367Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(5842,)"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:37.981248Z","iopub.execute_input":"2024-02-08T17:30:37.981725Z","iopub.status.idle":"2024-02-08T17:30:37.994071Z","shell.execute_reply.started":"2024-02-08T17:30:37.981678Z","shell.execute_reply":"2024-02-08T17:30:37.992820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_sequence_length = max(len(seq) for seq in X_train)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)\nX_test = pad_sequences(X_test, maxlen=max_sequence_length)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T17:30:40.463262Z","iopub.execute_input":"2024-02-08T17:30:40.463774Z","iopub.status.idle":"2024-02-08T17:30:40.510413Z","shell.execute_reply.started":"2024-02-08T17:30:40.463725Z","shell.execute_reply":"2024-02-08T17:30:40.509291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(X_val)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T18:28:34.696523Z","iopub.execute_input":"2024-02-08T18:28:34.697087Z","iopub.status.idle":"2024-02-08T18:28:34.705344Z","shell.execute_reply.started":"2024-02-08T18:28:34.697045Z","shell.execute_reply":"2024-02-08T18:28:34.704142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#todo model i validacja\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense,Dropout\nmodel = Sequential()\nmodel.add(Embedding(input_dim=10648, output_dim=52))\nmodel.add(LSTM(52, dropout=0.5, recurrent_dropout=0.5))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=20, batch_size=100, verbose=1, validation_data=(X_val,y_val))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T18:05:44.178532Z","iopub.execute_input":"2024-02-08T18:05:44.179021Z","iopub.status.idle":"2024-02-08T18:06:51.720133Z","shell.execute_reply.started":"2024-02-08T18:05:44.178984Z","shell.execute_reply":"2024-02-08T18:06:51.718904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Zadanie: Klasyfikacja kotów i psów za pomocą modelu ResNet50\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować obrazy kotów i psów. W tym celu wykorzystaj model ResNet50, który został wstępnie przeszkolony na szerokim zbiorze danych.\n\nKroki, które musisz podjąć:\n\n1. **Załadowanie danych**: Dane treningowe i walidacyjne zostały już przygotowane w formie generatorów za pomocą biblioteki `ImageDataGenerator`. Generator treningowy zawiera obrazy treningowe, a generator walidacyjny zawiera obrazy walidacyjne. Obrazy są przeskalowane do rozmiaru `(224, 224)` i podzielone na dwie klasy: koty i psy.\n\n2. **Model ResNet50**: W kodzie załadowano model ResNet50, który jest wstępnie przeszkolony na zestawie danych ImageNet. Model ten ma zamrożone wagi wszystkich warstw.\n\n3. **Warstwy klasyfikacji**: Do modelu ResNet50 dodano warstwy klasyfikacji. Jest to warstwa `GlobalAveragePooling2D` i warstwa `Dense`, która wykorzystuje funkcję aktywacji sigmoid. Model ten jest przystosowany do zadania klasyfikacji binarnej, gdzie klasy to \"kot\" i \"pies\".\n\n4. **Kompilacja modelu**: Model jest skompilowany z optymalizatorem Adam, funkcją straty \"binary_crossentropy\" (odpowiednia do klasyfikacji binarnej), oraz metryką \"accuracy\".\n\n5. **Trenowanie modelu**: Model jest trenowany na danych treningowych przez jedną epokę. Wynik trenowania jest wyświetlany na konsoli.\n\nTwoim zadaniem jest uzupełnienie tego kodu o brakujące elementy, takie jak liczba epok trenowania, odblokowanie warstw modelu ResNet50 oraz dostosowanie modelu do odpowiedniego rodzaju klasyfikacji (binarna). Następnie możesz dostosować parametry trenowania, takie jak liczba epok czy wielkość wsadu (batch size), aby osiągnąć jak najlepsze wyniki w zadaniu klasyfikacji kotów i psów.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Ustawienie ścieżki do katalogu z danymi\ndata_dir = '/kaggle/input/cat-and-dog/'\n\n# Definicja generatora obrazów\ndatagen = ImageDataGenerator(\n    rescale=1.0/255,           # Przeskalowanie wartości pikseli do zakresu [0, 1]\n    validation_split=0.2       # Procent danych przeznaczonych na zbiór walidacyjny\n)\n\n# Wczytanie danych treningowych\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),    # Rozmiar docelowy obrazów\n    batch_size=32,             # Rozmiar wsadu\n    class_mode='binary',  # Rodzaj klasyfikacji (binary lub categorical)\n    subset='training'          # Ustawienie dla danych treningowych\n)\n\n# Wczytanie danych walidacyjnych\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation'        # Ustawienie dla danych walidacyjnych\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T20:48:55.886668Z","iopub.execute_input":"2024-02-16T20:48:55.887125Z","iopub.status.idle":"2024-02-16T20:49:18.191249Z","shell.execute_reply.started":"2024-02-16T20:48:55.887087Z","shell.execute_reply":"2024-02-16T20:49:18.189560Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found 8023 images belonging to 2 classes.\nFound 2005 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.optimizers import Adam\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T20:49:59.330585Z","iopub.execute_input":"2024-02-16T20:49:59.331504Z","iopub.status.idle":"2024-02-16T20:49:59.340336Z","shell.execute_reply.started":"2024-02-16T20:49:59.331465Z","shell.execute_reply":"2024-02-16T20:49:59.338876Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Sprawdź liczbę klas\nnum_classes = len(train_generator.class_indices)\nprint(\"Liczba klas:\", num_classes)\n\n# Sprawdź rozmiar pierwszej partii danych treningowych\nbatch_images, batch_labels = train_generator.next()\nprint(\"Rozmiar partii obrazów:\", batch_images.shape)\nprint(\"Rozmiar partii etykiet:\", batch_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T20:50:36.563600Z","iopub.execute_input":"2024-02-16T20:50:36.564014Z","iopub.status.idle":"2024-02-16T20:50:36.854667Z","shell.execute_reply.started":"2024-02-16T20:50:36.563983Z","shell.execute_reply":"2024-02-16T20:50:36.853333Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Liczba klas: 2\nRozmiar partii obrazów: (32, 224, 224, 3)\nRozmiar partii etykiet: (32,)\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 1\noutput_logistic_regression = 1\n# Loading the pre-trained ResNet50 model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freezing all layers of the ResNet50\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Adding new classification layers\nmodel = Sequential([\n   base_model,\n   GlobalAveragePooling2D(),\n   Dense(output_logistic_regression, activation='sigmoid') # num_classes is the number of classes\n])\n\n# Compiling the model\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(\n    train_generator,\n    epochs=1,                 # Liczba epok treningu\n    validation_data=validation_generator)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T20:50:03.941426Z","iopub.execute_input":"2024-02-16T20:50:03.942490Z","iopub.status.idle":"2024-02-16T20:50:28.939049Z","shell.execute_reply.started":"2024-02-16T20:50:03.942447Z","shell.execute_reply":"2024-02-16T20:50:28.937079Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 1s 0us/step\n  3/251 [..............................] - ETA: 14:33 - loss: 1.4385 - accuracy: 0.1562","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Compiling the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Liczba epok treningu\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}