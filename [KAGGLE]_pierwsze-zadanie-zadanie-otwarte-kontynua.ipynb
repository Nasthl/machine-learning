{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1272990,"sourceType":"datasetVersion","datasetId":733642},{"sourceId":5339021,"sourceType":"datasetVersion","datasetId":2078011},{"sourceId":7618846,"sourceType":"datasetVersion","datasetId":4437563}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Klasyfikacja kwiatów\n","metadata":{}},{"cell_type":"markdown","source":"Ten zestaw danych zawiera 9 różnych rodzajów kwiatów. Twoim zadaniem jest zbudowanie modelu uczenia maszynowego lub głębokiego uczenia, który będzie w stanie klasyfikować te obrazy jako kwiaty. Oto klasy, które są dostępne:\n\n    Tulipan\n    Słonecznik\n    Róża\n    Orchidea\n    Lotos\n    Lilia\n    Lawenda\n    Mniszek lekarski\n    Stokrotka","metadata":{}},{"cell_type":"markdown","source":"Twoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować obrazy w kategorie kwiatów np. tulipan itp. W tym celu wykorzystaj model ResNet50, który został wstępnie przeszkolony na szerokim zbiorze danych.\n\nKroki, które musisz podjąć:\n\n1. **Załadowanie danych**: Dane treningowe i walidacyjne zostały już przygotowane w formie generatorów za pomocą biblioteki `ImageDataGenerator`. Generator treningowy zawiera obrazy treningowe, a generator walidacyjny zawiera obrazy walidacyjne. Obrazy są przeskalowane do rozmiaru `(224, 224)` i podzielone na dwie klasy: koty i psy.\n\n2. **Model ResNet50**: W kodzie załaduj model ResNet50, który jest wstępnie przeszkolony na zestawie danych ImageNet. Model ten ma zamrożone wagi wszystkich warstw.\n\n3. **Warstwy klasyfikacji**: Do modelu ResNet50 dodano warstwy klasyfikacji. Jest to warstwa `GlobalAveragePooling2D` i warstwa `Dense`, która wykorzystuje funkcję aktywacji softmax. Model ten jest przystosowany do zadania klasyfikacji.\n\n4. **Kompilacja modelu**: Model jest skompilowany z optymalizatorem Adam, funkcją straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej), oraz metryką \"accuracy\".\n\n5. **Trenowanie modelu**: Model jest trenowany na danych treningowych przez jedną epokę. Wynik trenowania jest wyświetlany na konsoli.\n\nTwoim zadaniem jest uzupełnienie tego kodu o brakujące elementy, takie jak liczba epok trenowania, odblokowanie warstw modelu ResNet50 oraz dostosowanie modelu do odpowiedniego rodzaju klasyfikacji (wieloklasowej). Następnie możesz dostosować parametry trenowania, takie jak liczba epok czy wielkość wsadu (batch size), aby osiągnąć jak najlepsze wyniki w zadaniu klasyfikacji.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Ustawienie ścieżki do katalogu z danymi\n\n# Definicja generatora obrazów\ndatagen = ImageDataGenerator(\n    rescale=1.0/255, # Przeskalowanie wartości pikseli do zakresu [0, 1]\n    validation_split=0.2 # Procent danych przeznaczonych na zbiór walidacyjny\n)\n\n# Wczytanie danych treningowych\ntrain_generator = datagen.flow_from_directory(\n    '/kaggle/input/national-flowers/flowerdataset/train',\n    target_size=(224, 224), # Rozmiar docelowy obrazów\n    batch_size=32, # Rozmiar wsadu\n    class_mode='categorical', # Rodzaj klasyfikacji (binary lub categorical)\n    subset='training' # Ustawienie dla danych treningowych\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T17:34:39.669972Z","iopub.execute_input":"2024-02-27T17:34:39.670644Z","iopub.status.idle":"2024-02-27T17:34:54.730652Z","shell.execute_reply.started":"2024-02-27T17:34:39.670616Z","shell.execute_reply":"2024-02-27T17:34:54.729929Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-27 17:34:41.879481: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-27 17:34:41.879610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-27 17:34:42.056549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 2880 images belonging to 9 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Wczytanie danych treningowych\nvalidation_generator = datagen.flow_from_directory(\n    '/kaggle/input/national-flowers/flowerdataset/test',\n    target_size=(224, 224), # Rozmiar docelowy obrazów\n    batch_size=32, # Rozmiar wsadu\n    class_mode='categorical', # Rodzaj klasyfikacji (binary lub categorical)\n    subset='training' # Ustawienie dla danych treningowych\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T17:34:56.682682Z","iopub.execute_input":"2024-02-27T17:34:56.683579Z","iopub.status.idle":"2024-02-27T17:34:57.068436Z","shell.execute_reply.started":"2024-02-27T17:34:56.683548Z","shell.execute_reply":"2024-02-27T17:34:57.067660Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 706 images belonging to 9 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Input, Dense, GlobalAveragePooling2D, AveragePooling2D, Flatten\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T17:34:58.612712Z","iopub.execute_input":"2024-02-27T17:34:58.613100Z","iopub.status.idle":"2024-02-27T17:34:58.622292Z","shell.execute_reply.started":"2024-02-27T17:34:58.613072Z","shell.execute_reply":"2024-02-27T17:34:58.621512Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Adding new classification layers\nmodel = Sequential([   base_model,   GlobalAveragePooling2D(),   Dense(9, activation='softmax')])\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(train_generator, epochs=10, verbose=1, validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T17:35:01.182994Z","iopub.execute_input":"2024-02-27T17:35:01.183693Z","iopub.status.idle":"2024-02-27T17:38:40.726044Z","shell.execute_reply.started":"2024-02-27T17:35:01.183662Z","shell.execute_reply":"2024-02-27T17:38:40.725087Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 0s 0us/step\nEpoch 1/10\n 1/90 [..............................] - ETA: 11:45 - loss: 2.3100 - accuracy: 0.2188","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1709055314.000888     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"90/90 [==============================] - 57s 553ms/step - loss: 2.1709 - accuracy: 0.1628 - val_loss: 2.1364 - val_accuracy: 0.1615\nEpoch 2/10\n90/90 [==============================] - 17s 182ms/step - loss: 2.0975 - accuracy: 0.2125 - val_loss: 2.0919 - val_accuracy: 0.1955\nEpoch 3/10\n90/90 [==============================] - 19s 211ms/step - loss: 2.0604 - accuracy: 0.2316 - val_loss: 2.0459 - val_accuracy: 0.2337\nEpoch 4/10\n90/90 [==============================] - 16s 182ms/step - loss: 2.0330 - accuracy: 0.2451 - val_loss: 2.0265 - val_accuracy: 0.1997\nEpoch 5/10\n90/90 [==============================] - 17s 184ms/step - loss: 2.0071 - accuracy: 0.2694 - val_loss: 2.0279 - val_accuracy: 0.2181\nEpoch 6/10\n90/90 [==============================] - 18s 203ms/step - loss: 1.9915 - accuracy: 0.2795 - val_loss: 1.9863 - val_accuracy: 0.2734\nEpoch 7/10\n90/90 [==============================] - 17s 184ms/step - loss: 1.9718 - accuracy: 0.2979 - val_loss: 2.0024 - val_accuracy: 0.2578\nEpoch 8/10\n90/90 [==============================] - 18s 193ms/step - loss: 1.9435 - accuracy: 0.3038 - val_loss: 1.9749 - val_accuracy: 0.2762\nEpoch 9/10\n90/90 [==============================] - 21s 232ms/step - loss: 1.9391 - accuracy: 0.3101 - val_loss: 1.9783 - val_accuracy: 0.2408\nEpoch 10/10\n90/90 [==============================] - 15s 167ms/step - loss: 1.9183 - accuracy: 0.3253 - val_loss: 1.9648 - val_accuracy: 0.2734\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7eead0677df0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detekcja fake newsów","metadata":{}},{"cell_type":"markdown","source":"Ten zbiór danych posiada 6 atrybutów, spośród których Nagłówek_Wiadomości jest dla nas najważniejszy, aby klasyfikować wiadomości jako FAŁSZYWE lub PRAWDZIWE. Jak zauważysz w atrybucie Etykieta, określono w nim 6 klas. Dlatego to od Ciebie zależy, czy chcesz użyć mojego zbioru danych do klasyfikacji wieloklasowej, czy przekształcić te etykiety klas na FAŁSZ lub PRAWDA, a następnie przeprowadzić klasyfikację binarną. Chociaż dla Twojej wygody, napiszę notatnik na temat tego, jak przekształcić ten zbiór danych z wieloklasowego na dwuklasowy. Aby radzić sobie z danymi tekstowymi, musisz mieć dobre praktyczne doświadczenie w zakresie NLP (Przetwarzanie Języka Naturalnego) i koncepcji Data-Miningu (Eksploracji Danych).\n\n    Nagłówek_Wiadomości - zawiera fragment informacji, który ma być analizowany.\n    Link_Do_Wiadomości - zawiera adres URL nagłówków wiadomości określonych w pierwszej kolumnie.\n    Źródło - ta kolumna zawiera nazwiska autorów, którzy opublikowali informacje na Facebooku, Instagramie, Twitterze lub innej platformie mediów społecznościowych.\n    Data_Opublikowania - Ta kolumna zawiera datę, kiedy informacje zostały opublikowane przez autorów na różnych platformach mediów społecznościowych.\n    Data - Ta kolumna zawiera datę, kiedy ta informacja została przeanalizowana przez zespół Politifact do sprawdzania faktów w celu oznaczenia jako FAŁSZYWE lub PRAWDZIWE.\n    Etykieta - Ta kolumna zawiera 5 etykiet klas: Prawda, Większość-Prawdy, Pół-Prawdy, Ledwo-Prawdy, Fałsz, Spodnie w Ogniu.","metadata":{}},{"cell_type":"markdown","source":"\n### Zadanie prostsze: Analiza fake newsów na podstawie tytułów z PositionalEncoding\n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować tweety na podstawie tytułu. W danych mamy dostarczone tytuły artykułów oraz etykiety, zdecyduj co z nimi zrobić :). \nKroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty znajdują się w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty powinny być tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przykładowo niech składa się z następujących warstw:\n\n* Warstwa wejściowa: Przyjmuje sekwencje tokenów o długości określonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentację słów jako gęstych wektorów cech.\n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, który pozwala modelowi skupić się na różnych częściach sekwencji wejściowej, co jest szczególnie przydatne w przetwarzaniu języka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z różnych części sekwencji, redukując wymiarowość danych i przygotowując je do procesu klasyfikacji.\n* Warstwa Dense (wyjściowa): Z funkcją aktywacji softmax, generuje dystrybucję prawdopodobieństwa dla dwóch możliwych klas sentymentu, umożliwiając klasyfikację.\n\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcją straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metryką \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy fake newsów na podstawie tytułów. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size).\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nfile_path = '/kaggle/input/fakereal-news/New Task.csv'\ntry:\n    df = pd.read_csv(file_path, encoding='utf-8')\nexcept UnicodeDecodeError:\n    try:\n        df = pd.read_csv(file_path, encoding='ISO-8859-1')  # Próba z kodowaniem ISO-8859-1\n    except UnicodeDecodeError:\n        df = pd.read_csv(file_path, encoding='Windows-1252')  # Próba z kodowaniem Windows-1252\n\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:03.914297Z","iopub.execute_input":"2024-03-02T10:24:03.914705Z","iopub.status.idle":"2024-03-02T10:24:04.050067Z","shell.execute_reply.started":"2024-03-02T10:24:03.914675Z","shell.execute_reply":"2024-03-02T10:24:04.049092Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                       News_Headline  \\\n0            Says Osama bin Laden endorsed Joe Biden   \n1  CNN aired a video of a toddler running away fr...   \n2  Says Tim Tebow kneeled in protest of abortion...   \n3  Even so-called moderate Democrats like Joe Bi...   \n4  \"Our health department, our city and our count...   \n\n                                        Link_Of_News            Source  \\\n0  https://www.politifact.com/factchecks/2020/jun...  Donald Trump Jr.   \n1  https://www.politifact.com/factchecks/2020/jun...      Donald Trump   \n2  https://www.politifact.com/factchecks/2020/jun...    Facebook posts   \n3  https://www.politifact.com/factchecks/2020/jun...        Paul Junge   \n4  https://www.politifact.com/factchecks/2020/jun...  Jeanette Kowalik   \n\n        Stated_On            Date        Label  \n0   June 18, 2020   June 19, 2020        FALSE  \n1   June 18, 2020   June 19, 2020   pants-fire  \n2   June 12, 2020   June 19, 2020        FALSE  \n3   June 10, 2020   June 19, 2020  barely-true  \n4   June 14, 2020   June 18, 2020         TRUE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>News_Headline</th>\n      <th>Link_Of_News</th>\n      <th>Source</th>\n      <th>Stated_On</th>\n      <th>Date</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Says Osama bin Laden endorsed Joe Biden</td>\n      <td>https://www.politifact.com/factchecks/2020/jun...</td>\n      <td>Donald Trump Jr.</td>\n      <td>June 18, 2020</td>\n      <td>June 19, 2020</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CNN aired a video of a toddler running away fr...</td>\n      <td>https://www.politifact.com/factchecks/2020/jun...</td>\n      <td>Donald Trump</td>\n      <td>June 18, 2020</td>\n      <td>June 19, 2020</td>\n      <td>pants-fire</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Says Tim Tebow kneeled in protest of abortion...</td>\n      <td>https://www.politifact.com/factchecks/2020/jun...</td>\n      <td>Facebook posts</td>\n      <td>June 12, 2020</td>\n      <td>June 19, 2020</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even so-called moderate Democrats like Joe Bi...</td>\n      <td>https://www.politifact.com/factchecks/2020/jun...</td>\n      <td>Paul Junge</td>\n      <td>June 10, 2020</td>\n      <td>June 19, 2020</td>\n      <td>barely-true</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"Our health department, our city and our count...</td>\n      <td>https://www.politifact.com/factchecks/2020/jun...</td>\n      <td>Jeanette Kowalik</td>\n      <td>June 14, 2020</td>\n      <td>June 18, 2020</td>\n      <td>TRUE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:06.692132Z","iopub.execute_input":"2024-03-02T10:24:06.692502Z","iopub.status.idle":"2024-03-02T10:24:06.710368Z","shell.execute_reply.started":"2024-03-02T10:24:06.692472Z","shell.execute_reply":"2024-03-02T10:24:06.709364Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array(['FALSE', 'pants-fire', 'barely-true', 'TRUE', 'mostly-true',\n       'half-true', 'full-flop', 'half-flip', 'no-flip'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"X=df['News_Headline'].to_numpy()\nlabels = pd.get_dummies(df['Label']).values\ny=labels","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:08.154683Z","iopub.execute_input":"2024-03-02T10:24:08.155088Z","iopub.status.idle":"2024-03-02T10:24:08.167454Z","shell.execute_reply.started":"2024-03-02T10:24:08.155053Z","shell.execute_reply":"2024-03-02T10:24:08.165371Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:10.467553Z","iopub.execute_input":"2024-03-02T10:24:10.467925Z","iopub.status.idle":"2024-03-02T10:24:10.474523Z","shell.execute_reply.started":"2024-03-02T10:24:10.467897Z","shell.execute_reply":"2024-03-02T10:24:10.473552Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([[ True, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False,  True],\n       [ True, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ...,  True, False, False],\n       [False, False,  True, ..., False, False, False],\n       [False,  True, False, ..., False, False, False]])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:12.814758Z","iopub.execute_input":"2024-03-02T10:24:12.815158Z","iopub.status.idle":"2024-03-02T10:24:14.215909Z","shell.execute_reply.started":"2024-03-02T10:24:12.815128Z","shell.execute_reply":"2024-03-02T10:24:14.214868Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Embedding, Dense, Dropout, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Input\n\nclass PositionalEncoding(Layer):\n   def __init__(self, position, d_model):\n       super(PositionalEncoding, self).__init__()\n       self.pos_encoding = self.positional_encoding(position, d_model)\n\n   def get_angles(self, position, i, d_model):\n       angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n       return position * angles\n\n   def positional_encoding(self, position, d_model):\n       angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n                                    np.arange(d_model)[np.newaxis, :],\n                                    d_model)\n       # Aplikuj sinus do indeksów parzystych w macierzy; 2i\n       angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n       # Aplikuj cosinus do indeksów nieparzystych w macierzy; 2i+1\n       angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n       pos_encoding = angle_rads[np.newaxis, ...]\n       return tf.cast(pos_encoding, dtype=tf.float32)\n\n   def call(self, inputs):\n       return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:18.395290Z","iopub.execute_input":"2024-03-02T10:24:18.395653Z","iopub.status.idle":"2024-03-02T10:24:18.405781Z","shell.execute_reply.started":"2024-03-02T10:24:18.395624Z","shell.execute_reply":"2024-03-02T10:24:18.404908Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Embedding, Dense, Dropout, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Input\n\nfrom keras import layers\nclass TokenAndPositionEmbedding(layers.Layer):\n   def __init__(self, maxlen, vocab_size, embed_dim):\n       super().__init__()\n       self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n       self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n   def call(self, x):\n       # Obliczanie długości sekwencji\n       maxlen = tf.shape(x)[-1]\n       # Generowanie pozycji dla każdego tokenu w sekwencji\n       positions = tf.range(start=0, limit=maxlen, delta=1)\n       # Uzyskanie pozycyjnego embedding\n       positions = self.pos_emb(positions)\n       # Uzyskanie tlenowego embedding\n       x = self.token_emb(x)\n       # Dodanie pozycyjnego embedding do tlenowego embedding\n       return x + positions\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:24:20.261100Z","iopub.execute_input":"2024-03-02T10:24:20.261742Z","iopub.status.idle":"2024-03-02T10:24:20.269563Z","shell.execute_reply.started":"2024-03-02T10:24:20.261710Z","shell.execute_reply":"2024-03-02T10:24:20.268586Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\nimport numpy as np\nembed_dim = 100  # Wymiar wektora embeddingowego\nnum_heads = 5  # Liczba \"głowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar słownika\n\ninputs = Input(shape=(max_sequence_length,))\n#embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\npositional_layer=TokenAndPositionEmbedding(max_sequence_length,vocab_size, embed_dim)(inputs)\n#positional_layer=PositionalEncoding(vocab_size, embed_dim)(inputs),\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(positional_layer, positional_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\nglobal_average= Dropout(0.5) (global_average)\n#dense_layer = Dense(9, activation='relu')(global_average)\noutputs = Dense(9, activation='softmax')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T10:54:38.076672Z","iopub.execute_input":"2024-03-02T10:54:38.077078Z","iopub.status.idle":"2024-03-02T10:57:26.793964Z","shell.execute_reply.started":"2024-03-02T10:54:38.077037Z","shell.execute_reply":"2024-03-02T10:57:26.792902Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/20\n175/175 [==============================] - 24s 77ms/step - loss: 1.8745 - accuracy: 0.1967 - val_loss: 1.8221 - val_accuracy: 0.2280\nEpoch 2/20\n175/175 [==============================] - 9s 50ms/step - loss: 1.8407 - accuracy: 0.2006 - val_loss: 1.8133 - val_accuracy: 0.2280\nEpoch 3/20\n175/175 [==============================] - 8s 47ms/step - loss: 1.8289 - accuracy: 0.2057 - val_loss: 1.8120 - val_accuracy: 0.2280\nEpoch 4/20\n175/175 [==============================] - 8s 47ms/step - loss: 1.8193 - accuracy: 0.2130 - val_loss: 1.8025 - val_accuracy: 0.2301\nEpoch 5/20\n175/175 [==============================] - 8s 45ms/step - loss: 1.7472 - accuracy: 0.2578 - val_loss: 1.8114 - val_accuracy: 0.2215\nEpoch 6/20\n175/175 [==============================] - 8s 44ms/step - loss: 1.6228 - accuracy: 0.3072 - val_loss: 1.7541 - val_accuracy: 0.2495\nEpoch 7/20\n175/175 [==============================] - 7s 42ms/step - loss: 1.4872 - accuracy: 0.3660 - val_loss: 1.9051 - val_accuracy: 0.2459\nEpoch 8/20\n175/175 [==============================] - 8s 44ms/step - loss: 1.3231 - accuracy: 0.4519 - val_loss: 1.9295 - val_accuracy: 0.2659\nEpoch 9/20\n175/175 [==============================] - 7s 41ms/step - loss: 1.1369 - accuracy: 0.5429 - val_loss: 2.3500 - val_accuracy: 0.2573\nEpoch 10/20\n175/175 [==============================] - 7s 43ms/step - loss: 0.9920 - accuracy: 0.5967 - val_loss: 2.8223 - val_accuracy: 0.2280\nEpoch 11/20\n175/175 [==============================] - 8s 43ms/step - loss: 0.8492 - accuracy: 0.6606 - val_loss: 3.1964 - val_accuracy: 0.2530\nEpoch 12/20\n175/175 [==============================] - 7s 42ms/step - loss: 0.7213 - accuracy: 0.7226 - val_loss: 3.6788 - val_accuracy: 0.2351\nEpoch 13/20\n175/175 [==============================] - 7s 42ms/step - loss: 0.5873 - accuracy: 0.7852 - val_loss: 4.3924 - val_accuracy: 0.2516\nEpoch 14/20\n175/175 [==============================] - 7s 43ms/step - loss: 0.4363 - accuracy: 0.8415 - val_loss: 5.5806 - val_accuracy: 0.2394\nEpoch 15/20\n175/175 [==============================] - 7s 43ms/step - loss: 0.3294 - accuracy: 0.8815 - val_loss: 7.1665 - val_accuracy: 0.2394\nEpoch 16/20\n175/175 [==============================] - 7s 42ms/step - loss: 0.2421 - accuracy: 0.9159 - val_loss: 8.6665 - val_accuracy: 0.2308\nEpoch 17/20\n175/175 [==============================] - 7s 42ms/step - loss: 0.1769 - accuracy: 0.9396 - val_loss: 9.3816 - val_accuracy: 0.2366\nEpoch 18/20\n175/175 [==============================] - 7s 42ms/step - loss: 0.1331 - accuracy: 0.9550 - val_loss: 10.9835 - val_accuracy: 0.2301\nEpoch 19/20\n175/175 [==============================] - 7s 41ms/step - loss: 0.0938 - accuracy: 0.9684 - val_loss: 11.8533 - val_accuracy: 0.2301\nEpoch 20/20\n175/175 [==============================] - 7s 42ms/step - loss: 0.0730 - accuracy: 0.9756 - val_loss: 13.2607 - val_accuracy: 0.2244\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7d4f2c35ecb0>"},"metadata":{}}]},{"cell_type":"markdown","source":"Model sie przeucza bardzo szybko, niezależnie od parametrów","metadata":{}},{"cell_type":"markdown","source":"#  Binary Classification Amazon Reviews","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Input, Dense, GlobalAveragePooling2D, AveragePooling2D, Flatten\n\ndataset_train = pd.read_csv('../input/amazon-reviews-for-sa-binary-negative-positive-csv/amazon_review_sa_binary_csv/train.csv')\ndataset_test = pd.read_csv('../input/amazon-reviews-for-sa-binary-negative-positive-csv/amazon_review_sa_binary_csv/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:47:57.563483Z","iopub.execute_input":"2024-03-02T11:47:57.564250Z","iopub.status.idle":"2024-03-02T11:48:19.787201Z","shell.execute_reply.started":"2024-03-02T11:47:57.564217Z","shell.execute_reply":"2024-03-02T11:48:19.786085Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X=dataset_train['review_title'].values.astype(str)\ny=dataset_train['class_index'].values\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:48:53.121464Z","iopub.status.idle":"2024-03-02T11:48:53.121816Z","shell.execute_reply.started":"2024-03-02T11:48:53.121648Z","shell.execute_reply":"2024-03-02T11:48:53.121663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:48:55.113939Z","iopub.execute_input":"2024-03-02T11:48:55.114701Z","iopub.status.idle":"2024-03-02T11:48:55.121692Z","shell.execute_reply.started":"2024-03-02T11:48:55.114666Z","shell.execute_reply":"2024-03-02T11:48:55.120663Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(3600000,)"},"metadata":{}}]},{"cell_type":"code","source":"def strip_html_tags(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    [s.extract() for s in soup(['iframe', 'script'])]\n    stripped_text = soup.get_text()\n    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n    return stripped_text\n\ndef remove_accented_chars(text):\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return text\n\n\n\ndef pre_process_corpus(docs):\n    norm_docs = []\n    for doc in tqdm.tqdm(docs):\n        doc = strip_html_tags(doc)\n        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n        doc = doc.lower()\n        doc = remove_accented_chars(doc)\n        doc = contractions.fix(doc)\n        # lower case and remove special characters\\whitespaces\n        doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n        doc = re.sub(' +', ' ', doc)\n        doc = doc.strip()  \n        norm_docs.append(doc)\n  \n    return norm_docs\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:48:56.877123Z","iopub.execute_input":"2024-03-02T11:48:56.877890Z","iopub.status.idle":"2024-03-02T11:48:56.886743Z","shell.execute_reply.started":"2024-03-02T11:48:56.877857Z","shell.execute_reply":"2024-03-02T11:48:56.885824Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tqdm\nimport re\nfrom bs4 import BeautifulSoup\nimport unicodedata\nimport contractions\nX = pre_process_corpus(X)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:48:59.162884Z","iopub.execute_input":"2024-03-02T11:48:59.163269Z","iopub.status.idle":"2024-03-02T11:54:36.494764Z","shell.execute_reply.started":"2024-03-02T11:48:59.163240Z","shell.execute_reply":"2024-03-02T11:54:36.493628Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"  0%|          | 0/3600000 [00:00<?, ?it/s]/tmp/ipykernel_4224/2395363686.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  soup = BeautifulSoup(text, \"html.parser\")\n  5%|▍         | 174543/3600000 [00:16<05:11, 10980.14it/s]/tmp/ipykernel_4224/2395363686.py:2: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n  soup = BeautifulSoup(text, \"html.parser\")\n100%|██████████| 3600000/3600000 [05:37<00:00, 10680.16it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install contractions","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:30:21.453134Z","iopub.execute_input":"2024-03-02T11:30:21.453526Z","iopub.status.idle":"2024-03-02T11:30:39.430822Z","shell.execute_reply.started":"2024-03-02T11:30:21.453495Z","shell.execute_reply":"2024-03-02T11:30:39.429568Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Collecting contractions\n  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting textsearch>=0.0.21 (from contractions)\n  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting anyascii (from textsearch>=0.0.21->contractions)\n  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\nCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\nDownloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n","output_type":"stream"}]},{"cell_type":"code","source":"#Normalizacja - były klasy 1,2 teraz sa 0 i 1\ny=y-1\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:56:34.115462Z","iopub.execute_input":"2024-03-02T11:56:34.116383Z","iopub.status.idle":"2024-03-02T11:56:34.126335Z","shell.execute_reply.started":"2024-03-02T11:56:34.116348Z","shell.execute_reply":"2024-03-02T11:56:34.125344Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:56:36.517239Z","iopub.execute_input":"2024-03-02T11:56:36.517638Z","iopub.status.idle":"2024-03-02T11:56:36.524502Z","shell.execute_reply.started":"2024-03-02T11:56:36.517613Z","shell.execute_reply":"2024-03-02T11:56:36.523462Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, ..., 0, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T11:56:38.935711Z","iopub.execute_input":"2024-03-02T11:56:38.936404Z","iopub.status.idle":"2024-03-02T11:58:31.413866Z","shell.execute_reply.started":"2024-03-02T11:56:38.936355Z","shell.execute_reply":"2024-03-02T11:58:31.412979Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Twoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować recenzje na podstawie tytułu. W danych mamy dostarczone klasy (1) albo (2). \nKroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty znajdują się w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty powinny być tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przykładowo niech składa się z następujących warstw:\n\n* Warstwa wejściowa: Przyjmuje sekwencje tokenów o długości określonej przez max_sequence_length.\n* Warstwa Embedding: Mapuje tokeny na wektory o wymiarze embed_dim (100 w tym przypadku), co pozwala na reprezentację słów jako gęstych wektorów cech.\n* Warstwa MultiHeadAttention: Implementuje mechanizm uwagi, który pozwala modelowi skupić się na różnych częściach sekwencji wejściowej, co jest szczególnie przydatne w przetwarzaniu języka naturalnego.\n* GlobalAveragePooling1D: Agreguje informacje z różnych części sekwencji, redukując wymiarowość danych i przygotowując je do procesu klasyfikacji.\n* Warstwa PositionalEncoding(position, embed_dim)(embedding_layer), która mapuje sekwencje na odpowiednie pozycje. \n* Warstwa Dense (wyjściowa): Z funkcją aktywacji softmax, generuje dystrybucję prawdopodobieństwa dla dwóch możliwych klas sentymentu, umożliwiając klasyfikację.\n\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcją straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metryką \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym. \n\n6. Porównaj swój model z https://www.kaggle.com/code/yacharki/binary-classification-amazon-reviews-84-lstm/notebook#Text-classification-with-an-RNN-%5BLSTM%5D. \n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu klasyfikacji. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size).\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, GlobalAveragePooling1D, Dense\nimport numpy as np\nembed_dim = 100  # Wymiar wektora embeddingowego\nnum_heads = 2  # Liczba \"głowic\" w warstwie Multi-Head Attention\nvocab_size = 10000  # Rozmiar słownika\n\ninputs = Input(shape=(max_sequence_length,))\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\nattention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(embedding_layer, embedding_layer)\nglobal_average = GlobalAveragePooling1D()(attention_output)\n#global_average= Dropout(0.5) (global_average)\noutputs = Dense(1, activation='sigmoid')(global_average)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=600, validation_split=0.2, verbose=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:07:29.563833Z","iopub.execute_input":"2024-03-02T12:07:29.564683Z","iopub.status.idle":"2024-03-02T12:41:55.728582Z","shell.execute_reply.started":"2024-03-02T12:07:29.564650Z","shell.execute_reply":"2024-03-02T12:41:55.727432Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/10\n3360/3360 [==============================] - 222s 66ms/step - loss: 0.3748 - accuracy: 0.8244 - val_loss: 0.3376 - val_accuracy: 0.8430\nEpoch 2/10\n3360/3360 [==============================] - 206s 61ms/step - loss: 0.3319 - accuracy: 0.8446 - val_loss: 0.3289 - val_accuracy: 0.8463\nEpoch 3/10\n3360/3360 [==============================] - 205s 61ms/step - loss: 0.3241 - accuracy: 0.8482 - val_loss: 0.3256 - val_accuracy: 0.8488\nEpoch 4/10\n3360/3360 [==============================] - 205s 61ms/step - loss: 0.3192 - accuracy: 0.8507 - val_loss: 0.3240 - val_accuracy: 0.8493\nEpoch 5/10\n3360/3360 [==============================] - 205s 61ms/step - loss: 0.3156 - accuracy: 0.8528 - val_loss: 0.3219 - val_accuracy: 0.8503\nEpoch 6/10\n3360/3360 [==============================] - 205s 61ms/step - loss: 0.3126 - accuracy: 0.8542 - val_loss: 0.3234 - val_accuracy: 0.8510\nEpoch 7/10\n3360/3360 [==============================] - 204s 61ms/step - loss: 0.3096 - accuracy: 0.8558 - val_loss: 0.3224 - val_accuracy: 0.8492\nEpoch 8/10\n3360/3360 [==============================] - 204s 61ms/step - loss: 0.3067 - accuracy: 0.8575 - val_loss: 0.3205 - val_accuracy: 0.8510\nEpoch 9/10\n3360/3360 [==============================] - 204s 61ms/step - loss: 0.3039 - accuracy: 0.8589 - val_loss: 0.3204 - val_accuracy: 0.8511\nEpoch 10/10\n3360/3360 [==============================] - 204s 61ms/step - loss: 0.3010 - accuracy: 0.8605 - val_loss: 0.3209 - val_accuracy: 0.8520\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7d0638371ed0>"},"metadata":{}}]}]}