{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression: 3750.00 + 250.00x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'years': [1, 2, 3, 4, 5, 6],\n",
    "        'salary': [4000, 4250, 4500, 4750, 5000, 5250],\n",
    "    }\n",
    ")\n",
    "X1=df['years']\n",
    "Y=df['salary']\n",
    "X = np.c_[np.ones((6, 1)), X1]\n",
    "\n",
    "coefs=np.dot(np.linalg.inv(np.dot(X.T,X)),np.dot(X.T,Y))\n",
    "print(f'Linear regression: {coefs[0]:.2f} + {coefs[1]:.2f}x')   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    " \n",
    "df = pd.read_csv('data.csv')\n",
    "data=df[['variable']]\n",
    "target=df['target']\n",
    "data\n",
    "lr=LinearRegression()\n",
    "lr.fit(data,target)\n",
    "print(f'{lr.score(data,target):.4f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   , -0.542,  0.294],\n",
       "       [ 1.   ,  0.529,  0.279],\n",
       "       [ 1.   ,  0.625,  0.391],\n",
       "       [ 1.   ,  0.194,  0.038],\n",
       "       [ 1.   , -0.8  ,  0.64 ],\n",
       "       [ 1.   , -0.304,  0.092],\n",
       "       [ 1.   ,  1.086,  1.18 ],\n",
       "       [ 1.   , -1.16 ,  1.346],\n",
       "       [ 1.   ,  1.038,  1.078],\n",
       "       [ 1.   , -0.815,  0.665],\n",
       "       [ 1.   ,  0.416,  0.173],\n",
       "       [ 1.   ,  1.297,  1.683],\n",
       "       [ 1.   , -0.433,  0.187],\n",
       "       [ 1.   ,  1.059,  1.121],\n",
       "       [ 1.   ,  1.139,  1.297],\n",
       "       [ 1.   ,  1.   ,  1.   ],\n",
       "       [ 1.   ,  0.109,  0.012],\n",
       "       [ 1.   , -0.39 ,  0.152],\n",
       "       [ 1.   , -0.701,  0.491],\n",
       "       [ 1.   ,  0.698,  0.488],\n",
       "       [ 1.   ,  0.752,  0.565],\n",
       "       [ 1.   ,  0.661,  0.437],\n",
       "       [ 1.   , -0.964,  0.93 ],\n",
       "       [ 1.   , -0.252,  0.064],\n",
       "       [ 1.   ,  0.344,  0.119],\n",
       "       [ 1.   ,  0.524,  0.274],\n",
       "       [ 1.   , -0.164,  0.027],\n",
       "       [ 1.   ,  0.048,  0.002],\n",
       "       [ 1.   ,  0.606,  0.367],\n",
       "       [ 1.   , -0.148,  0.022]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    " \n",
    " \n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "df = pd.read_csv('data.csv')\n",
    "data=df[['var1']]\n",
    "pf=PolynomialFeatures(degree=2)\n",
    "pf.fit(data)\n",
    "data_poly=pf.transform(data)\n",
    "data_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.   ,  -0.016,   0.589,   0.   ,  -0.01 ,   0.347,  -0.   ,\n",
       "          0.   ,  -0.006,   0.204],\n",
       "       [  1.   ,   0.754,   0.076,   0.569,   0.058,   0.006,   0.429,\n",
       "          0.043,   0.004,   0.   ],\n",
       "       [  1.   ,  -1.157,  -1.465,   1.338,   1.695,   2.146,  -1.548,\n",
       "         -1.96 ,  -2.482,  -3.143],\n",
       "       [  1.   ,   0.177,  -0.175,   0.031,  -0.031,   0.031,   0.006,\n",
       "         -0.006,   0.005,  -0.005],\n",
       "       [  1.   ,  -2.502,   1.536,   6.258,  -3.843,   2.36 , -15.656,\n",
       "          9.615,  -5.905,   3.626],\n",
       "       [  1.   ,   0.631,   0.537,   0.398,   0.339,   0.288,   0.251,\n",
       "          0.214,   0.182,   0.155],\n",
       "       [  1.   ,   0.239,   0.227,   0.057,   0.054,   0.051,   0.014,\n",
       "          0.013,   0.012,   0.012],\n",
       "       [  1.   ,   1.062,   0.598,   1.127,   0.635,   0.358,   1.197,\n",
       "          0.675,   0.38 ,   0.214],\n",
       "       [  1.   ,  -0.837,  -0.328,   0.7  ,   0.275,   0.108,  -0.586,\n",
       "         -0.23 ,  -0.09 ,  -0.035],\n",
       "       [  1.   ,   0.567,  -0.313,   0.321,  -0.178,   0.098,   0.182,\n",
       "         -0.101,   0.056,  -0.031],\n",
       "       [  1.   ,   0.845,  -2.593,   0.714,  -2.191,   6.726,   0.603,\n",
       "         -1.852,   5.684, -17.444],\n",
       "       [  1.   ,  -0.498,   0.997,   0.248,  -0.497,   0.994,  -0.124,\n",
       "          0.247,  -0.495,   0.991],\n",
       "       [  1.   ,  -0.753,   0.89 ,   0.566,  -0.67 ,   0.792,  -0.426,\n",
       "          0.504,  -0.596,   0.704],\n",
       "       [  1.   ,   0.549,  -1.034,   0.302,  -0.568,   1.068,   0.166,\n",
       "         -0.312,   0.587,  -1.104],\n",
       "       [  1.   ,   0.872,   0.405,   0.76 ,   0.353,   0.164,   0.662,\n",
       "          0.307,   0.143,   0.066],\n",
       "       [  1.   ,   1.309,  -1.543,   1.713,  -2.019,   2.38 ,   2.243,\n",
       "         -2.643,   3.115,  -3.672],\n",
       "       [  1.   ,  -1.486,  -0.926,   2.208,   1.376,   0.858,  -3.28 ,\n",
       "         -2.045,  -1.275,  -0.795],\n",
       "       [  1.   ,  -0.192,  -1.319,   0.037,   0.253,   1.739,  -0.007,\n",
       "         -0.048,  -0.333,  -2.293],\n",
       "       [  1.   ,   0.786,   0.64 ,   0.618,   0.503,   0.409,   0.486,\n",
       "          0.396,   0.322,   0.262],\n",
       "       [  1.   ,  -0.013,   0.489,   0.   ,  -0.006,   0.24 ,  -0.   ,\n",
       "          0.   ,  -0.003,   0.117],\n",
       "       [  1.   ,   0.849,  -1.723,   0.72 ,  -1.462,   2.969,   0.612,\n",
       "         -1.241,   2.52 ,  -5.115],\n",
       "       [  1.   ,  -0.175,   0.269,   0.031,  -0.047,   0.072,  -0.005,\n",
       "          0.008,  -0.013,   0.019],\n",
       "       [  1.   ,   0.289,   0.723,   0.084,   0.209,   0.523,   0.024,\n",
       "          0.06 ,   0.151,   0.378],\n",
       "       [  1.   ,  -0.761,  -0.848,   0.579,   0.646,   0.72 ,  -0.441,\n",
       "         -0.492,  -0.548,  -0.61 ],\n",
       "       [  1.   ,  -0.556,   0.191,   0.309,  -0.106,   0.037,  -0.172,\n",
       "          0.059,  -0.02 ,   0.007],\n",
       "       [  1.   ,  -0.137,  -1.477,   0.019,   0.203,   2.182,  -0.003,\n",
       "         -0.028,  -0.3  ,  -3.224],\n",
       "       [  1.   ,   0.369,  -0.511,   0.136,  -0.189,   0.261,   0.05 ,\n",
       "         -0.07 ,   0.096,  -0.133],\n",
       "       [  1.   ,   2.415,   0.031,   5.833,   0.074,   0.001,  14.087,\n",
       "          0.179,   0.002,   0.   ],\n",
       "       [  1.   ,  -1.502,  -1.225,   2.257,   1.841,   1.502,  -3.39 ,\n",
       "         -2.766,  -2.256,  -1.84 ],\n",
       "       [  1.   ,   0.642,   1.024,   0.412,   0.658,   1.049,   0.265,\n",
       "          0.423,   0.674,   1.075]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    " \n",
    " \n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "df = pd.read_csv('data.csv')\n",
    "data=df[['var1','var2']]\n",
    "pf=PolynomialFeatures(degree=3)\n",
    "pf.fit(data)\n",
    "data_poly=pf.transform(data)\n",
    "data_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 74.9471\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "MAE=np.mean((data['y_true'].values-data['y_pred'].values)**2)\n",
    "print(f'MAE = {MAE:.6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var1_sigmoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>0.621687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.465489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647689</td>\n",
       "      <td>0.656489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.523030</td>\n",
       "      <td>0.820984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.234153</td>\n",
       "      <td>0.441728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.234137</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.579213</td>\n",
       "      <td>0.829093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.767435</td>\n",
       "      <td>0.682966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.384741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.542560</td>\n",
       "      <td>0.632408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1  var1_sigmoid\n",
       "0  0.496714      0.621687\n",
       "1 -0.138264      0.465489\n",
       "2  0.647689      0.656489\n",
       "3  1.523030      0.820984\n",
       "4 -0.234153      0.441728\n",
       "5 -0.234137      0.441732\n",
       "6  1.579213      0.829093\n",
       "7  0.767435      0.682966\n",
       "8 -0.469474      0.384741\n",
       "9  0.542560      0.632408"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(data=np.random.randn(10), columns=['var1'])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "df['var1_sigmoid']=sigmoid(df['var1'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4785 -0.2137 -0.4584 -0.5114  0.0636]\n",
      " [ 1.3742  0.3895  1.2924  1.4055 -0.616 ]\n",
      " [ 0.3777 -0.0178  0.3905  0.2783  0.7424]\n",
      " [-0.4986 -0.4185 -0.4427 -0.5531  0.4723]\n",
      " [-0.7449 -1.1397 -0.7236 -0.745   0.0771]\n",
      " [ 1.8496  2.1747  1.9719  1.8048  1.3537]\n",
      " [ 2.2534  0.5208  2.2644  2.4466  0.5363]\n",
      " [ 0.9819 -1.0039  0.9382  0.8882 -0.0203]\n",
      " [-0.2294 -0.8236 -0.236  -0.3987  0.6429]\n",
      " [-0.069  -0.6544 -0.1338 -0.1639 -2.1663]\n",
      " [-0.2666  1.2665 -0.3344 -0.3457 -0.7709]\n",
      " [ 0.7557 -0.1692  0.7035  0.6847 -0.7183]\n",
      " [ 0.2374  0.0445  0.1351  0.1047 -1.0339]\n",
      " [ 0.6068  0.5164  0.6293  0.5087  1.2613]\n",
      " [-0.5158 -1.6227 -0.5469 -0.551  -0.6202]\n",
      " [ 1.4201  1.498   1.5189  1.4114  1.6167]\n",
      " [ 0.1916 -1.0818  0.1005  0.0766 -0.9977]\n",
      " [-1.14    0.0066 -1.1321 -1.0148  0.1098]\n",
      " [-2.0504 -1.3645 -1.9945 -1.5123  1.2968]\n",
      " [ 1.8353  0.2893  1.8772  1.932   0.4154]\n",
      " [-0.0977 -0.8392 -0.0737 -0.2091  0.1382]\n",
      " [-0.5845 -0.4096 -0.5827 -0.617   0.2946]\n",
      " [ 2.1388  0.6054  2.149   2.2248  1.2755]\n",
      " [-1.1773  0.3828 -1.1956 -1.0278 -1.25  ]\n",
      " [-0.7277  1.0973 -0.7409 -0.7027 -1.7071]\n",
      " [-0.175  -1.9188 -0.1775 -0.2828  2.1569]\n",
      " [-0.2466 -1.3    -0.2648 -0.3342 -1.0752]\n",
      " [-1.1028  1.7918 -1.0934 -0.9861 -0.601 ]\n",
      " [-0.3955 -0.1603 -0.4262 -0.4679 -0.1419]\n",
      " [ 0.876   1.104   0.9053  0.8122  0.5931]\n",
      " [-0.8623  0.641  -0.8537 -0.8175 -0.22  ]\n",
      " [-0.5959 -1.5181 -0.6334 -0.6099 -0.4013]\n",
      " [-1.2597 -0.098  -1.2474 -1.0798  0.6216]\n",
      " [-0.132  -0.719  -0.1837 -0.2345 -0.4255]\n",
      " [-1.1343 -0.4519 -1.1161 -1.0106  0.5221]\n",
      " [-0.7506 -0.1803 -0.7775 -0.727  -0.2499]\n",
      " [ 0.5381  0.8191  0.4316  0.423  -1.1868]\n",
      " [-0.6876 -1.2332 -0.7405 -0.6729 -1.4661]\n",
      " [ 1.1767  0.0935  1.1277  1.1393 -0.2933]\n",
      " [ 0.1371  0.9927  0.0968  0.0234 -0.6409]\n",
      " [-1.0455 -0.0601 -1.0218 -0.9426  0.0806]\n",
      " [ 0.2689  1.3756  0.2381  0.1828  0.259 ]\n",
      " [-0.7248 -0.788  -0.6902 -0.7294  0.714 ]\n",
      " [-0.6589 -0.138  -0.6882 -0.6708 -0.7141]\n",
      " [-0.6446 -0.4897 -0.6597 -0.6483  1.6878]\n",
      " [-0.8021  0.3784 -0.813  -0.764  -0.7937]\n",
      " [-1.3877 -1.2599 -1.3286 -1.1742  2.7256]\n",
      " [-1.3511  1.8519 -1.3574 -1.1343 -1.2458]\n",
      " [-0.7076  0.1024 -0.7005 -0.7057  0.2022]\n",
      " [-0.3583 -0.8592 -0.3352 -0.4087 -1.4626]\n",
      " [ 0.8731  0.5587  0.7982  0.8089 -0.1063]\n",
      " [ 1.2855  1.2353  1.3418  1.2813  0.5434]\n",
      " [-0.2953  0.6633 -0.2141 -0.3709  0.1027]\n",
      " [-0.0576 -1.4224 -0.0786 -0.1792  1.8513]\n",
      " [-0.6418 -1.0929 -0.5811 -0.6566  1.1689]\n",
      " [-0.2781 -0.2983 -0.327  -0.3475 -1.7128]\n",
      " [-1.1143 -0.7524 -1.0584 -0.9778  0.5221]\n",
      " [ 3.1726  1.1908  3.2651  3.6178  0.5363]\n",
      " [-0.1893  0.2804 -0.1573 -0.2828  0.2022]\n",
      " [-0.8164 -1.4513 -0.8232 -0.7891 -0.0295]\n",
      " [-0.3669 -0.3473 -0.3719 -0.4392  0.0415]\n",
      " [ 1.589   0.3761  1.556   1.6214  0.7708]\n",
      " [ 2.1245  0.6299  2.0502  2.4377  0.8704]\n",
      " [ 0.0741  1.6538  0.0013 -0.0257 -2.0476]\n",
      " [-0.5272 -0.1202 -0.5906 -0.5631 -1.1107]\n",
      " [-0.4356  0.9816 -0.4476 -0.4685 -1.4021]\n",
      " [ 0.4693  0.7456  0.5552  0.378   1.1902]\n",
      " [ 1.7293  0.9816  2.1202  1.7456  2.1214]\n",
      " [-0.6675 -0.483  -0.698  -0.6681  0.1382]\n",
      " [-0.3325 -0.0468 -0.3171 -0.4164 -0.2108]\n",
      " [-0.1063  0.6076 -0.0655 -0.1949  1.5101]\n",
      " [ 0.4693 -0.3718  0.4687  0.3733 -0.1177]\n",
      " [-0.0232 -0.5298 -0.1017 -0.1352 -1.3012]\n",
      " [ 0.6641  0.1224  0.7035  0.5268 -0.0317]\n",
      " [-1.8362  1.3199 -1.822  -1.4079 -1.2635]\n",
      " [-0.1922 -1.2243 -0.2018 -0.3209  0.5931]\n",
      " [-0.0318  0.3761 -0.1    -0.152  -0.5726]\n",
      " [-0.0519 -0.5587 -0.0325 -0.155   0.7708]\n",
      " [-0.9711 -1.0217 -0.9868 -0.8858 -1.4803]\n",
      " [-0.8222 -1.4691 -0.7849 -0.7941  1.7731]\n",
      " [ 0.5781  0.4407  0.5758  0.4584  0.1453]\n",
      " [-0.8279 -1.064  -0.8583 -0.7832 -1.1157]\n",
      " [ 0.0971  0.4229  0.0836 -0.0195 -0.3068]\n",
      " [ 1.947   0.8903  1.9225  2.0976  0.1382]\n",
      " [ 1.085   1.0951  0.9464  1.0177 -0.7254]\n",
      " [ 0.3376 -0.5098  0.4522  0.173   2.4697]\n",
      " [-0.4814  0.9972 -0.3397 -0.5291  1.4106]\n",
      " [ 0.9905  0.8391  1.1029  0.9633 -0.4169]\n",
      " [-0.5988  0.7034 -0.5547 -0.6122 -2.0902]\n",
      " [-0.3669 -1.389  -0.3871 -0.4436  1.041 ]\n",
      " [-0.6131 -0.8704 -0.6289 -0.6255 -0.1084]\n",
      " [-0.195  -0.1803 -0.1968 -0.3067  0.6216]\n",
      " [ 0.2574 -0.6277  0.2681  0.1023  0.0053]\n",
      " [-0.8422  2.1836 -0.8875 -0.795  -1.7249]\n",
      " [-0.8365  0.0667 -0.8352 -0.7912  0.4723]\n",
      " [-1.2497 -0.5721 -1.224  -1.0784  0.3515]\n",
      " [ 1.715   1.9343  1.6054  1.793  -0.0679]\n",
      " [-0.0948  0.9326 -0.0272 -0.1686  2.3844]\n",
      " [-0.8565 -1.4424 -0.8793 -0.8071 -0.0864]\n",
      " [ 0.896   1.3043  0.8311  0.8104 -1.0979]\n",
      " [ 0.4464  0.1669  0.3699  0.3307 -0.198 ]\n",
      " [-1.2609 -1.6895 -1.2759 -1.0834 -0.4447]\n",
      " [ 1.1194 -0.7591  1.1524  1.0387  0.5505]\n",
      " [ 1.1022  0.2448  1.0535  0.9964  0.3443]\n",
      " [-0.951   1.035  -0.9608 -0.8672 -1.1967]\n",
      " [-0.6847 -0.4452 -0.6725 -0.6859  0.6073]\n",
      " [-0.5158  0.5921 -0.5094 -0.5628  0.1737]\n",
      " [ 2.5627  0.0601  2.4662  3.0381 -0.3793]\n",
      " [ 0.0856 -0.975   0.0721 -0.0435  0.0671]\n",
      " [ 0.1429 -0.6032  0.082   0.0331 -0.8776]\n",
      " [ 0.5524  0.02    0.4893  0.4818 -0.503 ]\n",
      " [-0.7506 -1.0306 -0.7557 -0.735   0.1809]\n",
      " [ 0.0226  1.8452  0.0136 -0.0914 -1.1747]\n",
      " [ 1.8868  2.5731  1.7907  2.2603 -0.289 ]\n",
      " [-1.4639 -0.4964 -1.3768 -1.1958  0.5576]\n",
      " [ 1.9899  1.5603  2.079   1.9408  1.0907]\n",
      " [-1.4227 -1.2688 -1.3599 -1.165  -1.5315]\n",
      " [-0.9997  1.2598 -0.997  -0.9104 -0.1554]\n",
      " [-1.1372 -1.0417 -1.1395 -1.0142  1.041 ]\n",
      " [ 0.1142  1.7762  0.1858  0.0118  1.0765]\n",
      " [ 0.077   0.0378  0.1569 -0.0112 -0.7951]\n",
      " [-0.7764 -0.9282 -0.7891 -0.7542 -0.1682]\n",
      " [-0.5415 -0.3606 -0.5745 -0.5753 -0.8683]\n",
      " [ 1.6463  0.1558  1.5766  1.6539  0.3515]\n",
      " [-0.51    0.4986 -0.5123 -0.5581 -0.7844]\n",
      " [ 1.9928  0.2137  1.8896  2.1567 -0.1362]\n",
      " [ 0.2087 -0.6433  0.2644  0.0819  1.24  ]\n",
      " [-1.2812 -0.2382 -1.2656 -1.0816 -0.6608]\n",
      " [-0.2122 -0.581  -0.2776 -0.3029 -1.378 ]\n",
      " [ 1.4687  1.5381  1.4695  1.5001 -0.3373]\n",
      " [ 1.1022 -2.0434  1.2595  1.024   1.3964]\n",
      " [ 0.309   2.4618  0.4605  0.1837  0.4296]\n",
      " [ 0.0341 -0.3094 -0.0412 -0.0642 -2.3454]\n",
      " [-0.699  -0.1002 -0.7368 -0.6983 -0.7546]\n",
      " [ 0.3233 -1.4802  0.2451  0.2091 -1.2038]\n",
      " [ 0.3433 -1.1798  0.4234  0.1467  0.6073]\n",
      " [-0.1807 -0.1492 -0.1697 -0.286   0.5078]\n",
      " [-1.0484  0.0667 -1.0502 -0.9379  0.586 ]\n",
      " [ 0.1429 -0.9616  0.1462 -0.0086  1.0267]\n",
      " [ 0.0885  0.1469  0.0935 -0.0358 -0.0025]\n",
      " [-0.888  -0.6077 -0.8772 -0.8329  0.6358]\n",
      " [ 1.6234  0.5765  1.556   1.79   -0.0317]\n",
      " [-1.1114 -1.6338 -1.0901 -0.9855  0.0856]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "data=pd.read_csv('data.csv')\n",
    "\n",
    "scaler=StandardScaler()\n",
    "data_transformed=scaler.fit_transform(data)\n",
    "print(data_transformed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3491 -1.4385 -0.4117 -0.3905 -1.8637]\n",
      " [-0.2047  0.3126 -0.1337 -0.2759  1.0781]\n",
      " [-0.3293 -0.2151 -0.3174 -0.3644 -1.5799]\n",
      " [ 1.0274  2.0898  1.0469  0.9176  0.3163]\n",
      " [ 1.829   0.696   1.7637  1.7838 -0.3337]]\n",
      "[[-0.4681 -0.1417 -0.4447 -0.486   0.2934]\n",
      " [ 1.3645  0.4996  1.3064  1.3344 -0.3917]\n",
      " [ 0.3788  0.0665  0.4043  0.264   0.9777]\n",
      " [-0.4879 -0.3594 -0.429  -0.5256  0.7054]\n",
      " [-0.7315 -1.1261 -0.71   -0.7079  0.307 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "X_train=pd.read_csv('X_train.csv')\n",
    "X_test=pd.read_csv('X_test.csv')\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "print(X_train_scaled[:5])\n",
    "print(X_test_scaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   val_1  val_2  entropy\n",
      "0   0.01   0.99   0.0808\n",
      "1   0.11   0.89   0.4999\n",
      "2   0.21   0.79   0.7415\n",
      "3   0.31   0.69   0.8932\n",
      "4   0.41   0.59   0.9765\n",
      "5   0.51   0.49   0.9997\n",
      "6   0.61   0.39   0.9648\n",
      "7   0.71   0.29   0.8687\n",
      "8   0.81   0.19   0.7015\n",
      "9   0.91   0.09   0.4365\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def entropy(x):\n",
    "    return np.round(-np.sum(x * np.log2(x)), 4)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'val_1': np.arange(0.01, 1.0, 0.1),\n",
    "        'val_2': 1 - np.arange(0.01, 1.0, 0.1),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'entropy']=entropy([df.loc[i,'val_1'],df.loc[i,'val_2']])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:245: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_pred contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      5\u001b[0m data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m acc\u001b[38;5;241m=\u001b[39maccuracy_score(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m],data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:382\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    380\u001b[0m     data \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39many(data \u001b[38;5;241m!=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(data, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m--> 382\u001b[0m         _assert_all_finite(data, input_name\u001b[38;5;241m=\u001b[39minput_name)\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tkdar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y_pred contains NaN."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "data=pd.read_csv('predictions.csv')\n",
    "acc=accuracy_score(data['y_true'],data['y_pred'])\n",
    "conf=confusion_matrix(data['y_true'],data['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "raw_data = make_moons(n_samples=2000, noise=0.25, random_state=42)\n",
    "data = raw_data[0]\n",
    "target = raw_data[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
    "classifier=DecisionTreeClassifier(max_depth=6,min_samples_leaf=6)\n",
    "classifier.fit(X_train,y_train)\n",
    "acc=classifier.score(X_test,y_test) \n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_leaf': 6}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(42)\n",
    "raw_data = make_moons(n_samples=2000, noise=0.25, random_state=42)\n",
    "data = raw_data[0]\n",
    "target = raw_data[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
    "classifier=DecisionTreeClassifier()\n",
    "params={'max_depth':np.arange(1,10),'min_samples_leaf':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],}\n",
    "grid=GridSearchCV(classifier,params,cv=5,scoring='accuracy')\n",
    "grid.fit(X_train,y_train)   \n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "raw_data = make_moons(n_samples=2000, noise=0.25, random_state=42)\n",
    "data = raw_data[0]\n",
    "target = raw_data[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
    "classifier=RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train,y_train)\n",
    "acc=classifier.score(X_test,y_test)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(42)\n",
    "raw_data = make_moons(n_samples=2000, noise=0.25, random_state=42)\n",
    "data = raw_data[0]\n",
    "target = raw_data[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
    "classifier=RandomForestClassifier()\n",
    "\n",
    "params={'max_depth':[6,7], 'min_samples_leaf':[4,5],'criterion':['gini','entropy']}\n",
    "grid=GridSearchCV(classifier,params,cv=5,scoring='accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "acc=grid.score(X_test,y_test)   \n",
    "print(grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
