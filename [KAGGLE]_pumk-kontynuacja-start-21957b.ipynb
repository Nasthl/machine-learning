{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7187792,"sourceType":"datasetVersion","datasetId":4155562},{"sourceId":7222412,"sourceType":"datasetVersion","datasetId":4180521}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Zadanie: Klasyfikacja zwierząt morskich za pomocą modelu ResNet50\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować obrazy meduzy, ryby, rekina, tuńczyka, wieloryba. W tym celu wykorzystaj model ResNet50, który został wstępnie przeszkolony na szerokim zbiorze danych.\n\nKroki, które musisz podjąć:\n\n1. **Załadowanie danych**: Dane treningowe i walidacyjne zostały już przygotowane w formie generatorów za pomocą biblioteki `ImageDataGenerator`. Generator treningowy zawiera obrazy treningowe, a generator walidacyjny zawiera obrazy walidacyjne. Obrazy są przeskalowane do rozmiaru `(224, 224)` i podzielone na dwie klasy: koty i psy.\n\n2. **Model ResNet50**: W kodzie załadowano model ResNet50, który jest wstępnie przeszkolony na zestawie danych ImageNet. Model ten ma zamrożone wagi wszystkich warstw.\n\n3. **Warstwy klasyfikacji**: Do modelu ResNet50 dodano warstwy klasyfikacji. Jest to warstwa `GlobalAveragePooling2D` i warstwa `Dense`, która wykorzystuje funkcję aktywacji softmax. Model ten jest przystosowany do zadania klasyfikacji, gdzie klasy to jelly, fish shark tuna whale.\n\n4. **Kompilacja modelu**: Model jest skompilowany z optymalizatorem Adam, funkcją straty \"categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej), oraz metryką \"accuracy\".\n\n5. **Trenowanie modelu**: Model jest trenowany na danych treningowych przez jedną epokę. Wynik trenowania jest wyświetlany na konsoli.\n\nTwoim zadaniem jest uzupełnienie tego kodu o brakujące elementy, takie jak liczba epok trenowania, odblokowanie warstw modelu ResNet50 oraz dostosowanie modelu do odpowiedniego rodzaju klasyfikacji (wieloklasowej). Następnie możesz dostosować parametry trenowania, takie jak liczba epok czy wielkość wsadu (batch size), aby osiągnąć jak najlepsze wyniki w zadaniu klasyfikacji zwierząt morskich.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Ustawienie ścieżki do katalogu z danymi\ndata_dir = '/kaggle/input/fall-23-intro-to-vision-dataset/Dataset/classification'\n\n# Definicja generatora obrazów\ndatagen = ImageDataGenerator(\n    rescale=1.0/255, # Przeskalowanie wartości pikseli do zakresu [0, 1]\n    validation_split=0.2 # Procent danych przeznaczonych na zbiór walidacyjny\n)\n\n# Wczytanie danych treningowych\ntrain_generator = datagen.flow_from_directory(\n    '/kaggle/input/fall-23-intro-to-vision-dataset/Dataset/classification/train',\n    target_size=(224, 224), # Rozmiar docelowy obrazów\n    batch_size=32, # Rozmiar wsadu\n    class_mode='categorical', # Rodzaj klasyfikacji (binary lub categorical)\n    subset='training' # Ustawienie dla danych treningowych\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T13:37:29.909549Z","iopub.execute_input":"2024-02-21T13:37:29.909811Z","iopub.status.idle":"2024-02-21T13:37:43.088729Z","shell.execute_reply.started":"2024-02-21T13:37:29.909786Z","shell.execute_reply":"2024-02-21T13:37:43.087981Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-21 13:37:31.695978: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 13:37:31.696065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 13:37:31.826481: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 931 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Wczytanie danych treningowych\nvalidation_generator = datagen.flow_from_directory(\n    '/kaggle/input/fall-23-intro-to-vision-dataset/Dataset/classification/val',\n    target_size=(224, 224), # Rozmiar docelowy obrazów\n    batch_size=32, # Rozmiar wsadu\n    class_mode='categorical', # Rodzaj klasyfikacji (binary lub categorical)\n    subset='training' # Ustawienie dla danych treningowych\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:37:51.617311Z","iopub.execute_input":"2024-02-21T13:37:51.618690Z","iopub.status.idle":"2024-02-21T13:37:51.720329Z","shell.execute_reply.started":"2024-02-21T13:37:51.618655Z","shell.execute_reply":"2024-02-21T13:37:51.719464Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 249 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\n\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nfor layer in base_model.layers[:-1]:\n    layer.trainable = False\n    \n\n# Adding new classification layers\nmodel = Sequential([   base_model,   GlobalAveragePooling2D(),   Dense(5, activation='softmax')])\nmodel.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(train_generator, epochs=40, verbose=1, validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:44:39.563288Z","iopub.execute_input":"2024-02-21T13:44:39.563685Z","iopub.status.idle":"2024-02-21T13:47:35.206347Z","shell.execute_reply.started":"2024-02-21T13:44:39.563655Z","shell.execute_reply":"2024-02-21T13:47:35.205430Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/40\n30/30 [==============================] - 8s 175ms/step - loss: 1.5317 - accuracy: 0.4253 - val_loss: 1.1517 - val_accuracy: 0.5020\nEpoch 2/40\n30/30 [==============================] - 4s 139ms/step - loss: 1.2951 - accuracy: 0.4909 - val_loss: 1.1369 - val_accuracy: 0.5462\nEpoch 3/40\n30/30 [==============================] - 4s 137ms/step - loss: 1.2793 - accuracy: 0.4780 - val_loss: 1.0450 - val_accuracy: 0.6627\nEpoch 4/40\n30/30 [==============================] - 4s 141ms/step - loss: 1.1504 - accuracy: 0.5510 - val_loss: 1.0026 - val_accuracy: 0.6145\nEpoch 5/40\n30/30 [==============================] - 4s 139ms/step - loss: 1.0804 - accuracy: 0.5843 - val_loss: 0.9725 - val_accuracy: 0.6827\nEpoch 6/40\n30/30 [==============================] - 4s 140ms/step - loss: 1.0395 - accuracy: 0.5768 - val_loss: 0.9731 - val_accuracy: 0.6426\nEpoch 7/40\n30/30 [==============================] - 4s 138ms/step - loss: 1.0505 - accuracy: 0.5682 - val_loss: 0.9290 - val_accuracy: 0.6426\nEpoch 8/40\n30/30 [==============================] - 4s 141ms/step - loss: 1.0665 - accuracy: 0.5736 - val_loss: 1.1029 - val_accuracy: 0.5542\nEpoch 9/40\n30/30 [==============================] - 4s 137ms/step - loss: 1.0059 - accuracy: 0.6112 - val_loss: 1.0152 - val_accuracy: 0.6225\nEpoch 10/40\n30/30 [==============================] - 4s 140ms/step - loss: 0.9910 - accuracy: 0.6241 - val_loss: 0.8367 - val_accuracy: 0.6948\nEpoch 11/40\n30/30 [==============================] - 4s 136ms/step - loss: 0.9566 - accuracy: 0.6369 - val_loss: 0.8819 - val_accuracy: 0.6908\nEpoch 12/40\n30/30 [==============================] - 4s 135ms/step - loss: 0.9484 - accuracy: 0.6369 - val_loss: 0.7746 - val_accuracy: 0.7631\nEpoch 13/40\n30/30 [==============================] - 4s 135ms/step - loss: 0.9754 - accuracy: 0.6090 - val_loss: 0.8410 - val_accuracy: 0.7189\nEpoch 14/40\n30/30 [==============================] - 4s 141ms/step - loss: 0.9236 - accuracy: 0.6477 - val_loss: 0.8474 - val_accuracy: 0.6908\nEpoch 15/40\n30/30 [==============================] - 4s 140ms/step - loss: 0.9330 - accuracy: 0.6445 - val_loss: 0.7751 - val_accuracy: 0.6988\nEpoch 16/40\n30/30 [==============================] - 4s 135ms/step - loss: 0.9827 - accuracy: 0.6069 - val_loss: 0.8090 - val_accuracy: 0.7028\nEpoch 17/40\n30/30 [==============================] - 4s 143ms/step - loss: 0.9585 - accuracy: 0.6155 - val_loss: 0.8262 - val_accuracy: 0.6867\nEpoch 18/40\n30/30 [==============================] - 4s 137ms/step - loss: 0.9171 - accuracy: 0.6412 - val_loss: 0.9862 - val_accuracy: 0.5783\nEpoch 19/40\n30/30 [==============================] - 4s 136ms/step - loss: 0.9387 - accuracy: 0.6606 - val_loss: 0.8233 - val_accuracy: 0.6747\nEpoch 20/40\n30/30 [==============================] - 4s 134ms/step - loss: 0.9240 - accuracy: 0.6563 - val_loss: 0.9144 - val_accuracy: 0.6908\nEpoch 21/40\n30/30 [==============================] - 4s 138ms/step - loss: 0.8548 - accuracy: 0.6713 - val_loss: 0.8947 - val_accuracy: 0.6787\nEpoch 22/40\n30/30 [==============================] - 4s 134ms/step - loss: 0.8703 - accuracy: 0.6885 - val_loss: 0.7934 - val_accuracy: 0.7831\nEpoch 23/40\n30/30 [==============================] - 4s 137ms/step - loss: 0.8234 - accuracy: 0.6928 - val_loss: 0.7938 - val_accuracy: 0.7309\nEpoch 24/40\n30/30 [==============================] - 4s 136ms/step - loss: 0.8485 - accuracy: 0.6971 - val_loss: 0.8502 - val_accuracy: 0.7631\nEpoch 25/40\n30/30 [==============================] - 4s 141ms/step - loss: 0.9066 - accuracy: 0.6874 - val_loss: 0.8155 - val_accuracy: 0.7510\nEpoch 26/40\n30/30 [==============================] - 4s 136ms/step - loss: 0.8336 - accuracy: 0.6992 - val_loss: 0.8256 - val_accuracy: 0.7149\nEpoch 27/40\n30/30 [==============================] - 4s 140ms/step - loss: 0.8574 - accuracy: 0.6670 - val_loss: 0.7527 - val_accuracy: 0.7068\nEpoch 28/40\n30/30 [==============================] - 4s 137ms/step - loss: 0.9726 - accuracy: 0.6369 - val_loss: 1.4254 - val_accuracy: 0.5422\nEpoch 29/40\n30/30 [==============================] - 4s 135ms/step - loss: 1.0844 - accuracy: 0.6294 - val_loss: 0.8287 - val_accuracy: 0.7550\nEpoch 30/40\n30/30 [==============================] - 4s 140ms/step - loss: 0.9074 - accuracy: 0.6531 - val_loss: 0.9282 - val_accuracy: 0.7349\nEpoch 31/40\n30/30 [==============================] - 4s 137ms/step - loss: 0.8442 - accuracy: 0.6917 - val_loss: 0.7760 - val_accuracy: 0.7510\nEpoch 32/40\n30/30 [==============================] - 4s 139ms/step - loss: 0.9020 - accuracy: 0.6262 - val_loss: 1.1186 - val_accuracy: 0.5904\nEpoch 33/40\n30/30 [==============================] - 4s 140ms/step - loss: 0.8338 - accuracy: 0.6767 - val_loss: 0.8642 - val_accuracy: 0.6867\nEpoch 34/40\n30/30 [==============================] - 4s 136ms/step - loss: 0.8729 - accuracy: 0.6638 - val_loss: 0.8822 - val_accuracy: 0.6908\nEpoch 35/40\n30/30 [==============================] - 4s 138ms/step - loss: 0.7561 - accuracy: 0.7164 - val_loss: 0.8304 - val_accuracy: 0.7108\nEpoch 36/40\n30/30 [==============================] - 4s 135ms/step - loss: 0.7702 - accuracy: 0.7111 - val_loss: 0.7196 - val_accuracy: 0.7590\nEpoch 37/40\n30/30 [==============================] - 4s 134ms/step - loss: 0.7706 - accuracy: 0.7132 - val_loss: 0.8131 - val_accuracy: 0.7269\nEpoch 38/40\n30/30 [==============================] - 4s 138ms/step - loss: 0.7798 - accuracy: 0.7003 - val_loss: 0.8318 - val_accuracy: 0.6948\nEpoch 39/40\n30/30 [==============================] - 4s 136ms/step - loss: 0.8388 - accuracy: 0.6842 - val_loss: 1.0064 - val_accuracy: 0.7229\nEpoch 40/40\n30/30 [==============================] - 5s 147ms/step - loss: 0.8421 - accuracy: 0.6992 - val_loss: 0.7383 - val_accuracy: 0.7550\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e5c5052aaa0>"},"metadata":{}}]},{"cell_type":"code","source":"base_model.layers","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:53:15.604672Z","iopub.execute_input":"2024-02-20T17:53:15.605019Z","iopub.status.idle":"2024-02-20T17:53:15.619127Z","shell.execute_reply.started":"2024-02-20T17:53:15.604993Z","shell.execute_reply":"2024-02-20T17:53:15.618094Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[<keras.src.engine.input_layer.InputLayer at 0x7d45307938b0>,\n <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7d419485e860>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4540775d80>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45ba323550>,\n <keras.src.layers.core.activation.Activation at 0x7d45bbf86ec0>,\n <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7d4182284eb0>,\n <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7d4182286530>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41822855d0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45407c5c90>,\n <keras.src.layers.core.activation.Activation at 0x7d45902af640>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c36f220>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c189060>,\n <keras.src.layers.core.activation.Activation at 0x7d4540776dd0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d419485d4e0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c5ddf30>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41822865f0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c5ddd80>,\n <keras.src.layers.merging.add.Add at 0x7d45903dc0a0>,\n <keras.src.layers.core.activation.Activation at 0x7d455c6fff10>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c25e860>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45900ba0b0>,\n <keras.src.layers.core.activation.Activation at 0x7d45900bafe0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c5df100>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c76ef20>,\n <keras.src.layers.core.activation.Activation at 0x7d455c76c130>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c6c6050>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4182500be0>,\n <keras.src.layers.merging.add.Add at 0x7d41824e2f80>,\n <keras.src.layers.core.activation.Activation at 0x7d4182286260>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194a10910>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4194a10610>,\n <keras.src.layers.core.activation.Activation at 0x7d4182286d70>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d419498aa40>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d419498ae90>,\n <keras.src.layers.core.activation.Activation at 0x7d4194988520>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194989fc0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d419498acb0>,\n <keras.src.layers.merging.add.Add at 0x7d419498a7a0>,\n <keras.src.layers.core.activation.Activation at 0x7d4194b11ed0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194b13a90>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4194b109a0>,\n <keras.src.layers.core.activation.Activation at 0x7d4194b12590>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194b13970>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4194b112a0>,\n <keras.src.layers.core.activation.Activation at 0x7d459038c610>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194b13910>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4182287670>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4194b10d90>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c25dd80>,\n <keras.src.layers.merging.add.Add at 0x7d4182286f80>,\n <keras.src.layers.core.activation.Activation at 0x7d4194a57190>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194bdee30>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45301a08e0>,\n <keras.src.layers.core.activation.Activation at 0x7d455c5de020>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45bbe8a800>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbe8b670>,\n <keras.src.layers.core.activation.Activation at 0x7d45bbe8b730>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45bbf86c50>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbdbf190>,\n <keras.src.layers.merging.add.Add at 0x7d45bbf856c0>,\n <keras.src.layers.core.activation.Activation at 0x7d45bbf3b940>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45bbf38070>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbf3b760>,\n <keras.src.layers.core.activation.Activation at 0x7d45bbf39420>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45bbf5a620>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbf5a8c0>,\n <keras.src.layers.core.activation.Activation at 0x7d45bbe5e5c0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45bbe5cc70>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbe5d390>,\n <keras.src.layers.merging.add.Add at 0x7d4590192a70>,\n <keras.src.layers.core.activation.Activation at 0x7d45b8144130>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d459023de10>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4590384ca0>,\n <keras.src.layers.core.activation.Activation at 0x7d4590387910>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d459023d6f0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c5aa650>,\n <keras.src.layers.core.activation.Activation at 0x7d459023e230>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c592290>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c753dc0>,\n <keras.src.layers.merging.add.Add at 0x7d455c5aa530>,\n <keras.src.layers.core.activation.Activation at 0x7d455c593370>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45bc025de0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c7196f0>,\n <keras.src.layers.core.activation.Activation at 0x7d4194bddf90>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c72ce20>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c72ffd0>,\n <keras.src.layers.core.activation.Activation at 0x7d455c1abca0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45b8146620>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d45900fb820>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbe5c670>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45900fb0d0>,\n <keras.src.layers.merging.add.Add at 0x7d45900fbb80>,\n <keras.src.layers.core.activation.Activation at 0x7d455c656200>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c5f1d80>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c5f15a0>,\n <keras.src.layers.core.activation.Activation at 0x7d455c5f0d90>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41822a5300>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41822a5420>,\n <keras.src.layers.core.activation.Activation at 0x7d41822a5e40>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41822a4a30>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41822a72e0>,\n <keras.src.layers.merging.add.Add at 0x7d41822a43d0>,\n <keras.src.layers.core.activation.Activation at 0x7d455c0dc490>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c0de200>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c0de1a0>,\n <keras.src.layers.core.activation.Activation at 0x7d455c0df370>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c0df910>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d455c0dd150>,\n <keras.src.layers.core.activation.Activation at 0x7d455c0dfb80>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949c57e0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949c5d20>,\n <keras.src.layers.merging.add.Add at 0x7d41949c78b0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949c75e0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949c5810>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41822a69e0>,\n <keras.src.layers.core.activation.Activation at 0x7d41822a4e20>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d455c0dcca0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d45bbe5e9e0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949c69b0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949fc0a0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949fd300>,\n <keras.src.layers.merging.add.Add at 0x7d41949fe6e0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949ff100>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949ffe50>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949fd2d0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949e9240>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949e97e0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949e9de0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949eb640>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949ebbe0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949ea530>,\n <keras.src.layers.merging.add.Add at 0x7d41949eb550>,\n <keras.src.layers.core.activation.Activation at 0x7d41949d1d20>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949d2710>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949d26b0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949d2cb0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949d21a0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949b8700>,\n <keras.src.layers.core.activation.Activation at 0x7d41949b9ed0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949b9810>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949ba680>,\n <keras.src.layers.merging.add.Add at 0x7d41949bb790>,\n <keras.src.layers.core.activation.Activation at 0x7d41949ba4d0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949a9de0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949aa860>,\n <keras.src.layers.core.activation.Activation at 0x7d41949d1900>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949d2140>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949d0940>,\n <keras.src.layers.core.activation.Activation at 0x7d41949fe8f0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949bb400>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949fcf70>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949a8f40>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949e81c0>,\n <keras.src.layers.merging.add.Add at 0x7d41949fc580>,\n <keras.src.layers.core.activation.Activation at 0x7d4194981bd0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194981360>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4194983970>,\n <keras.src.layers.core.activation.Activation at 0x7d41949ab850>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194982950>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d4194981f60>,\n <keras.src.layers.core.activation.Activation at 0x7d4194983fa0>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d4194979fc0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d419497ac80>,\n <keras.src.layers.merging.add.Add at 0x7d4194980d90>,\n <keras.src.layers.core.activation.Activation at 0x7d4194978c10>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d419497bca0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d419497bd00>,\n <keras.src.layers.core.activation.Activation at 0x7d4194979690>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d419497bd90>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d419497ba00>,\n <keras.src.layers.core.activation.Activation at 0x7d4194955330>,\n <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d41949560b0>,\n <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d41949576a0>,\n <keras.src.layers.merging.add.Add at 0x7d419497bdc0>,\n <keras.src.layers.core.activation.Activation at 0x7d41949568c0>]"},"metadata":{}}]},{"cell_type":"markdown","source":"\n### Zadanie prostsze: Analiza fake newsów na podstawie tytułów, \n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować tweety na podstawie tytułu. W danych mamy dostarczone tytuły artykułów oraz etykiety fake news (1) albo nie (0). \nKroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty znajdują się w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty powinny być tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie i przykładowo niech składa się z następujących warstw:\n\n    * Warstwa wejściowa: Przyjmuje sekwencje tokenów o maksymalnej długości max_sequence_length.\n    * Warstwa Embedding: Mapuje tokeny na wektory o wymiarze 100.\n    * Warstwa LSTM: Warstwa rekurencyjna LSTM o rozmiarze 64, która przetwarza sekwencje wektorów.\n    * Warstwa Dense: Warstwa wyjściowa z funkcją aktywacji softmax, która generuje dwa możliwe klasy.\n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcją straty \"sparse_categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metryką \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy fake newsów na podstawie tytułów. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size), wymiar embeddingu czy rozmiar warstwy LSTM, aby dostosować model.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \n\nfake = pd.read_csv(\"/kaggle/input/fake-news-detection/fake.csv\")\ntrue = pd.read_csv(\"/kaggle/input/fake-news-detection/true.csv\")\n\nfake['class']=0\ntrue['class']=1\n\n\ndata = pd.concat([fake,true],axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:59:46.838893Z","iopub.execute_input":"2024-02-20T18:59:46.839289Z","iopub.status.idle":"2024-02-20T18:59:49.801654Z","shell.execute_reply.started":"2024-02-20T18:59:46.839254Z","shell.execute_reply":"2024-02-20T18:59:49.800776Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:59:49.803725Z","iopub.execute_input":"2024-02-20T18:59:49.804594Z","iopub.status.idle":"2024-02-20T18:59:49.822174Z","shell.execute_reply.started":"2024-02-20T18:59:49.804553Z","shell.execute_reply":"2024-02-20T18:59:49.821086Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0   Donald Trump Sends Out Embarrassing New Year’...   \n1   Drunk Bragging Trump Staffer Started Russian ...   \n2   Sheriff David Clarke Becomes An Internet Joke...   \n3   Trump Is So Obsessed He Even Has Obama’s Name...   \n4   Pope Francis Just Called Out Donald Trump Dur...   \n\n                                                text subject  \\\n0  Donald Trump just couldn t wish all Americans ...    News   \n1  House Intelligence Committee Chairman Devin Nu...    News   \n2  On Friday, it was revealed that former Milwauk...    News   \n3  On Christmas day, Donald Trump announced that ...    News   \n4  Pope Francis used his annual Christmas Day mes...    News   \n\n                date  class  \n0  December 31, 2017      0  \n1  December 31, 2017      0  \n2  December 30, 2017      0  \n3  December 29, 2017      0  \n4  December 25, 2017      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n      <td>News</td>\n      <td>December 30, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n      <td>News</td>\n      <td>December 29, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n      <td>News</td>\n      <td>December 25, 2017</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['class']","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:59:49.823579Z","iopub.execute_input":"2024-02-20T18:59:49.823906Z","iopub.status.idle":"2024-02-20T18:59:49.832877Z","shell.execute_reply.started":"2024-02-20T18:59:49.823878Z","shell.execute_reply":"2024-02-20T18:59:49.831572Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n21412    1\n21413    1\n21414    1\n21415    1\n21416    1\nName: class, Length: 44898, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"X = data['title'].to_numpy()\ny = data['class'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:59:49.834984Z","iopub.execute_input":"2024-02-20T18:59:49.835457Z","iopub.status.idle":"2024-02-20T18:59:49.840869Z","shell.execute_reply.started":"2024-02-20T18:59:49.835427Z","shell.execute_reply":"2024-02-20T18:59:49.839885Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = max(len(seq) for seq in X)\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:08:33.211543Z","iopub.execute_input":"2024-02-20T18:08:33.212282Z","iopub.status.idle":"2024-02-20T18:08:35.864158Z","shell.execute_reply.started":"2024-02-20T18:08:33.212252Z","shell.execute_reply":"2024-02-20T18:08:35.863246Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\nmodel = Sequential()\nmodel.add(Embedding(input_dim=max_sequence_length, output_dim=100))\nmodel.add(LSTM(64))\nmodel.add(Dense(256))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=500, verbose=1, validation_data=(X_val,y_val))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:08:38.783638Z","iopub.execute_input":"2024-02-20T18:08:38.784749Z","iopub.status.idle":"2024-02-20T18:09:30.536926Z","shell.execute_reply.started":"2024-02-20T18:08:38.784716Z","shell.execute_reply":"2024-02-20T18:09:30.536052Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1708452522.105430    7011 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"63/63 [==============================] - 13s 163ms/step - loss: 0.3418 - accuracy: 0.8572 - val_loss: 0.1698 - val_accuracy: 0.9327\nEpoch 2/10\n63/63 [==============================] - 8s 127ms/step - loss: 0.1574 - accuracy: 0.9401 - val_loss: 0.1541 - val_accuracy: 0.9405\nEpoch 3/10\n63/63 [==============================] - 6s 99ms/step - loss: 0.1467 - accuracy: 0.9435 - val_loss: 0.1478 - val_accuracy: 0.9405\nEpoch 4/10\n63/63 [==============================] - 3s 56ms/step - loss: 0.1485 - accuracy: 0.9432 - val_loss: 0.1495 - val_accuracy: 0.9420\nEpoch 5/10\n63/63 [==============================] - 5s 71ms/step - loss: 0.1378 - accuracy: 0.9481 - val_loss: 0.1435 - val_accuracy: 0.9431\nEpoch 6/10\n63/63 [==============================] - 4s 64ms/step - loss: 0.1329 - accuracy: 0.9488 - val_loss: 0.1432 - val_accuracy: 0.9434\nEpoch 7/10\n63/63 [==============================] - 3s 52ms/step - loss: 0.1308 - accuracy: 0.9497 - val_loss: 0.1396 - val_accuracy: 0.9439\nEpoch 8/10\n63/63 [==============================] - 3s 49ms/step - loss: 0.1271 - accuracy: 0.9509 - val_loss: 0.1466 - val_accuracy: 0.9428\nEpoch 9/10\n63/63 [==============================] - 3s 44ms/step - loss: 0.1295 - accuracy: 0.9496 - val_loss: 0.1389 - val_accuracy: 0.9442\nEpoch 10/10\n63/63 [==============================] - 2s 39ms/step - loss: 0.1254 - accuracy: 0.9510 - val_loss: 0.1372 - val_accuracy: 0.9436\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x780b0aa6da20>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:12:20.232621Z","iopub.execute_input":"2024-02-20T18:12:20.233832Z","iopub.status.idle":"2024-02-20T18:12:26.991957Z","shell.execute_reply.started":"2024-02-20T18:12:20.233783Z","shell.execute_reply":"2024-02-20T18:12:26.990525Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/10\n37/63 [================>.............] - ETA: 2s - loss: nan - accuracy: 0.5245","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"\n### Zadanie trudniejsze: Analiza fake newsów na podstawie opisu, \n\n\nTwoim zadaniem jest stworzenie modelu sieci neuronowej, który będzie klasyfikować tweety na podstawie opisu. W danych mamy dostarczone artykuły oraz etykiety fake news (1) albo nie (0). \nKroki, które musisz podjąć:\n\n1. Przygotowanie danych: Dane zostały wczytane z pliku CSV. Teksty znajdują się w kolumnach title, a etykiety w kolumnie \"class\". Teksty oraz etykiety są przygotowane do dalszej obróbki.\n\n2. Tokenizacja tekstu: Teksty powinny być tokenizowane za pomocą Tokenizer, a następnie przekształcane na sekwencje liczb. Jest to niezbędne, aby można było używać ich jako danych wejściowych do modelu sieci neuronowej.\n\n3. Zbuduj model sieci neuronowej: Model sieci rekurencyjnej zdefiniuj w kodzie. \n\n4. Kompilacja modelu: Model jest kompilowany z optymalizatorem Adam, funkcją straty \"sparse_categorical_crossentropy\" (odpowiednia do klasyfikacji wieloklasowej) oraz metryką \"accuracy\".\n\n5. Trenowanie modelu: Model jest trenowany na danych tweetów przez 5 epok, z wsadem o rozmiarze 32. Wynik trenowania jest oceniany na zbiorze walidacyjnym.\n\nTwoim zadaniem jest uzupełnienie kodu i dostosowanie parametrów modelu oraz trenowania, aby uzyskać jak najlepsze wyniki w zadaniu analizy fake newsów na podstawie tytułów. Możesz eksperymentować z parametrami, takimi jak liczba epok trenowania, rozmiar wsadu (batch size), wymiar embeddingu czy rozmiar warstwy LSTM, aby dostosować model.\n","metadata":{}},{"cell_type":"code","source":"X = data['text'].to_numpy()\ny = data['class'].to_numpy()\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Tokenizacja tekstu\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\nword_index = tokenizer.word_index\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.3, random_state=42)\n\nmax_sequence_length = 10000 #ile\nX_train = pad_sequences(X_train, maxlen=max_sequence_length)\nX_val = pad_sequences(X_val, maxlen=max_sequence_length)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T19:00:21.611734Z","iopub.execute_input":"2024-02-20T19:00:21.612157Z","iopub.status.idle":"2024-02-20T19:01:01.401211Z","shell.execute_reply.started":"2024-02-20T19:00:21.612123Z","shell.execute_reply":"2024-02-20T19:01:01.400257Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-02-20 19:00:22.020678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-20 19:00:22.020737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-20 19:00:22.022488: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\nmodel = Sequential()\nmodel.add(Embedding(input_dim=max_sequence_length, output_dim=100))\nmodel.add(LSTM(64))\nmodel.add(Dense(256))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1, validation_data=(X_val,y_val))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T19:01:08.921388Z","iopub.execute_input":"2024-02-20T19:01:08.922790Z","iopub.status.idle":"2024-02-20T19:45:59.564402Z","shell.execute_reply.started":"2024-02-20T19:01:08.922743Z","shell.execute_reply":"2024-02-20T19:45:59.562923Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1708455674.602040    5093 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"3143/3143 [==============================] - 996s 316ms/step - loss: 0.1175 - accuracy: 0.9583 - val_loss: 0.0601 - val_accuracy: 0.9830\nEpoch 2/10\n3143/3143 [==============================] - 849s 270ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0400 - val_accuracy: 0.9924\nEpoch 3/10\n3143/3143 [==============================] - 837s 266ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.0362 - val_accuracy: 0.9895\nEpoch 4/10\n  20/3143 [..............................] - ETA: 11:22 - loss: 0.0150 - accuracy: 0.9950","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <function AtomicFunction.__del__ at 0x7f8ae5319750>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 286, in __del__\n    def __del__(self):\nKeyboardInterrupt: \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"3143/3143 [==============================] - 996s 316ms/step - loss: 0.1175 - accuracy: 0.9583 - val_loss: 0.0601 - val_accuracy: 0.9830\nEpoch 2/10\n3143/3143 [==============================] - 849s 270ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0400 - val_accuracy: 0.9924\nEpoch 3/10\n3143/3143 [==============================] - 837s 266ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.0362 - val_accuracy: 0.9895","metadata":{"execution":{"iopub.status.busy":"2024-02-20T19:46:08.046769Z","iopub.execute_input":"2024-02-20T19:46:08.047607Z","iopub.status.idle":"2024-02-20T19:46:08.055713Z","shell.execute_reply.started":"2024-02-20T19:46:08.047570Z","shell.execute_reply":"2024-02-20T19:46:08.054125Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    3143/3143 [==============================] - 996s 316ms/step - loss: 0.1175 - accuracy: 0.9583 - val_loss: 0.0601 - val_accuracy: 0.9830\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"],"ename":"SyntaxError","evalue":"invalid decimal literal (681889006.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}